{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0ec2c20dcd7cdb",
   "metadata": {},
   "source": [
    "# Astro pipeline: target variable and XGBoost (BTC)\n",
    "\n",
    "This notebook shows the full cycle:\n",
    "1) load quotes (daily)\n",
    "2) build target variable (oracle labels)\n",
    "3) compute astro data and build astro features\n",
    "4) train and evaluate XGBoost.\n",
    "\n",
    "Important: features are astro-only; price is used only for targets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db0239534a72ec",
   "metadata": {},
   "source": [
    "## 0. Environment setup\n",
    "\n",
    "If some packages are missing, install via conda-forge (in active env):\n",
    "\n",
    "```\n",
    "conda install -c conda-forge xgboost scikit-learn matplotlib seaborn tqdm pyarrow jupyterlab\n",
    "```\n",
    "\n",
    "Also check:\n",
    "- `configs/astro.yaml` -> `ephe_path` (path to Swiss Ephemeris)\n",
    "- `configs/subjects.yaml` -> `active_subject_id` and subject birth date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5052dce34d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- TRACE HELPERS (auto-generated) ---\n",
    "import inspect as _inspect\n",
    "from pathlib import Path as _Path\n",
    "\n",
    "def _format_value(val, max_items=5):\n",
    "    try:\n",
    "        import pandas as _pd\n",
    "    except Exception:\n",
    "        _pd = None\n",
    "    try:\n",
    "        import numpy as _np\n",
    "    except Exception:\n",
    "        _np = None\n",
    "\n",
    "    if _inspect.ismodule(val):\n",
    "        return f\"<module {getattr(val, '__name__', 'module')}>\"\n",
    "    if _inspect.isfunction(val) or _inspect.isclass(val):\n",
    "        return f\"<{type(val).__name__} {getattr(val, '__name__', '')}>\"\n",
    "    if isinstance(val, _Path):\n",
    "        return f\"Path('{val}')\"\n",
    "    if _pd is not None and isinstance(val, _pd.DataFrame):\n",
    "        cols = list(val.columns)\n",
    "        head = val.head(3)\n",
    "        return f\"DataFrame shape={val.shape} cols={cols} head=\\n{head}\"\n",
    "    if _pd is not None and isinstance(val, _pd.Series):\n",
    "        head = val.head(3).to_list()\n",
    "        return f\"Series len={len(val)} name={val.name} head={head}\"\n",
    "    if _np is not None and isinstance(val, _np.ndarray):\n",
    "        sample = val.flatten()[:max_items]\n",
    "        return f\"ndarray shape={val.shape} dtype={val.dtype} sample={sample}\"\n",
    "    if isinstance(val, dict):\n",
    "        keys = list(val.keys())\n",
    "        return f\"dict keys={keys[:max_items]}\" + (\"...\" if len(keys) > max_items else \"\")\n",
    "    if isinstance(val, (list, tuple, set)):\n",
    "        lst = list(val)\n",
    "        return f\"{type(val).__name__} len={len(val)} sample={lst[:max_items]}\" + (\"...\" if len(lst) > max_items else \"\")\n",
    "    if isinstance(val, str):\n",
    "        if len(val) > 200:\n",
    "            return repr(val[:200] + '...')\n",
    "        return repr(val)\n",
    "    try:\n",
    "        return repr(val)\n",
    "    except Exception:\n",
    "        return f\"<{type(val).__name__}>\"\n",
    "\n",
    "VAR_HELP = {\n",
    "    'center': \"astro coordinate center ('geo' or 'helio')\",\n",
    "    'price_mode': \"oracle price_mode: 'log' or 'raw'\",\n",
    "    'LABEL_PRICE_MODE': \"labeling price space: 'log' or 'raw'\",\n",
    "    'LABEL_MODE': \"labeling mode (balanced_future_return / balanced_detrended)\",\n",
    "    'GAUSS_WINDOW': \"Gaussian window size (odd) for centered detrend\",\n",
    "    'GAUSS_STD': \"Gaussian std for centered detrend\",\n",
    "    'HORIZON': \"prediction horizon (days ahead)\",\n",
    "    'TARGET_MOVE_SHARE': \"target share of samples kept for balanced labeling\",\n",
    "    'MOVE_SHARE_TOTAL': \"total share kept (split up/down)\",\n",
    "    'cfg_market': \"market config loaded from configs/market.yaml\",\n",
    "    'cfg_astro': \"astro config loaded from configs/astro.yaml\",\n",
    "    'cfg_labels': \"labels config loaded from configs/labels.yaml\",\n",
    "    'df_market': \"market DataFrame (daily OHLCV)\",\n",
    "    'df_bodies': \"astro bodies table (daily)\",\n",
    "    'df_aspects': \"astro aspects table (daily)\",\n",
    "    'df_transits': \"transit-to-natal aspects table (daily)\",\n",
    "    'df_features': \"feature matrix (astro features)\",\n",
    "    'df_labels': \"oracle labels table\",\n",
    "    'feature_cols': \"feature column names used for model training\",\n",
    "    'TWO_STAGE': \"two-stage XGB (move + direction) flag\",\n",
    "    'model': \"single-stage model wrapper\",\n",
    "    'model_move': \"two-stage move model\",\n",
    "    'model_dir': \"two-stage direction model\",\n",
    "}\n",
    "\n",
    "\n",
    "def trace_cell(title, purpose=None, used_vars=None, notes=None):\n",
    "    print(\"\\n\" + \"=\" * 120)\n",
    "    print(f\"[CELL] {title}\")\n",
    "    if purpose:\n",
    "        print(f\"Purpose: {purpose}\")\n",
    "    if notes:\n",
    "        print(\"Notes:\")\n",
    "        for n in notes:\n",
    "            print(f\"- {n}\")\n",
    "    if used_vars:\n",
    "        print(\"Variables used in this cell:\")\n",
    "        for name in used_vars:\n",
    "            if name in globals():\n",
    "                val = globals()[name]\n",
    "                expl = VAR_HELP.get(name)\n",
    "                if expl:\n",
    "                    print(f\"  {name} ({expl}) = {_format_value(val)}\")\n",
    "                else:\n",
    "                    print(f\"  {name} = {_format_value(val)}\")\n",
    "            else:\n",
    "                print(f\"  {name} = <not set>\")\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "# Check dependencies (stop notebook if missing)\n",
    "import importlib.util as iu\n",
    "\n",
    "required = [\"xgboost\", \"sklearn\", \"matplotlib\", \"seaborn\", \"tqdm\", \"pyarrow\"]\n",
    "missing = [pkg for pkg in required if iu.find_spec(pkg) is None]\n",
    "\n",
    "if missing:\n",
    "    print(\"Missing packages:\", \", \".join(missing))\n",
    "    print(\"Install them with:\")\n",
    "    print(\"conda install -c conda-forge xgboost scikit-learn matplotlib seaborn tqdm pyarrow jupyterlab\")\n",
    "    raise SystemExit(\"Stopped: install dependencies and rerun\")\n",
    "\n",
    "print(\"OK: all core dependencies found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e67268d6aa58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 3',\n",
    "    purpose='Base imports and environment setup',\n",
    "    used_vars=['PROJECT_ROOT', 'Path', 'parent', 'pd', 'plt', 'sns', 'sys'],\n",
    ")\n",
    "\n",
    "# Base imports and environment setup\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visual style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 4)\n",
    "\n",
    "# Table display settings\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# Project root search (look for configs/market.yaml)\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / \"configs/market.yaml\").exists():\n",
    "    for parent in PROJECT_ROOT.parents:\n",
    "        if (parent / \"configs/market.yaml\").exists():\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "\n",
    "if not (PROJECT_ROOT / \"configs/market.yaml\").exists():\n",
    "    raise FileNotFoundError(\"Project root not found: configs/market.yaml\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"PROJECT_ROOT = {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d63f18bcb70dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 4',\n",
    "    purpose='Load configs and market data (from Postgres)',\n",
    "    used_vars=['NB_PLOT_PRICE_MODE', 'PLOT_PRICE_MODE', 'PROJECT_ROOT', 'Path', '_resolve_path', 'active_id', 'cfg_db', 'cfg_labels', 'cfg_market', 'conn', 'data_root', 'db_url', 'df_market', 'load_subjects', 'load_yaml', 'market_cfg', 'path', 'pd', 'psql_connection', 'reports_dir', 'subject', 'subjects', 'value'],\n",
    "    notes=['Loads market config; if DB/parquet cache enabled, avoids re-download.', 'Market dataframe is the price source for labels/plots.'],\n",
    ")\n",
    "\n",
    "# Load configs and market data (from Postgres)\n",
    "from src.common.config import load_yaml, load_subjects\n",
    "from src.db.connection import psql_connection\n",
    "\n",
    "cfg_market = load_yaml(PROJECT_ROOT / \"configs/market.yaml\")\n",
    "cfg_astro = load_yaml(PROJECT_ROOT / \"configs/astro.yaml\")\n",
    "cfg_labels = load_yaml(PROJECT_ROOT / \"configs/labels.yaml\")\n",
    "cfg_db = load_yaml(PROJECT_ROOT / \"configs/db.yaml\")\n",
    "cfg_train = load_yaml(PROJECT_ROOT / \"configs/training.yaml\")\n",
    "\n",
    "subjects, active_id = load_subjects(PROJECT_ROOT / \"configs/subjects.yaml\")\n",
    "subject = subjects[active_id]\n",
    "\n",
    "market_cfg = cfg_market[\"market\"]\n",
    "\n",
    "# NOTE: if path is relative, resolve from PROJECT_ROOT\n",
    "def _resolve_path(value: str | Path) -> Path:\n",
    "    path = Path(value)\n",
    "    if path.is_absolute():\n",
    "        return path\n",
    "    return (PROJECT_ROOT / path).resolve()\n",
    "\n",
    "data_root = _resolve_path(market_cfg[\"data_root\"])\n",
    "processed_dir = data_root / \"processed\"\n",
    "reports_dir = data_root / \"reports\"\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Active subject: {subject.subject_id}\")\n",
    "print(f\"Data root: {data_root}\")\n",
    "\n",
    "# Market source: Postgres only\n",
    "if \"db\" not in cfg_db or \"url\" not in cfg_db[\"db\"]:\n",
    "    raise KeyError(\"configs/db.yaml must define db.url\")\n",
    "\n",
    "db_url = cfg_db[\"db\"][\"url\"]\n",
    "\n",
    "# Load market_daily from DB\n",
    "with psql_connection(db_url) as conn:\n",
    "    df_market = pd.read_sql_query(\n",
    "        \"SELECT date, close FROM market_daily WHERE subject_id = %s ORDER BY date\",\n",
    "        conn,\n",
    "        params=(subject.subject_id,),\n",
    "    )\n",
    "\n",
    "if df_market.empty:\n",
    "    raise ValueError(\n",
    "        f\"No market data for subject_id={subject.subject_id}. \"\n",
    "        \"Load market_daily into Postgres first.\"\n",
    "    )\n",
    "\n",
    "if \"date\" not in df_market.columns or \"close\" not in df_market.columns:\n",
    "    raise ValueError(\"market_daily must have date and close columns\")\n",
    "\n",
    "df_market[\"date\"] = pd.to_datetime(df_market[\"date\"])\n",
    "print(df_market.head())\n",
    "print(f\"Market range: {df_market['date'].min().date()} -> {df_market['date'].max().date()}\")\n",
    "print(f\"Rows: {len(df_market)}\")\n",
    "\n",
    "# Plot price mode (optional override)\n",
    "NB_PLOT_PRICE_MODE = None  # 'log' or 'raw'\n",
    "PLOT_PRICE_MODE = str(NB_PLOT_PRICE_MODE or cfg_labels['labels'].get('price_mode', 'log')).lower()\n",
    "if PLOT_PRICE_MODE not in {'log', 'raw'}:\n",
    "    print(f\"[WARN] Unknown PLOT_PRICE_MODE={PLOT_PRICE_MODE}, fallback to 'log'\")\n",
    "    PLOT_PRICE_MODE = 'log'\n",
    "print(f\"PLOT_PRICE_MODE = {PLOT_PRICE_MODE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536de49616520110",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 5',\n",
    "    purpose='Quick look at price and daily change distribution',\n",
    "    used_vars=['PLOT_PRICE_MODE', 'ax', 'df_market', 'log_ret', 'np', 'plt', 'price_label', 'price_series'],\n",
    "    notes=['Market dataframe is the price source for labels/plots.'],\n",
    ")\n",
    "\n",
    "# Quick look at price and daily change distribution\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=False)\n",
    "\n",
    "price_series = np.log(df_market['close']) if PLOT_PRICE_MODE == 'log' else df_market['close']\n",
    "price_label = 'log(close)' if PLOT_PRICE_MODE == 'log' else 'close'\n",
    "\n",
    "ax[0].plot(df_market['date'], price_series, color='tab:blue', linewidth=1)\n",
    "ax[0].set_title('BTC close (daily)')\n",
    "ax[0].set_xlabel('Date')\n",
    "ax[0].set_ylabel(price_label)\n",
    "\n",
    "# Log returns for a rough distribution check\n",
    "log_ret = np.log(df_market['close']).diff().dropna()\n",
    "ax[1].hist(log_ret, bins=80, color='tab:gray')\n",
    "ax[1].set_title('Daily log return distribution')\n",
    "ax[1].set_xlabel('log_return')\n",
    "ax[1].set_ylabel('frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e7131b28eb523",
   "metadata": {},
   "source": [
    "## 1. Oracle labels (target variable)\n",
    "\n",
    "Idea: smooth log price, take slope, classify by threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0560a518668735",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 7',\n",
    "    purpose='Balanced binary labeling based on future return',\n",
    "    used_vars=['GAUSS_STD', 'GAUSS_WINDOW', 'HORIZON', 'LABEL_MODE', 'LABEL_PRICE_MODE', 'MOVE_SHARE_TOTAL', 'TARGET_MOVE_SHARE', '_gaussian_kernel', '_gaussian_smooth_centered', 'base', 'base_series', 'cfg_labels', 'df_labels', 'df_market', 'down_idx', 'future_ret', 'labels_cfg', 'n_down', 'n_up', 'neg', 'np', 'pd', 'per_side', 'pos', 'series', 'smooth', 'std', 'total_n', 'up_idx', 'valid', 'w', 'weights', 'window', 'x'],\n",
    "    notes=['Labeling mode controls how targets are constructed.', 'Labeling price space: log vs raw.', 'Market dataframe is the price source for labels/plots.', 'Oracle labels (targets) for training/eval.'],\n",
    ")\n",
    "\n",
    "# Balanced binary labeling based on future return\n",
    "# This creates an UP/DOWN target with roughly balanced classes.\n",
    "\n",
    "labels_cfg = cfg_labels['labels']\n",
    "HORIZON = int(labels_cfg.get('horizon', 1))\n",
    "TARGET_MOVE_SHARE = float(labels_cfg.get('target_move_share', 0.5))\n",
    "\n",
    "LABEL_MODE = 'balanced_future_return'  # 'balanced_future_return' or 'balanced_detrended'\n",
    "LABEL_PRICE_MODE = 'raw'  # 'raw' or 'log' for labeling space\n",
    "MOVE_SHARE_TOTAL = float(TARGET_MOVE_SHARE)  # total share of samples kept (split UP/DOWN)\n",
    "\n",
    "# Centered Gaussian smoothing for detrending (no lag)\n",
    "GAUSS_WINDOW = int(labels_cfg.get('gauss_window', 201))  # must be odd\n",
    "GAUSS_STD = float(labels_cfg.get('gauss_std', 50.0))\n",
    "\n",
    "\n",
    "def _gaussian_kernel(window: int, std: float) -> np.ndarray:\n",
    "    if window % 2 == 0:\n",
    "        raise ValueError('GAUSS_WINDOW must be odd')\n",
    "    x = np.arange(window) - window // 2\n",
    "    w = np.exp(-(x ** 2) / (2 * (std ** 2)))\n",
    "    w /= w.sum()\n",
    "    return w\n",
    "\n",
    "\n",
    "def _gaussian_smooth_centered(series: pd.Series, window: int, std: float) -> pd.Series:\n",
    "    weights = _gaussian_kernel(window, std)\n",
    "    # full window only to avoid edge bias; edges become NaN\n",
    "    return series.rolling(window=window, center=True, min_periods=window).apply(\n",
    "        lambda x: np.dot(x, weights), raw=True\n",
    "    )\n",
    "\n",
    "\n",
    "if LABEL_PRICE_MODE == 'log':\n",
    "    base_series = np.log(df_market['close']).astype(float)\n",
    "elif LABEL_PRICE_MODE == 'raw':\n",
    "    base_series = df_market['close'].astype(float)\n",
    "else:\n",
    "    raise ValueError(f'Unknown LABEL_PRICE_MODE={LABEL_PRICE_MODE}')\n",
    "\n",
    "if LABEL_MODE == 'balanced_detrended':\n",
    "    smooth = _gaussian_smooth_centered(base_series, GAUSS_WINDOW, GAUSS_STD)\n",
    "    base = base_series - smooth\n",
    "    future_ret = base.shift(-HORIZON) - base\n",
    "else:\n",
    "    # Plain future return in selected price space\n",
    "    future_ret = base_series.shift(-HORIZON) - base_series\n",
    "\n",
    "valid = future_ret.dropna()\n",
    "total_n = len(valid)\n",
    "if total_n == 0:\n",
    "    raise ValueError('No valid future returns for labeling')\n",
    "\n",
    "# Choose top-N UP and top-N DOWN by absolute size (balanced)\n",
    "per_side = max(1, int(total_n * MOVE_SHARE_TOTAL / 2))\n",
    "pos = valid[valid > 0]\n",
    "neg = valid[valid < 0]\n",
    "n_up = min(per_side, len(pos))\n",
    "n_down = min(per_side, len(neg))\n",
    "\n",
    "up_idx = pos.nlargest(n_up).index\n",
    "down_idx = neg.nsmallest(n_down).index  # most negative\n",
    "\n",
    "df_labels = df_market.copy()\n",
    "df_labels['target'] = np.nan\n",
    "df_labels.loc[up_idx, 'target'] = 1\n",
    "df_labels.loc[down_idx, 'target'] = 0\n",
    "\n",
    "df_labels = df_labels.dropna(subset=['target']).reset_index(drop=True)\n",
    "df_labels['target'] = df_labels['target'].astype(int)\n",
    "\n",
    "BINARY_TREND = True\n",
    "print(f'Label mode: {LABEL_MODE}, price_mode={LABEL_PRICE_MODE}, horizon={HORIZON}, move_share_total={MOVE_SHARE_TOTAL}')\n",
    "if LABEL_MODE == 'balanced_detrended':\n",
    "    print(f'Gaussian detrend: window={GAUSS_WINDOW}, std={GAUSS_STD}')\n",
    "print(df_labels[['date', 'close', 'target']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9cbc8fe73be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 8',\n",
    "    purpose='Class distribution (binary)',\n",
    "    used_vars=['colors', 'counts', 'df_labels', 'i', 'label_map', 'plt'],\n",
    "    notes=['Oracle labels (targets) for training/eval.'],\n",
    ")\n",
    "\n",
    "# Class distribution (binary)\n",
    "label_map = {0: 'DOWN', 1: 'UP'}\n",
    "counts = df_labels['target'].value_counts(normalize=True).sort_index() * 100\n",
    "colors = ['#d62728', '#2ca02c']\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar([label_map[i] for i in counts.index], counts.values, color=colors)\n",
    "plt.title('Class share (balanced labels)')\n",
    "plt.ylabel('%')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85c4466d1307c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 9',\n",
    "    purpose='Visual: price and centered Gaussian smoothing in labeling space',\n",
    "    used_vars=['GAUSS_STD', 'GAUSS_WINDOW', 'LABEL_MODE', 'LABEL_PRICE_MODE', '_gaussian_smooth_centered', 'ax', 'df_market', 'np', 'plt', 'price_series', 'smooth', 'y_label'],\n",
    "    notes=['Labeling mode controls how targets are constructed.', 'Labeling price space: log vs raw.', 'Market dataframe is the price source for labels/plots.'],\n",
    ")\n",
    "\n",
    "# Visual: price and centered Gaussian smoothing in labeling space\n",
    "if LABEL_PRICE_MODE == 'log':\n",
    "    price_series = np.log(df_market['close']).astype(float)\n",
    "    y_label = 'log(price)'\n",
    "else:\n",
    "    price_series = df_market['close'].astype(float)\n",
    "    y_label = 'price'\n",
    "\n",
    "smooth = None\n",
    "if LABEL_MODE == 'balanced_detrended':\n",
    "    smooth = _gaussian_smooth_centered(price_series, GAUSS_WINDOW, GAUSS_STD)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "ax.plot(df_market['date'], price_series, label='price', linewidth=0.8)\n",
    "if smooth is not None:\n",
    "    ax.plot(df_market['date'], smooth, label=f'Gauss(w={GAUSS_WINDOW}, std={GAUSS_STD})', linewidth=1.2)\n",
    "ax.set_title('Price and centered Gaussian smoothing in labeling space')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel(y_label)\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae5ed2f56a6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 10',\n",
    "    purpose='Future return distribution (labeling space)',\n",
    "    used_vars=['GAUSS_STD', 'GAUSS_WINDOW', 'HORIZON', 'LABEL_MODE', 'LABEL_PRICE_MODE', '_gaussian_smooth_centered', 'base', 'base_series', 'df_market', 'future_ret', 'np', 'plt', 'smooth'],\n",
    "    notes=['Labeling mode controls how targets are constructed.', 'Labeling price space: log vs raw.', 'Market dataframe is the price source for labels/plots.'],\n",
    ")\n",
    "\n",
    "# Future return distribution (labeling space)\n",
    "if LABEL_PRICE_MODE == 'log':\n",
    "    base_series = np.log(df_market['close']).astype(float)\n",
    "else:\n",
    "    base_series = df_market['close'].astype(float)\n",
    "\n",
    "if LABEL_MODE == 'balanced_detrended':\n",
    "    smooth = _gaussian_smooth_centered(base_series, GAUSS_WINDOW, GAUSS_STD)\n",
    "    base = base_series - smooth\n",
    "    future_ret = base.shift(-HORIZON) - base\n",
    "else:\n",
    "    future_ret = base_series.shift(-HORIZON) - base_series\n",
    "\n",
    "plt.figure(figsize=(7, 4))\n",
    "plt.hist(future_ret.dropna(), bins=80, color='tab:gray')\n",
    "plt.title('Future return distribution')\n",
    "plt.xlabel('future return')\n",
    "plt.ylabel('count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3e9c1d8303433",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 11',\n",
    "    purpose='Simple label plot (binary)',\n",
    "    used_vars=['PLOT_PRICE_MODE', 'ax', 'close', 'dates', 'df_labels', 'down_mask', 'labels', 'np', 'pd', 'plot_df', 'plt', 'shade_up_down', 'title', 'up_mask', 'y_label'],\n",
    "    notes=['Oracle labels (targets) for training/eval.'],\n",
    ")\n",
    "\n",
    "# Simple label plot (binary)\n",
    "plot_df = df_labels[['date', 'close', 'target']].copy()\n",
    "plot_df['date'] = pd.to_datetime(plot_df['date'])\n",
    "plot_df = plot_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "def shade_up_down(ax, dates, close, up_mask, down_mask, title: str, y_label: str):\n",
    "    ax.plot(dates, close, color='black', linewidth=1.2, label='BTC close')\n",
    "    ax.fill_between(dates, 0, 1, where=up_mask, transform=ax.get_xaxis_transform(),\n",
    "                   color='green', alpha=0.15, label='UP')\n",
    "    ax.fill_between(dates, 0, 1, where=down_mask, transform=ax.get_xaxis_transform(),\n",
    "                   color='red', alpha=0.15, label='DOWN')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "labels = plot_df['target'].to_numpy()\n",
    "up_mask = labels == 1\n",
    "down_mask = labels == 0\n",
    "\n",
    "dates = plot_df['date'].to_numpy()\n",
    "if PLOT_PRICE_MODE == 'log':\n",
    "    close = np.log(plot_df['close'].to_numpy())\n",
    "    y_label = 'log(price)'\n",
    "else:\n",
    "    close = plot_df['close'].to_numpy()\n",
    "    y_label = 'Close'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "shade_up_down(ax, dates, close, up_mask, down_mask, 'Balanced labels (UP/DOWN)', y_label)\n",
    "ax.set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c13841d4dbfb3",
   "metadata": {},
   "source": [
    "## 2. Target shift by horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9940e8dc4d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 13',\n",
    "    purpose='Target already includes horizon (future return), no additional shift needed',\n",
    "    used_vars=['df_labels', 'df_labels_shifted'],\n",
    "    notes=['Oracle labels (targets) for training/eval.'],\n",
    ")\n",
    "\n",
    "# Target already includes horizon (future return), no additional shift needed\n",
    "df_labels_shifted = df_labels.copy()\n",
    "df_labels_shifted = df_labels_shifted.dropna(subset=['target']).reset_index(drop=True)\n",
    "df_labels_shifted['target'] = df_labels_shifted['target'].astype(int)\n",
    "\n",
    "print(df_labels_shifted[['date', 'target']].tail())\n",
    "print(f'Rows after labeling: {len(df_labels_shifted)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7ba5cc6d75912",
   "metadata": {},
   "source": [
    "## 3. Astro data and astro features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3531212a28c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 15',\n",
    "    used_vars=['AstroSettings', '_ephe_path', '_resolve_path', 'a', 'aspects', 'aspects_path', 'aspects_rows', 'astro_cfg', 'b', 'bodies', 'bodies_path', 'bodies_rows', 'calculate_aspects', 'calculate_daily_bodies', 'center', 'cfg_astro', 'd', 'dates', 'datetime', 'df_aspects', 'df_bodies', 'df_market', 'pd', 'processed_dir', 'set_ephe_path', 'settings', 'subject', 'time_utc', 'tqdm'],\n",
    "    notes=['Uses astro config (bodies/aspects paths, ephemeris path, center).', 'Center controls geo vs helio coordinates for astro bodies/aspects.', 'Market dataframe is the price source for labels/plots.'],\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.astro.engine.settings import AstroSettings\n",
    "from src.astro.engine.calculator import set_ephe_path, calculate_daily_bodies\n",
    "from src.astro.engine.aspects import calculate_aspects\n",
    "from src.features.builder import build_features_daily\n",
    "\n",
    "# Astro settings\n",
    "astro_cfg = cfg_astro[\"astro\"]\n",
    "# Same path rules: resolve to PROJECT_ROOT\n",
    "_ephe_path = _resolve_path(astro_cfg[\"ephe_path\"])\n",
    "set_ephe_path(str(_ephe_path))\n",
    "\n",
    "settings = AstroSettings(\n",
    "    bodies_path=_resolve_path(astro_cfg[\"bodies_path\"]),\n",
    "    aspects_path=_resolve_path(astro_cfg[\"aspects_path\"]),\n",
    ")\n",
    "\n",
    "time_utc = datetime.strptime(astro_cfg[\"daily_time_utc\"], \"%H:%M:%S\").time()\n",
    "\n",
    "center = astro_cfg.get(\"center\", \"geo\")\n",
    "\n",
    "bodies_path = processed_dir / f\"{subject.subject_id}_astro_bodies.parquet\"\n",
    "aspects_path = processed_dir / f\"{subject.subject_id}_astro_aspects.parquet\"\n",
    "features_path = processed_dir / f\"{subject.subject_id}_features.parquet\"\n",
    "\n",
    "# Ignore astro cache, recompute\n",
    "print(\"Ignoring astro cache, recomputing...\")\n",
    "bodies_rows = []\n",
    "aspects_rows = []\n",
    "dates = pd.to_datetime(df_market[\"date\"]).dt.date\n",
    "\n",
    "for d in tqdm(dates, desc=\"astro days\"):\n",
    "    bodies = calculate_daily_bodies(d, time_utc, settings.bodies, center=center)\n",
    "    aspects = calculate_aspects(bodies, settings.aspects)\n",
    "\n",
    "    for b in bodies:\n",
    "        bodies_rows.append({\n",
    "            \"date\": b.date,\n",
    "            \"body\": b.body,\n",
    "            \"lon\": b.lon,\n",
    "            \"lat\": b.lat,\n",
    "            \"speed\": b.speed,\n",
    "            \"is_retro\": b.is_retro,\n",
    "            \"sign\": b.sign,\n",
    "            \"declination\": b.declination,\n",
    "        })\n",
    "\n",
    "    for a in aspects:\n",
    "        aspects_rows.append({\n",
    "            \"date\": a.date,\n",
    "            \"p1\": a.p1,\n",
    "            \"p2\": a.p2,\n",
    "            \"aspect\": a.aspect,\n",
    "            \"orb\": a.orb,\n",
    "            \"is_exact\": a.is_exact,\n",
    "            \"is_applying\": a.is_applying,\n",
    "        })\n",
    "\n",
    "df_bodies = pd.DataFrame(bodies_rows)\n",
    "df_aspects = pd.DataFrame(aspects_rows)\n",
    "\n",
    "bodies_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_bodies.to_parquet(bodies_path, index=False)\n",
    "df_aspects.to_parquet(aspects_path, index=False)\n",
    "print(f\"Saved bodies: {bodies_path}\")\n",
    "print(f\"Saved aspects: {aspects_path}\")\n",
    "\n",
    "print(df_bodies.head())\n",
    "print(df_aspects.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432416fd73dbd01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 16',\n",
    "    purpose='Build astro features',\n",
    "    used_vars=['build_features_daily', 'df_aspects', 'df_bodies', 'df_features', 'features_path'],\n",
    "    notes=['Feature matrix used for XGBoost training.'],\n",
    ")\n",
    "\n",
    "# Build astro features\n",
    "# Ignore features cache, recompute\n",
    "print(\"Ignoring features cache, recomputing...\")\n",
    "df_features = build_features_daily(df_bodies, df_aspects)\n",
    "df_features.to_parquet(features_path, index=False)\n",
    "print(f\"Saved features: {features_path}\")\n",
    "\n",
    "print(df_features.head())\n",
    "print(f\"Features: {df_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb56db552f4cf718",
   "metadata": {},
   "source": [
    "## 4. Merge features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db15a80c1fb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 18',\n",
    "    purpose='Merge by date',\n",
    "    used_vars=['df_dataset', 'df_features', 'df_labels_shifted', 'features', 'labels', 'pd'],\n",
    "    notes=['Feature matrix used for XGBoost training.'],\n",
    ")\n",
    "\n",
    "# Merge by date\n",
    "features = df_features.copy()\n",
    "features[\"date\"] = pd.to_datetime(features[\"date\"])\n",
    "\n",
    "labels = df_labels_shifted[[\"date\", \"target\"]].copy()\n",
    "labels[\"date\"] = pd.to_datetime(labels[\"date\"])\n",
    "\n",
    "# Date intersection only\n",
    "df_dataset = pd.merge(features, labels, on=\"date\", how=\"inner\")\n",
    "\n",
    "# Drop possible duplicates\n",
    "if df_dataset[\"date\"].duplicated().any():\n",
    "    df_dataset = df_dataset.drop_duplicates(subset=[\"date\"]).reset_index(drop=True)\n",
    "\n",
    "print(df_dataset.head())\n",
    "print(f\"Final dataset: {df_dataset.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248db262",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 19',\n",
    "    purpose='Feature inventory (readable table)',\n",
    "    used_vars=['c', 'df_dataset', 'display', 'feature_cols', 'feature_group', 'feature_type', 'info', 'missing_pct', 'name', 'pd', 'stats'],\n",
    ")\n",
    "\n",
    "# Feature inventory (readable table)\n",
    "feature_cols = [c for c in df_dataset.columns if c not in ['date', 'target']]\n",
    "\n",
    "def feature_group(name: str) -> str:\n",
    "    if name.startswith('transit_aspect_'):\n",
    "        return 'transit_aspect'\n",
    "    if name.startswith('aspect_'):\n",
    "        return 'aspect'\n",
    "    if '_' in name:\n",
    "        return name.split('_', 1)[0]\n",
    "    return 'other'\n",
    "\n",
    "def feature_type(name: str) -> str:\n",
    "    if '_' in name:\n",
    "        return name.split('_', 1)[1]\n",
    "    return ''\n",
    "\n",
    "info = pd.DataFrame({'feature': feature_cols})\n",
    "info['group'] = info['feature'].apply(feature_group)\n",
    "info['type'] = info['feature'].apply(feature_type)\n",
    "\n",
    "stats = df_dataset[feature_cols].describe().T[['mean', 'std', 'min', 'max']]\n",
    "missing_pct = df_dataset[feature_cols].isna().mean() * 100\n",
    "stats = stats.join(missing_pct.rename('missing_%'), how='left')\n",
    "\n",
    "info = info.merge(stats, left_on='feature', right_index=True, how='left')\n",
    "info = info.sort_values(['group', 'feature']).reset_index(drop=True)\n",
    "\n",
    "display(info.groupby('group').size().rename('count').to_frame())\n",
    "\n",
    "# Full feature list\n",
    "display(info.style.format({\n",
    "    'mean': '{:.6f}',\n",
    "    'std': '{:.6f}',\n",
    "    'min': '{:.6f}',\n",
    "    'max': '{:.6f}',\n",
    "    'missing_%': '{:.2f}'\n",
    "}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e747191f6c3acaa",
   "metadata": {},
   "source": [
    "## 5. Train/val/test split (time-based)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09ed5946652e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 21',\n",
    "    purpose='Time-based split without shuffling',\n",
    "    used_vars=['df_dataset', 'n', 'test_df', 'train_df', 'train_end', 'train_ratio', 'val_df', 'val_end', 'val_ratio'],\n",
    ")\n",
    "\n",
    "# Time-based split without shuffling\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "\n",
    "n = len(df_dataset)\n",
    "train_end = int(n * train_ratio)\n",
    "val_end = int(n * (train_ratio + val_ratio))\n",
    "\n",
    "train_df = df_dataset.iloc[:train_end].copy()\n",
    "val_df = df_dataset.iloc[train_end:val_end].copy()\n",
    "test_df = df_dataset.iloc[val_end:].copy()\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "print(f\"Train range: {train_df['date'].min().date()} -> {train_df['date'].max().date()}\")\n",
    "print(f\"Test range : {test_df['date'].min().date()} -> {test_df['date'].max().date()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc184fc481271",
   "metadata": {},
   "source": [
    "## 6. Prepare X/y matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd265ad590aa52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 23',\n",
    "    purpose='Feature list (astro only)',\n",
    "    used_vars=['X_test', 'X_train', 'X_val', 'c', 'df_dataset', 'feature_cols', 'np', 'test_df', 'train_df', 'val_df', 'y_test', 'y_train', 'y_val'],\n",
    ")\n",
    "\n",
    "# Feature list (astro only)\n",
    "feature_cols = [c for c in df_dataset.columns if c not in [\"date\", \"target\"]]\n",
    "\n",
    "X_train = train_df[feature_cols].to_numpy(dtype=np.float64)\n",
    "y_train = train_df[\"target\"].to_numpy(dtype=np.int32)\n",
    "\n",
    "X_val = val_df[feature_cols].to_numpy(dtype=np.float64)\n",
    "y_val = val_df[\"target\"].to_numpy(dtype=np.int32)\n",
    "\n",
    "X_test = test_df[feature_cols].to_numpy(dtype=np.float64)\n",
    "y_test = test_df[\"target\"].to_numpy(dtype=np.int32)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val  : {X_val.shape}, y_val  : {y_val.shape}\")\n",
    "print(f\"X_test : {X_test.shape}, y_test : {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee50f9c7cc7c1f",
   "metadata": {},
   "source": [
    "## 7. XGBoost training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847844c-bb2f-4066-acd4-f73ae4f92d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 25',\n",
    "    used_vars=['BINARY_TREND', 'TWO_STAGE', 'acc', 'accuracy_score', 'bal', 'calc_metrics', 'cfg_train', 'counts', 'device', 'e', 'f1_score', 'f1m', 'fallback_label', 'hi', 'idx', 'info', 'k', 'label_ids', 'lbl', 'lbls', 'lo', 'm', 'majority_label', 'matthews_corrcoef', 'mcc', 'n', 'n_boot', 'np', 'out', 'pred', 'recall_score', 'rng', 'samples', 'seed', 'train_cfg', 'use_cuda', 'vals', 'xgb', 'y_pred', 'y_true'],\n",
    ")\n",
    "\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    recall_score,\n",
    ")\n",
    "from src.models.xgb import XGBBaseline\n",
    "\n",
    "train_cfg = cfg_train.get(\"training\", {})\n",
    "TWO_STAGE = bool(train_cfg.get(\"two_stage\", True))\n",
    "if BINARY_TREND and TWO_STAGE:\n",
    "    print(\"Binary trend active -> forcing SINGLE_STAGE\")\n",
    "    TWO_STAGE = False\n",
    "\n",
    "# Check if this XGBoost build supports CUDA\n",
    "use_cuda = False\n",
    "try:\n",
    "    info = xgb.build_info()\n",
    "    use_cuda = bool(info.get(\"USE_CUDA\", False))\n",
    "    print(f\"XGBoost build_info USE_CUDA = {info.get('USE_CUDA', None)}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to read build_info:\", e)\n",
    "\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "print(f\"Using device={device}\")\n",
    "\n",
    "if BINARY_TREND:\n",
    "    label_names = [\"DOWN\", \"UP\"]\n",
    "    label_ids = [0, 1]\n",
    "else:\n",
    "    label_names = [\"DOWN\", \"SIDEWAYS\", \"UP\"]\n",
    "    label_ids = [0, 1, 2]\n",
    "N_CLASSES = len(label_ids)\n",
    "\n",
    "\n",
    "def majority_baseline_pred(y_true, lbls):\n",
    "    counts = [int((y_true == lbl).sum()) for lbl in lbls]\n",
    "    majority_label = lbls[int(np.argmax(counts))]\n",
    "    return np.full_like(y_true, majority_label)\n",
    "\n",
    "\n",
    "def prev_label_baseline_pred(y_true, fallback_label: int = 0):\n",
    "    if len(y_true) == 0:\n",
    "        return np.array([], dtype=y_true.dtype)\n",
    "    pred = np.roll(y_true, 1)\n",
    "    pred[0] = fallback_label\n",
    "    return pred\n",
    "\n",
    "\n",
    "def calc_metrics(y_true, y_pred, lbls):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal = recall_score(y_true, y_pred, labels=lbls, average=\"macro\", zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"bal_acc\": bal,\n",
    "        \"mcc\": mcc,\n",
    "        \"f1_macro\": f1m,\n",
    "        \"summary\": 0.5 * (bal + f1m),\n",
    "    }\n",
    "\n",
    "\n",
    "def bootstrap_metrics(y_true, y_pred, lbls, n_boot=200, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "    if n == 0:\n",
    "        return None\n",
    "    samples = {\"acc\": [], \"bal_acc\": [], \"mcc\": [], \"f1_macro\": [], \"summary\": []}\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        m = calc_metrics(y_true[idx], y_pred[idx], lbls)\n",
    "        for k in samples:\n",
    "            samples[k].append(m[k])\n",
    "    out = {}\n",
    "    for k, vals in samples.items():\n",
    "        lo, hi = np.percentile(vals, [2.5, 97.5])\n",
    "        out[k] = (float(lo), float(hi))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1216f761ad021",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 26',\n",
    "    used_vars=['BINARY_TREND', 'N_CLASSES', 'TWO_STAGE', 'XGBBaseline', 'X_test', 'X_test_dir', 'X_train', 'X_train_dir', 'X_val', 'X_val_dir', 'base_metrics', 'base_pred', 'bootstrap_metrics', 'calc_metrics', 'ci', 'classification_report', 'cm', 'cm_title', 'cnt', 'compute_sample_weight', 'confusion_matrix', 'counts', 'device', 'dir_names', 'dir_pred', 'dir_pred_full', 'dist_parts', 'feature_cols', 'hi', 'key', 'label_ids', 'label_names', 'lbl', 'lbls', 'lo', 'low_recall', 'majority_baseline_pred', 'mask_test_dir', 'mask_train_dir', 'mask_val_dir', 'metrics', 'model', 'model_dir', 'model_move', 'move_names', 'move_pred', 'n', 'name', 'names', 'np', 'overall_title', 'pct', 'plot_confusion', 'plt', 'prev_label_baseline_pred', 'prev_metrics', 'prev_pred', 'print_basic_metrics', 'print_ci', 'report_dict', 'report_str', 'sns', 'title', 'w_train', 'w_train_dir', 'w_train_move', 'w_val', 'w_val_dir', 'w_val_move', 'warn_margin', 'y_pred', 'y_test', 'y_test_dir', 'y_test_move', 'y_train', 'y_train_dir', 'y_train_move', 'y_true', 'y_val', 'y_val_dir', 'y_val_move'],\n",
    ")\n",
    "\n",
    "def print_ci(ci, key, name):\n",
    "    if ci is None:\n",
    "        return\n",
    "    lo, hi = ci[key]\n",
    "    print(f\"  {name} 95% CI: [{lo:.4f}, {hi:.4f}]\")\n",
    "\n",
    "\n",
    "def print_basic_metrics(y_true, y_pred, lbls, names, title: str) -> None:\n",
    "    print()\n",
    "    print(title)\n",
    "\n",
    "    metrics = calc_metrics(y_true, y_pred, lbls)\n",
    "    print(\"Accuracy:\", metrics[\"acc\"])\n",
    "    print(\"Balanced acc:\", metrics[\"bal_acc\"])\n",
    "    print(\"MCC:\", metrics[\"mcc\"])\n",
    "    print(\"F1 macro:\", metrics[\"f1_macro\"])\n",
    "    print(\"Summary score (avg bal_acc + f1_macro):\", metrics[\"summary\"])\n",
    "\n",
    "    counts = [int((y_true == lbl).sum()) for lbl in lbls]\n",
    "    n = len(y_true)\n",
    "    dist_parts = []\n",
    "    for lbl, name, cnt in zip(lbls, names, counts):\n",
    "        pct = 100.0 * cnt / n if n else 0.0\n",
    "        dist_parts.append(f\"{name}={cnt} ({pct:.1f}%)\")\n",
    "    print(\"Class distribution:\", \", \".join(dist_parts))\n",
    "\n",
    "    report_str = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=lbls,\n",
    "        target_names=names,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    report_dict = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=lbls,\n",
    "        target_names=names,\n",
    "        output_dict=True,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    print(\"Classification report:\")\n",
    "    print(report_str)\n",
    "\n",
    "    # Baseline 1: always predict majority class\n",
    "    base_pred = majority_baseline_pred(y_true, lbls)\n",
    "    base_metrics = calc_metrics(y_true, base_pred, lbls)\n",
    "    print(\n",
    "        f\"Majority baseline -> acc={base_metrics['acc']:.4f}, \"\n",
    "        f\"bal_acc={base_metrics['bal_acc']:.4f}, f1_macro={base_metrics['f1_macro']:.4f}, \"\n",
    "        f\"summary={base_metrics['summary']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Baseline 2: predict previous label (naive time baseline)\n",
    "    prev_pred = prev_label_baseline_pred(y_true, fallback_label=lbls[0])\n",
    "    prev_metrics = calc_metrics(y_true, prev_pred, lbls)\n",
    "    print(\n",
    "        f\"Prev-label baseline -> acc={prev_metrics['acc']:.4f}, \"\n",
    "        f\"bal_acc={prev_metrics['bal_acc']:.4f}, f1_macro={prev_metrics['f1_macro']:.4f}, \"\n",
    "        f\"summary={prev_metrics['summary']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Bootstrap CI for model metrics\n",
    "    ci = bootstrap_metrics(y_true, y_pred, lbls, n_boot=200, seed=42)\n",
    "    if ci is not None:\n",
    "        print(\"Model 95% bootstrap CI:\")\n",
    "        print_ci(ci, \"acc\", \"acc\")\n",
    "        print_ci(ci, \"bal_acc\", \"bal_acc\")\n",
    "        print_ci(ci, \"f1_macro\", \"f1_macro\")\n",
    "        print_ci(ci, \"summary\", \"summary\")\n",
    "\n",
    "    # Sanity warnings\n",
    "    warn_margin = 0.02\n",
    "    if metrics[\"acc\"] < max(base_metrics[\"acc\"], prev_metrics[\"acc\"]) + warn_margin:\n",
    "        print(\"WARNING: accuracy barely above naive baselines\")\n",
    "    if metrics[\"bal_acc\"] < max(base_metrics[\"bal_acc\"], prev_metrics[\"bal_acc\"]) + warn_margin:\n",
    "        print(\"WARNING: balanced accuracy barely above naive baselines\")\n",
    "    if metrics[\"f1_macro\"] < max(base_metrics[\"f1_macro\"], prev_metrics[\"f1_macro\"]) + warn_margin:\n",
    "        print(\"WARNING: macro F1 barely above naive baselines\")\n",
    "    if metrics[\"summary\"] < max(base_metrics[\"summary\"], prev_metrics[\"summary\"]) + warn_margin:\n",
    "        print(\"WARNING: summary score barely above naive baselines\")\n",
    "\n",
    "    low_recall = []\n",
    "    for name in names:\n",
    "        if name in report_dict and report_dict[name][\"recall\"] < 0.2:\n",
    "            low_recall.append(f\"{name} (recall={report_dict[name]['recall']:.2f})\")\n",
    "    if low_recall:\n",
    "        print(\"WARNING: low recall ->\", \", \".join(low_recall))\n",
    "\n",
    "    if len(counts) > 0 and min(counts) < 30:\n",
    "        print(\"WARNING: some classes have <30 samples; metrics may be unstable\")\n",
    "\n",
    "\n",
    "def plot_confusion(y_true, y_pred, lbls, names, title: str) -> None:\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=lbls)\n",
    "    plt.figure(figsize=(4.5, 3.8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=names,\n",
    "        yticklabels=names,\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if TWO_STAGE:\n",
    "    print(\"Training mode: TWO_STAGE (MOVE/NO_MOVE -> UP/DOWN)\")\n",
    "\n",
    "    # --- Stage 1: MOVE vs NO_MOVE ---\n",
    "    y_train_move = (y_train != 1).astype(np.int32)\n",
    "    y_val_move = (y_val != 1).astype(np.int32)\n",
    "    y_test_move = (y_test != 1).astype(np.int32)\n",
    "\n",
    "    w_train_move = compute_sample_weight(class_weight=\"balanced\", y=y_train_move)\n",
    "    w_val_move = compute_sample_weight(class_weight=\"balanced\", y=y_val_move)\n",
    "\n",
    "    model_move = XGBBaseline(\n",
    "        n_classes=2,\n",
    "        device=device,\n",
    "        random_state=42,\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "    )\n",
    "\n",
    "    model_move.fit(\n",
    "        X_train, y_train_move,\n",
    "        X_val=X_val, y_val=y_val_move,\n",
    "        feature_names=feature_cols,\n",
    "        sample_weight=w_train_move,\n",
    "        sample_weight_val=w_val_move,\n",
    "    )\n",
    "\n",
    "    # --- Stage 2: direction (UP vs DOWN) only on MOVE rows ---\n",
    "    mask_train_dir = y_train != 1\n",
    "    mask_val_dir = y_val != 1\n",
    "    mask_test_dir = y_test != 1\n",
    "\n",
    "    X_train_dir = X_train[mask_train_dir]\n",
    "    y_train_dir = (y_train[mask_train_dir] == 2).astype(np.int32)\n",
    "    X_val_dir = X_val[mask_val_dir]\n",
    "    y_val_dir = (y_val[mask_val_dir] == 2).astype(np.int32)\n",
    "\n",
    "    w_train_dir = compute_sample_weight(class_weight=\"balanced\", y=y_train_dir)\n",
    "    w_val_dir = compute_sample_weight(class_weight=\"balanced\", y=y_val_dir)\n",
    "\n",
    "    model_dir = XGBBaseline(\n",
    "        n_classes=2,\n",
    "        device=device,\n",
    "        random_state=42,\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "    )\n",
    "\n",
    "    model_dir.fit(\n",
    "        X_train_dir, y_train_dir,\n",
    "        X_val=X_val_dir, y_val=y_val_dir,\n",
    "        feature_names=feature_cols,\n",
    "        sample_weight=w_train_dir,\n",
    "        sample_weight_val=w_val_dir,\n",
    "    )\n",
    "\n",
    "    # --- Combine predictions to preserve the original sequence ---\n",
    "    move_pred = model_move.predict(X_test)\n",
    "    dir_pred_full = model_dir.predict(X_test)\n",
    "\n",
    "    # If MOVE then UP/DOWN else SIDEWAYS(1)\n",
    "    y_pred = np.where(move_pred == 1, np.where(dir_pred_full == 1, 2, 0), 1)\n",
    "else:\n",
    "    if BINARY_TREND:\n",
    "        print(\"Training mode: SINGLE_STAGE (binary)\")\n",
    "    else:\n",
    "        print(\"Training mode: SINGLE_STAGE (3 classes)\")\n",
    "\n",
    "    w_train = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "    w_val = compute_sample_weight(class_weight=\"balanced\", y=y_val)\n",
    "\n",
    "    model = XGBBaseline(\n",
    "        n_classes=N_CLASSES,\n",
    "        device=device,\n",
    "        random_state=42,\n",
    "        n_estimators=300,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        X_val=X_val, y_val=y_val,\n",
    "        feature_names=feature_cols,\n",
    "        sample_weight=w_train,\n",
    "        sample_weight_val=w_val,\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "# --- Metrics: overall 3-class ---\n",
    "overall_title = \"Overall (binary) metrics\" if BINARY_TREND else \"Overall (3-class) metrics\"\n",
    "print_basic_metrics(y_test, y_pred, label_ids, label_names, overall_title)\n",
    "cm_title = \"Confusion matrix (binary)\" if BINARY_TREND else \"Confusion matrix (3-class)\"\n",
    "plot_confusion(y_test, y_pred, label_ids, label_names, cm_title)\n",
    "\n",
    "if TWO_STAGE:\n",
    "    # Stage 1 metrics (MOVE vs NO_MOVE)\n",
    "    move_names = [\"NO_MOVE\", \"MOVE\"]\n",
    "    print_basic_metrics(y_test_move, move_pred, [0, 1], move_names, \"Stage 1 (MOVE vs NO_MOVE) metrics\")\n",
    "    plot_confusion(y_test_move, move_pred, [0, 1], move_names, \"Confusion matrix (MOVE vs NO_MOVE)\")\n",
    "\n",
    "    # Stage 2 metrics (UP vs DOWN) only on MOVE rows\n",
    "    if mask_test_dir.sum() > 0:\n",
    "        X_test_dir = X_test[mask_test_dir]\n",
    "        y_test_dir = (y_test[mask_test_dir] == 2).astype(np.int32)\n",
    "        dir_pred = model_dir.predict(X_test_dir)\n",
    "        dir_names = [\"DOWN\", \"UP\"]\n",
    "        print_basic_metrics(y_test_dir, dir_pred, [0, 1], dir_names, \"Stage 2 (UP vs DOWN) metrics\")\n",
    "        plot_confusion(y_test_dir, dir_pred, [0, 1], dir_names, \"Confusion matrix (UP vs DOWN)\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"Stage 2 metrics skipped: no MOVE samples in test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 27',\n",
    "    purpose='Plot BTC close with prediction background',\n",
    "    used_vars=['BINARY_TREND', 'PLOT_END', 'PLOT_LAST_N', 'PLOT_PRICE_MODE', 'PLOT_SCOPE', 'PLOT_START', 'PRED_DIR_MASK_MOVE', 'PRED_MODE', 'PRICE_COL', 'SHOW_TRUE', 'TWO_STAGE', 'X_plot', 'ax', 'axes', 'base_df', 'close', 'dates', 'df_dataset', 'df_market', 'dir_pred', 'dir_pred_plot', 'down_mask', 'down_mask_pred', 'down_mask_true', 'feature_cols', 'market_dates', 'model', 'model_dir', 'model_move', 'move_mask', 'move_pred_plot', 'np', 'pd', 'plot_df', 'plt', 'pred_3c_plot', 'preds_3c', 'shade_up_down', 'test_df', 'title', 'title_pred', 'train_df', 'true_labels', 'up_mask', 'up_mask_pred', 'up_mask_true', 'val_df', 'y_label'],\n",
    "    notes=['Market dataframe is the price source for labels/plots.'],\n",
    ")\n",
    "\n",
    "# Plot BTC close with prediction background\n",
    "# Green: UP, Red: DOWN, no color: SIDEWAYS\n",
    "\n",
    "# --- Plot options ---\n",
    "PLOT_SCOPE = \"test\"  # \"test\", \"val\", \"train\", \"full\"\n",
    "PLOT_START = None    # e.g. \"2023-01-01\"\n",
    "PLOT_END = None      # e.g. \"2024-01-01\"\n",
    "PLOT_LAST_N = 1400    # set None to disable\n",
    "PRED_MODE = \"dir_only\"  # \"three_class\" or \"dir_only\"\n",
    "PRED_DIR_MASK_MOVE = False  # if True, show dir preds only when MOVE predicted\n",
    "SHOW_TRUE = True           # second panel with true labels\n",
    "PRICE_COL = \"close\"\n",
    "\n",
    "# Select base dataframe\n",
    "if PLOT_SCOPE == \"full\":\n",
    "    base_df = df_dataset.copy()\n",
    "elif PLOT_SCOPE == \"train\":\n",
    "    base_df = train_df.copy()\n",
    "elif PLOT_SCOPE == \"val\":\n",
    "    base_df = val_df.copy()\n",
    "else:\n",
    "    base_df = test_df.copy()\n",
    "\n",
    "if PLOT_SCOPE != \"test\":\n",
    "    print(\"NOTE: PLOT_SCOPE is not test; this is in-sample visualization.\")\n",
    "\n",
    "base_df[\"date\"] = pd.to_datetime(base_df[\"date\"])\n",
    "\n",
    "# Compute predictions for chosen scope\n",
    "X_plot = base_df[feature_cols].to_numpy(dtype=np.float64)\n",
    "if TWO_STAGE:\n",
    "    move_pred_plot = model_move.predict(X_plot)\n",
    "    dir_pred_plot = model_dir.predict(X_plot)\n",
    "    pred_3c_plot = np.where(move_pred_plot == 1, np.where(dir_pred_plot == 1, 2, 0), 1)\n",
    "else:\n",
    "    move_pred_plot = np.full(len(base_df), np.nan)\n",
    "    dir_pred_plot = np.full(len(base_df), np.nan)\n",
    "    pred_3c_plot = model.predict(X_plot)\n",
    "\n",
    "plot_df = base_df[[\"date\", \"target\"]].copy()\n",
    "plot_df[\"pred_3c\"] = pred_3c_plot\n",
    "plot_df[\"pred_move\"] = move_pred_plot\n",
    "plot_df[\"pred_dir\"] = dir_pred_plot\n",
    "\n",
    "market_dates = df_market[[\"date\", PRICE_COL]].copy()\n",
    "market_dates[\"date\"] = pd.to_datetime(market_dates[\"date\"])\n",
    "\n",
    "plot_df = plot_df.merge(market_dates, on=\"date\", how=\"left\")\n",
    "plot_df = plot_df.dropna(subset=[PRICE_COL]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Apply date window\n",
    "if PLOT_START is not None:\n",
    "    plot_df = plot_df[plot_df[\"date\"] >= pd.to_datetime(PLOT_START)]\n",
    "if PLOT_END is not None:\n",
    "    plot_df = plot_df[plot_df[\"date\"] <= pd.to_datetime(PLOT_END)]\n",
    "if PLOT_LAST_N is not None and len(plot_df) > PLOT_LAST_N:\n",
    "    plot_df = plot_df.tail(PLOT_LAST_N)\n",
    "\n",
    "if plot_df.empty:\n",
    "    raise ValueError(\"Plot window is empty. Check PLOT_START/PLOT_END/PLOT_LAST_N\")\n",
    "\n",
    "# Helper to shade UP/DOWN zones\n",
    "\n",
    "def shade_up_down(ax, dates, close, up_mask, down_mask, title: str, y_label: str):\n",
    "    ax.plot(dates, close, color=\"black\", linewidth=1.2, label=\"BTC close\")\n",
    "    ax.fill_between(\n",
    "        dates,\n",
    "        0,\n",
    "        1,\n",
    "        where=up_mask,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        color=\"green\",\n",
    "        alpha=0.15,\n",
    "        label=\"UP\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        dates,\n",
    "        0,\n",
    "        1,\n",
    "        where=down_mask,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        color=\"red\",\n",
    "        alpha=0.15,\n",
    "        label=\"DOWN\",\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "# Choose prediction masks\n",
    "preds_3c = plot_df[\"pred_3c\"].to_numpy()\n",
    "if BINARY_TREND:\n",
    "    up_mask_pred = preds_3c == 1\n",
    "    down_mask_pred = preds_3c == 0\n",
    "    title_pred = \"Predicted binary (UP/DOWN shaded)\"\n",
    "elif PRED_MODE == \"dir_only\" and TWO_STAGE:\n",
    "    dir_pred = plot_df[\"pred_dir\"].to_numpy().astype(int)\n",
    "    if PRED_DIR_MASK_MOVE:\n",
    "        move_mask = plot_df[\"pred_move\"].to_numpy() == 1\n",
    "        up_mask_pred = (dir_pred == 1) & move_mask\n",
    "        down_mask_pred = (dir_pred == 0) & move_mask\n",
    "        title_pred = \"Predicted direction (dir model, MOVE only)\"\n",
    "    else:\n",
    "        up_mask_pred = dir_pred == 1\n",
    "        down_mask_pred = dir_pred == 0\n",
    "        title_pred = \"Predicted direction (dir model, all points)\"\n",
    "else:\n",
    "    up_mask_pred = preds_3c == 2\n",
    "    down_mask_pred = preds_3c == 0\n",
    "    title_pred = \"Predicted 3-class (UP/DOWN shaded)\"\n",
    "\n",
    "dates = plot_df[\"date\"].to_numpy()\n",
    "close = plot_df[PRICE_COL].to_numpy()\n",
    "if PLOT_PRICE_MODE == 'log':\n",
    "    close = np.log(close)\n",
    "    y_label = 'log(price)'\n",
    "else:\n",
    "    y_label = 'Close'\n",
    "\n",
    "if SHOW_TRUE:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 7), sharex=True)\n",
    "    shade_up_down(axes[0], dates, close, up_mask_pred, down_mask_pred, title_pred, y_label)\n",
    "\n",
    "    true_labels = plot_df[\"target\"].to_numpy()\n",
    "    if BINARY_TREND:\n",
    "        up_mask_true = true_labels == 1\n",
    "        down_mask_true = true_labels == 0\n",
    "    else:\n",
    "        up_mask_true = true_labels == 2\n",
    "        down_mask_true = true_labels == 0\n",
    "    shade_up_down(axes[1], dates, close, up_mask_true, down_mask_true, \"True labels (UP/DOWN shaded)\", y_label)\n",
    "\n",
    "    axes[1].set_xlabel(\"Date\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    shade_up_down(ax, dates, close, up_mask_pred, down_mask_pred, title_pred, y_label)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff00381dc9f34c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 28',\n",
    "    purpose='Confusion matrix',\n",
    "    used_vars=['BINARY_TREND', 'cm', 'confusion_matrix', 'labels', 'lbl_ids', 'plt', 'sns', 'y_pred', 'y_test'],\n",
    ")\n",
    "\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if BINARY_TREND:\n",
    "    labels = ['DOWN', 'UP']\n",
    "    lbl_ids = [0, 1]\n",
    "else:\n",
    "    labels = ['DOWN', 'SIDEWAYS', 'UP']\n",
    "    lbl_ids = [0, 1, 2]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=lbl_ids)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243188f193cdd910",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 29',\n",
    "    purpose='Feature importance (top 20)',\n",
    "    used_vars=['IMP_MODEL_STAGE', 'TWO_STAGE', 'feature_cols', 'imp_df', 'importances', 'model', 'model_dir', 'model_move', 'pd', 'plt', 'sns', 'stage_model', 'stage_models', 'stage_name'],\n",
    ")\n",
    "\n",
    "# Feature importance (top 20)\n",
    "# In two-stage mode you can plot one stage or both.\n",
    "IMP_MODEL_STAGE = \"dir\"  # \"dir\", \"move\", or \"both\"\n",
    "\n",
    "if TWO_STAGE:\n",
    "    if IMP_MODEL_STAGE == \"both\":\n",
    "        stage_models = [\n",
    "            (\"MOVE vs NO_MOVE\", model_move),\n",
    "            (\"UP vs DOWN\", model_dir),\n",
    "        ]\n",
    "    elif IMP_MODEL_STAGE == \"move\":\n",
    "        stage_models = [(\"MOVE vs NO_MOVE\", model_move)]\n",
    "    else:\n",
    "        stage_models = [(\"UP vs DOWN\", model_dir)]\n",
    "else:\n",
    "    stage_models = [(\"3-class\", model)]\n",
    "\n",
    "for stage_name, stage_model in stage_models:\n",
    "    importances = stage_model.model.feature_importances_\n",
    "    imp_df = pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"importance\": importances,\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(data=imp_df.head(20), x=\"importance\", y=\"feature\", color=\"tab:blue\")\n",
    "    plt.title(f\"Top-20 astro features by importance ({stage_name})\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf572e7ba9c6280d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 30',\n",
    "    purpose='Save model (optional)',\n",
    "    used_vars=['GAUSS_STD', 'GAUSS_WINDOW', 'HORIZON', 'LABEL_MODE', 'LABEL_PRICE_MODE', 'MOVE_SHARE_TOTAL', 'PROJECT_ROOT', 'TWO_STAGE', 'artifact', 'artifact_config', 'artifact_dir', 'dump', 'feature_cols', 'model', 'model_dir', 'model_move', 'out_path'],\n",
    "    notes=['Labeling mode controls how targets are constructed.', 'Labeling price space: log vs raw.'],\n",
    ")\n",
    "\n",
    "# Save model (optional)\n",
    "from joblib import dump\n",
    "\n",
    "artifact_dir = PROJECT_ROOT / \"models_artifacts\"\n",
    "artifact_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "artifact_config = {\n",
    "    \"label_mode\": LABEL_MODE,\n",
    "    \"label_price_mode\": LABEL_PRICE_MODE,\n",
    "    \"move_share_total\": MOVE_SHARE_TOTAL,\n",
    "    \"gauss_window\": GAUSS_WINDOW,\n",
    "    \"gauss_std\": GAUSS_STD,\n",
    "    \"horizon\": HORIZON,\n",
    "}\n",
    "\n",
    "if TWO_STAGE:\n",
    "    artifact = {\n",
    "        \"mode\": \"two_stage\",\n",
    "        \"move\": {\n",
    "            \"model\": model_move.model,\n",
    "            \"scaler\": model_move.scaler,\n",
    "        },\n",
    "        \"dir\": {\n",
    "            \"model\": model_dir.model,\n",
    "            \"scaler\": model_dir.scaler,\n",
    "        },\n",
    "        \"feature_names\": feature_cols,\n",
    "        \"config\": artifact_config,\n",
    "    }\n",
    "    out_path = artifact_dir / f\"xgb_astro_balanced_two_stage_h{HORIZON}.joblib\"\n",
    "else:\n",
    "    artifact = {\n",
    "        \"mode\": \"single_stage\",\n",
    "        \"model\": model.model,\n",
    "        \"scaler\": model.scaler,\n",
    "        \"feature_names\": feature_cols,\n",
    "        \"config\": artifact_config,\n",
    "    }\n",
    "    out_path = artifact_dir / f\"xgb_astro_balanced_h{HORIZON}.joblib\"\n",
    "\n",
    "dump(artifact, out_path)\n",
    "print(f\"Saved: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d50cd5e9c91440",
   "metadata": {},
   "source": [
    "## 8. Ideas for improvement\n",
    "\n",
    "- Pick sigma/threshold based on model metrics, not only class balance.\n",
    "- Add transit-to-natal aspects as extra features.\n",
    "- Use separate models for different market regimes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab9b36-ce9b-43bf-bd9a-0807f487445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_cell(\n",
    "    title='Cell 32',\n",
    "    used_vars=[],\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}