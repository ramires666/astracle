{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0ec2c20dcd7cdb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Astro pipeline: target variable and XGBoost (BTC)\n",
    "\n",
    "This notebook shows the full cycle:\n",
    "1) load quotes (daily)\n",
    "2) build target variable (oracle labels)\n",
    "3) compute astro data and build astro features\n",
    "4) train and evaluate XGBoost.\n",
    "\n",
    "Important: features are astro-only; price is used only for targets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0db0239534a72ec",
   "metadata": {},
   "source": [
    "## 0. Environment setup\n",
    "\n",
    "If some packages are missing, install via conda-forge (in active env):\n",
    "\n",
    "```\n",
    "conda install -c conda-forge xgboost scikit-learn matplotlib seaborn tqdm pyarrow jupyterlab\n",
    "```\n",
    "\n",
    "Also check:\n",
    "- `configs/astro.yaml` -> `ephe_path` (path to Swiss Ephemeris)\n",
    "- `configs/subjects.yaml` -> `active_subject_id` and subject birth date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5052dce34d77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dependencies (stop notebook if missing)\n",
    "import importlib.util as iu\n",
    "\n",
    "required = [\"xgboost\", \"sklearn\", \"matplotlib\", \"seaborn\", \"tqdm\", \"pyarrow\"]\n",
    "missing = [pkg for pkg in required if iu.find_spec(pkg) is None]\n",
    "\n",
    "if missing:\n",
    "    print(\"Missing packages:\", \", \".join(missing))\n",
    "    print(\"Install them with:\")\n",
    "    print(\"conda install -c conda-forge xgboost scikit-learn matplotlib seaborn tqdm pyarrow jupyterlab\")\n",
    "    raise SystemExit(\"Stopped: install dependencies and rerun\")\n",
    "\n",
    "print(\"OK: all core dependencies found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e67268d6aa58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base imports and environment setup\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visual style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 4)\n",
    "\n",
    "# Table display settings\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n",
    "# Project root search (look for configs/market.yaml)\n",
    "PROJECT_ROOT = Path.cwd().resolve()\n",
    "if not (PROJECT_ROOT / \"configs/market.yaml\").exists():\n",
    "    for parent in PROJECT_ROOT.parents:\n",
    "        if (parent / \"configs/market.yaml\").exists():\n",
    "            PROJECT_ROOT = parent\n",
    "            break\n",
    "\n",
    "if not (PROJECT_ROOT / \"configs/market.yaml\").exists():\n",
    "    raise FileNotFoundError(\"Project root not found: configs/market.yaml\")\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"PROJECT_ROOT = {PROJECT_ROOT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d63f18bcb70dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configs and market data (from Postgres)\n",
    "from src.common.config import load_yaml, load_subjects\n",
    "from src.db.connection import psql_connection\n",
    "\n",
    "cfg_market = load_yaml(PROJECT_ROOT / \"configs/market.yaml\")\n",
    "cfg_astro = load_yaml(PROJECT_ROOT / \"configs/astro.yaml\")\n",
    "cfg_labels = load_yaml(PROJECT_ROOT / \"configs/labels.yaml\")\n",
    "cfg_db = load_yaml(PROJECT_ROOT / \"configs/db.yaml\")\n",
    "cfg_train = load_yaml(PROJECT_ROOT / \"configs/training.yaml\")\n",
    "\n",
    "subjects, active_id = load_subjects(PROJECT_ROOT / \"configs/subjects.yaml\")\n",
    "subject = subjects[active_id]\n",
    "\n",
    "market_cfg = cfg_market[\"market\"]\n",
    "\n",
    "# NOTE: if path is relative, resolve from PROJECT_ROOT\n",
    "def _resolve_path(value: str | Path) -> Path:\n",
    "    path = Path(value)\n",
    "    if path.is_absolute():\n",
    "        return path\n",
    "    return (PROJECT_ROOT / path).resolve()\n",
    "\n",
    "data_root = _resolve_path(market_cfg[\"data_root\"])\n",
    "processed_dir = data_root / \"processed\"\n",
    "reports_dir = data_root / \"reports\"\n",
    "reports_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Active subject: {subject.subject_id}\")\n",
    "print(f\"Data root: {data_root}\")\n",
    "\n",
    "# Market source: Postgres only\n",
    "if \"db\" not in cfg_db or \"url\" not in cfg_db[\"db\"]:\n",
    "    raise KeyError(\"configs/db.yaml must define db.url\")\n",
    "\n",
    "db_url = cfg_db[\"db\"][\"url\"]\n",
    "\n",
    "# Load market_daily from DB\n",
    "with psql_connection(db_url) as conn:\n",
    "    df_market = pd.read_sql_query(\n",
    "        \"SELECT date, close FROM market_daily WHERE subject_id = %s ORDER BY date\",\n",
    "        conn,\n",
    "        params=(subject.subject_id,),\n",
    "    )\n",
    "\n",
    "if df_market.empty:\n",
    "    raise ValueError(\n",
    "        f\"No market data for subject_id={subject.subject_id}. \"\n",
    "        \"Load market_daily into Postgres first.\"\n",
    "    )\n",
    "\n",
    "if \"date\" not in df_market.columns or \"close\" not in df_market.columns:\n",
    "    raise ValueError(\"market_daily must have date and close columns\")\n",
    "\n",
    "df_market[\"date\"] = pd.to_datetime(df_market[\"date\"])\n",
    "print(df_market.head())\n",
    "print(f\"Market range: {df_market['date'].min().date()} -> {df_market['date'].max().date()}\")\n",
    "print(f\"Rows: {len(df_market)}\")\n",
    "\n",
    "# Plot price mode (optional override)\n",
    "NB_PLOT_PRICE_MODE = None  # 'log' or 'raw'\n",
    "PLOT_PRICE_MODE = str(NB_PLOT_PRICE_MODE or cfg_labels['labels'].get('price_mode', 'log')).lower()\n",
    "if PLOT_PRICE_MODE not in {'log', 'raw'}:\n",
    "    print(f\"[WARN] Unknown PLOT_PRICE_MODE={PLOT_PRICE_MODE}, fallback to 'log'\")\n",
    "    PLOT_PRICE_MODE = 'log'\n",
    "print(f\"PLOT_PRICE_MODE = {PLOT_PRICE_MODE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536de49616520110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick look at price and daily change distribution\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 6), sharex=False)\n",
    "\n",
    "price_series = np.log(df_market['close']) if PLOT_PRICE_MODE == 'log' else df_market['close']\n",
    "price_label = 'log(close)' if PLOT_PRICE_MODE == 'log' else 'close'\n",
    "\n",
    "ax[0].plot(df_market['date'], price_series, color='tab:blue', linewidth=1)\n",
    "ax[0].set_title('BTC close (daily)')\n",
    "ax[0].set_xlabel('Date')\n",
    "ax[0].set_ylabel(price_label)\n",
    "\n",
    "# Log returns for a rough distribution check\n",
    "log_ret = np.log(df_market['close']).diff().dropna()\n",
    "ax[1].hist(log_ret, bins=80, color='tab:gray')\n",
    "ax[1].set_title('Daily log return distribution')\n",
    "ax[1].set_xlabel('log_return')\n",
    "ax[1].set_ylabel('frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794e7131b28eb523",
   "metadata": {},
   "source": [
    "## 1. Oracle labels (target variable)\n",
    "\n",
    "Idea: smooth log price, take slope, classify by threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0560a518668735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.labeling.oracle import (\n",
    "    create_oracle_labels,\n",
    "    analyze_label_distribution,\n",
    "    estimate_threshold_for_move_balance,\n",
    ")\n",
    "\n",
    "labels_cfg = cfg_labels[\"labels\"]\n",
    "SIGMA = int(labels_cfg.get(\"sigma\", 3))\n",
    "THRESHOLD = float(labels_cfg.get(\"threshold\", 0.0005))\n",
    "THRESHOLD_MODE = str(labels_cfg.get(\"threshold_mode\", \"fixed\")).strip().lower()\n",
    "TARGET_MOVE_SHARE = float(labels_cfg.get(\"target_move_share\", 0.5))\n",
    "THRESHOLD_MIN = labels_cfg.get(\"threshold_min\", 0.0)\n",
    "if THRESHOLD_MIN is None:\n",
    "    THRESHOLD_MIN = 0.0\n",
    "THRESHOLD_MIN = float(THRESHOLD_MIN)\n",
    "THRESHOLD_MAX = labels_cfg.get(\"threshold_max\", None)\n",
    "if THRESHOLD_MAX is not None:\n",
    "    THRESHOLD_MAX = float(THRESHOLD_MAX)\n",
    "HORIZON = int(labels_cfg.get(\"horizon\", 1))\n",
    "PRICE_MODE = str(labels_cfg.get(\"price_mode\", \"log\")).lower()\n",
    "AUTO_GRID_SELECT = bool(labels_cfg.get(\"auto_grid_select\", True))\n",
    "BINARY_TREND = bool(labels_cfg.get(\"binary_trend\", False))\n",
    "BINARY_FALLBACK = str(labels_cfg.get(\"binary_fallback\", \"up\"))\n",
    "\n",
    "# Notebook overrides (optional)\n",
    "# SIDEWAYS share + MOVE share = 1.0, so MOVE share = 1 - SIDEWAYS.\n",
    "SIDEWAYS_SHARE_TARGET = 0.33  # set to None to use config target_move_share\n",
    "NB_THRESHOLD = None  # set float to force fixed threshold\n",
    "NB_THRESHOLD_MODE = None  # \"auto\" or \"fixed\" to override config\n",
    "\n",
    "if NB_THRESHOLD_MODE is not None:\n",
    "    THRESHOLD_MODE = str(NB_THRESHOLD_MODE).strip().lower()\n",
    "if SIDEWAYS_SHARE_TARGET is not None:\n",
    "    TARGET_MOVE_SHARE = 1.0 - float(SIDEWAYS_SHARE_TARGET)\n",
    "if NB_THRESHOLD is not None:\n",
    "    THRESHOLD = float(NB_THRESHOLD)\n",
    "    THRESHOLD_MODE = \"fixed\"\n",
    "\n",
    "if THRESHOLD_MODE == \"auto\":\n",
    "    THRESHOLD = estimate_threshold_for_move_balance(\n",
    "        df_market,\n",
    "        sigma=SIGMA,\n",
    "        price_col=\"close\",\n",
    "        price_mode=PRICE_MODE,\n",
    "        target_move_share=TARGET_MOVE_SHARE,\n",
    "        min_threshold=THRESHOLD_MIN,\n",
    "        max_threshold=THRESHOLD_MAX,\n",
    "    )\n",
    "    print(f\"Auto threshold={THRESHOLD:.8f} (target_move_share={TARGET_MOVE_SHARE:.2f})\")\n",
    "\n",
    "print(\n",
    "    f\"Label params: sigma={SIGMA}, threshold={THRESHOLD}, \"\n",
    "    f\"horizon={HORIZON}, price_mode={PRICE_MODE}, threshold_mode={THRESHOLD_MODE}, \"\n",
    "    f\"target_move_share={TARGET_MOVE_SHARE:.2f}\"\n",
    ")\n",
    "print(f\"Label mode: {'binary' if BINARY_TREND else '3-class'}\")\n",
    "\n",
    "df_labels = create_oracle_labels(\n",
    "    df_market,\n",
    "    sigma=SIGMA,\n",
    "    threshold=THRESHOLD,\n",
    "    price_col=\"close\",\n",
    "    price_mode=PRICE_MODE,\n",
    "    binary_trend=BINARY_TREND,\n",
    "    binary_fallback=BINARY_FALLBACK,\n",
    ")\n",
    "\n",
    "label_3_col = \"target_3\" if BINARY_TREND else \"target\"\n",
    "move_share = (df_labels[label_3_col] != 1).mean()\n",
    "sideways_share = (df_labels[label_3_col] == 1).mean()\n",
    "print(f\"MOVE share: {move_share*100:.1f}%, SIDEWAYS share: {sideways_share*100:.1f}%\")\n",
    "\n",
    "# Quick visual: threshold -> SIDEWAYS share\n",
    "PLOT_THRESHOLD_SWEEP = True\n",
    "SWEEP_STEPS = 25\n",
    "SWEEP_FACTOR = 0.5  # +/-50% around current threshold\n",
    "if PLOT_THRESHOLD_SWEEP:\n",
    "    thr_min = max(THRESHOLD * (1.0 - SWEEP_FACTOR), 1e-10)\n",
    "    thr_max = THRESHOLD * (1.0 + SWEEP_FACTOR) if THRESHOLD > 0 else 1e-3\n",
    "    thresholds = np.linspace(thr_min, thr_max, SWEEP_STEPS)\n",
    "    sideways_vals = []\n",
    "    for t in thresholds:\n",
    "        tmp = create_oracle_labels(\n",
    "            df_market,\n",
    "            sigma=SIGMA,\n",
    "            threshold=float(t),\n",
    "            price_col=\"close\",\n",
    "            price_mode=PRICE_MODE,\n",
    "            binary_trend=BINARY_TREND,\n",
    "            binary_fallback=BINARY_FALLBACK,\n",
    "        )\n",
    "        tmp_label_col = \"target_3\" if BINARY_TREND else \"target\"\n",
    "        sideways_vals.append((tmp[tmp_label_col] == 1).mean())\n",
    "\n",
    "    target_sideways = (\n",
    "        float(SIDEWAYS_SHARE_TARGET)\n",
    "        if SIDEWAYS_SHARE_TARGET is not None\n",
    "        else 1.0 - float(TARGET_MOVE_SHARE)\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.plot(thresholds, sideways_vals, marker=\".\")\n",
    "    plt.axvline(THRESHOLD, color=\"orange\", linestyle=\"--\", label=\"current threshold\")\n",
    "    if target_sideways is not None:\n",
    "        plt.axhline(target_sideways, color=\"red\", linestyle=\":\", label=\"target sideways\")\n",
    "    plt.title(\"Threshold vs SIDEWAYS share\")\n",
    "    plt.xlabel(\"threshold\")\n",
    "    plt.ylabel(\"sideways share\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "cols = [\"date\", \"close\", \"smoothed_close\", \"smooth_slope\", \"target\"]\n",
    "if BINARY_TREND:\n",
    "    cols.append(\"target_3\")\n",
    "print(df_labels[cols].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f9cbc8fe73be93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "if BINARY_TREND:\n",
    "    label_map = {0: \"DOWN\", 1: \"UP\"}\n",
    "    counts = df_labels[\"target\"].value_counts(normalize=True).sort_index() * 100\n",
    "    colors = [\"#d62728\", \"#2ca02c\"]\n",
    "else:\n",
    "    label_map = {0: \"DOWN\", 1: \"SIDEWAYS\", 2: \"UP\"}\n",
    "    counts = df_labels[\"target\"].value_counts(normalize=True).sort_index() * 100\n",
    "    colors = [\"#d62728\", \"#7f7f7f\", \"#2ca02c\"]\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.bar([label_map[i] for i in counts.index], counts.values, color=colors)\n",
    "plt.title(\"Class share (oracle)\")\n",
    "plt.ylabel(\"%\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d85c4466d1307c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual: price vs smoothed price\n",
    "if PLOT_PRICE_MODE == 'log':\n",
    "    close_series = np.log(df_labels['close'])\n",
    "    smoothed_series = np.log(df_labels['smoothed_close'])\n",
    "    ylabel = 'log(price)'\n",
    "    title = 'Log close and log-smoothed line (oracle)'\n",
    "else:\n",
    "    close_series = df_labels['close']\n",
    "    smoothed_series = df_labels['smoothed_close']\n",
    "    ylabel = 'Price'\n",
    "    title = 'Close and smoothed line (oracle)'\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "ax.plot(df_labels['date'], close_series, label='close', linewidth=0.8)\n",
    "ax.plot(df_labels['date'], smoothed_series, label='smoothed', linewidth=1.5)\n",
    "ax.set_title(title)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel(ylabel)\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae5ed2f56a6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Auto-tune sigma/threshold (minimize DOWN vs UP imbalance)\n",
    "# Also support auto-threshold (move share target)\n",
    "\n",
    "if AUTO_GRID_SELECT:\n",
    "    sigma_min = max(2, SIGMA - 2)\n",
    "    sigma_max = SIGMA + 2\n",
    "\n",
    "    if THRESHOLD_MODE == \"auto\":\n",
    "        sigmas = np.unique(np.linspace(sigma_min, sigma_max, 5, dtype=int))\n",
    "        rows = []\n",
    "        for s in sigmas:\n",
    "            thr = estimate_threshold_for_move_balance(\n",
    "                df_market,\n",
    "                sigma=int(s),\n",
    "                price_col=\"close\",\n",
    "                price_mode=PRICE_MODE,\n",
    "                target_move_share=TARGET_MOVE_SHARE,\n",
    "                min_threshold=THRESHOLD_MIN,\n",
    "                max_threshold=THRESHOLD_MAX,\n",
    "            )\n",
    "            labeled = create_oracle_labels(\n",
    "                df_market,\n",
    "                sigma=int(s),\n",
    "                threshold=float(thr),\n",
    "                price_col=\"close\",\n",
    "                price_mode=PRICE_MODE,\n",
    "                binary_trend=BINARY_TREND,\n",
    "                binary_fallback=BINARY_FALLBACK,\n",
    "            )\n",
    "            label_col = \"target_3\" if BINARY_TREND else \"target\"\n",
    "            counts = labeled[label_col].value_counts(normalize=True)\n",
    "            rows.append({\n",
    "                \"sigma\": int(s),\n",
    "                \"threshold\": float(thr),\n",
    "                \"down_pct\": counts.get(0, 0) * 100,\n",
    "                \"sideways_pct\": counts.get(1, 0) * 100,\n",
    "                \"up_pct\": counts.get(2, 0) * 100,\n",
    "                \"imbalance\": abs(counts.get(0, 0) - counts.get(2, 0)) * 100,\n",
    "            })\n",
    "        grid = pd.DataFrame(rows).sort_values(\"imbalance\")\n",
    "    else:\n",
    "        thr_min = max(THRESHOLD * 0.5, 1e-6)\n",
    "        thr_max = THRESHOLD * 1.5 if THRESHOLD > 0 else 1e-3\n",
    "        grid = analyze_label_distribution(\n",
    "            df_market,\n",
    "            sigma_range=(sigma_min, sigma_max),\n",
    "            threshold_range=(thr_min, thr_max),\n",
    "            n_steps=5,\n",
    "            price_mode=PRICE_MODE,\n",
    "            price_col=\"close\",\n",
    "        )\n",
    "\n",
    "    best = grid.iloc[0]\n",
    "    SIGMA = int(best[\"sigma\"])\n",
    "    THRESHOLD = float(best[\"threshold\"])\n",
    "    print(f\"Auto-grid: sigma={SIGMA}, threshold={THRESHOLD:.8f} (imbalance={best['imbalance']:.2f}%)\")\n",
    "\n",
    "    df_labels = create_oracle_labels(\n",
    "        df_market,\n",
    "        sigma=SIGMA,\n",
    "        threshold=THRESHOLD,\n",
    "        price_col=\"close\",\n",
    "        price_mode=PRICE_MODE,\n",
    "        binary_trend=BINARY_TREND,\n",
    "        binary_fallback=BINARY_FALLBACK,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3e9c1d8303433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple oracle label plot (matplotlib)\n",
    "plot_df = df_labels[['date', 'close', 'target']].copy()\n",
    "plot_df['date'] = pd.to_datetime(plot_df['date'])\n",
    "plot_df = plot_df.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "def shade_up_down(ax, dates, close, up_mask, down_mask, title: str, y_label: str):\n",
    "    ax.plot(dates, close, color='black', linewidth=1.2, label='BTC close')\n",
    "    ax.fill_between(\n",
    "        dates,\n",
    "        0,\n",
    "        1,\n",
    "        where=up_mask,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        color='green',\n",
    "        alpha=0.15,\n",
    "        label='UP',\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        dates,\n",
    "        0,\n",
    "        1,\n",
    "        where=down_mask,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        color='red',\n",
    "        alpha=0.15,\n",
    "        label='DOWN',\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend(loc='upper left')\n",
    "\n",
    "labels = plot_df['target'].to_numpy()\n",
    "if BINARY_TREND:\n",
    "    up_mask = labels == 1\n",
    "    down_mask = labels == 0\n",
    "    title = 'Oracle labels (binary: UP/DOWN)'\n",
    "else:\n",
    "    up_mask = labels == 2\n",
    "    down_mask = labels == 0\n",
    "    title = 'Oracle labels (3-class: UP/DOWN shaded)'\n",
    "\n",
    "dates = plot_df['date'].to_numpy()\n",
    "if PLOT_PRICE_MODE == 'log':\n",
    "    close = np.log(plot_df['close'].to_numpy())\n",
    "    y_label = 'log(price)'\n",
    "else:\n",
    "    close = plot_df['close'].to_numpy()\n",
    "    y_label = 'Close'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "shade_up_down(ax, dates, close, up_mask, down_mask, title, y_label)\n",
    "ax.set_xlabel('Date')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c13841d4dbfb3",
   "metadata": {},
   "source": [
    "## 2. Target shift by horizon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa9940e8dc4d8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift target to the future (features(t) -> target(t+horizon))\n",
    "df_labels_shifted = df_labels.copy()\n",
    "df_labels_shifted[\"target\"] = df_labels_shifted[\"target\"].shift(-HORIZON)\n",
    "\n",
    "# Drop rows without future label\n",
    "df_labels_shifted = df_labels_shifted.dropna(subset=[\"target\"]).reset_index(drop=True)\n",
    "df_labels_shifted[\"target\"] = df_labels_shifted[\"target\"].astype(int)\n",
    "\n",
    "print(df_labels_shifted[[\"date\", \"target\"]].tail())\n",
    "print(f\"Rows after shift: {len(df_labels_shifted)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7ba5cc6d75912",
   "metadata": {},
   "source": [
    "## 3. Astro data and astro features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3531212a28c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.astro.engine.settings import AstroSettings\n",
    "from src.astro.engine.calculator import set_ephe_path, calculate_daily_bodies\n",
    "from src.astro.engine.aspects import calculate_aspects\n",
    "from src.features.builder import build_features_daily\n",
    "\n",
    "# Astro settings\n",
    "astro_cfg = cfg_astro[\"astro\"]\n",
    "# Same path rules: resolve to PROJECT_ROOT\n",
    "_ephe_path = _resolve_path(astro_cfg[\"ephe_path\"])\n",
    "set_ephe_path(str(_ephe_path))\n",
    "\n",
    "settings = AstroSettings(\n",
    "    bodies_path=_resolve_path(astro_cfg[\"bodies_path\"]),\n",
    "    aspects_path=_resolve_path(astro_cfg[\"aspects_path\"]),\n",
    ")\n",
    "\n",
    "time_utc = datetime.strptime(astro_cfg[\"daily_time_utc\"], \"%H:%M:%S\").time()\n",
    "\n",
    "bodies_path = processed_dir / f\"{subject.subject_id}_astro_bodies.parquet\"\n",
    "aspects_path = processed_dir / f\"{subject.subject_id}_astro_aspects.parquet\"\n",
    "features_path = processed_dir / f\"{subject.subject_id}_features.parquet\"\n",
    "\n",
    "# Ignore astro cache, recompute\n",
    "print(\"Ignoring astro cache, recomputing...\")\n",
    "bodies_rows = []\n",
    "aspects_rows = []\n",
    "dates = pd.to_datetime(df_market[\"date\"]).dt.date\n",
    "\n",
    "for d in tqdm(dates, desc=\"astro days\"):\n",
    "    bodies = calculate_daily_bodies(d, time_utc, settings.bodies)\n",
    "    aspects = calculate_aspects(bodies, settings.aspects)\n",
    "\n",
    "    for b in bodies:\n",
    "        bodies_rows.append({\n",
    "            \"date\": b.date,\n",
    "            \"body\": b.body,\n",
    "            \"lon\": b.lon,\n",
    "            \"lat\": b.lat,\n",
    "            \"speed\": b.speed,\n",
    "            \"is_retro\": b.is_retro,\n",
    "            \"sign\": b.sign,\n",
    "            \"declination\": b.declination,\n",
    "        })\n",
    "\n",
    "    for a in aspects:\n",
    "        aspects_rows.append({\n",
    "            \"date\": a.date,\n",
    "            \"p1\": a.p1,\n",
    "            \"p2\": a.p2,\n",
    "            \"aspect\": a.aspect,\n",
    "            \"orb\": a.orb,\n",
    "            \"is_exact\": a.is_exact,\n",
    "            \"is_applying\": a.is_applying,\n",
    "        })\n",
    "\n",
    "df_bodies = pd.DataFrame(bodies_rows)\n",
    "df_aspects = pd.DataFrame(aspects_rows)\n",
    "\n",
    "bodies_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df_bodies.to_parquet(bodies_path, index=False)\n",
    "df_aspects.to_parquet(aspects_path, index=False)\n",
    "print(f\"Saved bodies: {bodies_path}\")\n",
    "print(f\"Saved aspects: {aspects_path}\")\n",
    "\n",
    "print(df_bodies.head())\n",
    "print(df_aspects.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432416fd73dbd01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build astro features\n",
    "# Ignore features cache, recompute\n",
    "print(\"Ignoring features cache, recomputing...\")\n",
    "df_features = build_features_daily(df_bodies, df_aspects)\n",
    "df_features.to_parquet(features_path, index=False)\n",
    "print(f\"Saved features: {features_path}\")\n",
    "\n",
    "print(df_features.head())\n",
    "print(f\"Features: {df_features.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb56db552f4cf718",
   "metadata": {},
   "source": [
    "## 4. Merge features and target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db15a80c1fb41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge by date\n",
    "features = df_features.copy()\n",
    "features[\"date\"] = pd.to_datetime(features[\"date\"])\n",
    "\n",
    "labels = df_labels_shifted[[\"date\", \"target\"]].copy()\n",
    "labels[\"date\"] = pd.to_datetime(labels[\"date\"])\n",
    "\n",
    "# Date intersection only\n",
    "df_dataset = pd.merge(features, labels, on=\"date\", how=\"inner\")\n",
    "\n",
    "# Drop possible duplicates\n",
    "if df_dataset[\"date\"].duplicated().any():\n",
    "    df_dataset = df_dataset.drop_duplicates(subset=[\"date\"]).reset_index(drop=True)\n",
    "\n",
    "print(df_dataset.head())\n",
    "print(f\"Final dataset: {df_dataset.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e747191f6c3acaa",
   "metadata": {},
   "source": [
    "## 5. Train/val/test split (time-based)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09ed5946652e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based split without shuffling\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.15\n",
    "\n",
    "n = len(df_dataset)\n",
    "train_end = int(n * train_ratio)\n",
    "val_end = int(n * (train_ratio + val_ratio))\n",
    "\n",
    "train_df = df_dataset.iloc[:train_end].copy()\n",
    "val_df = df_dataset.iloc[train_end:val_end].copy()\n",
    "test_df = df_dataset.iloc[val_end:].copy()\n",
    "\n",
    "print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
    "print(f\"Train range: {train_df['date'].min().date()} -> {train_df['date'].max().date()}\")\n",
    "print(f\"Test range : {test_df['date'].min().date()} -> {test_df['date'].max().date()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cc184fc481271",
   "metadata": {},
   "source": [
    "## 6. Prepare X/y matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd265ad590aa52c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature list (astro only)\n",
    "feature_cols = [c for c in df_dataset.columns if c not in [\"date\", \"target\"]]\n",
    "\n",
    "X_train = train_df[feature_cols].to_numpy(dtype=np.float64)\n",
    "y_train = train_df[\"target\"].to_numpy(dtype=np.int32)\n",
    "\n",
    "X_val = val_df[feature_cols].to_numpy(dtype=np.float64)\n",
    "y_val = val_df[\"target\"].to_numpy(dtype=np.int32)\n",
    "\n",
    "X_test = test_df[feature_cols].to_numpy(dtype=np.float64)\n",
    "y_test = test_df[\"target\"].to_numpy(dtype=np.int32)\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val  : {X_val.shape}, y_val  : {y_val.shape}\")\n",
    "print(f\"X_test : {X_test.shape}, y_test : {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee50f9c7cc7c1f",
   "metadata": {},
   "source": [
    "## 7. XGBoost training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8847844c-bb2f-4066-acd4-f73ae4f92d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    balanced_accuracy_score,\n",
    "    matthews_corrcoef,\n",
    "    recall_score,\n",
    ")\n",
    "from src.models.xgb import XGBBaseline\n",
    "\n",
    "train_cfg = cfg_train.get(\"training\", {})\n",
    "TWO_STAGE = bool(train_cfg.get(\"two_stage\", True))\n",
    "if BINARY_TREND and TWO_STAGE:\n",
    "    print(\"Binary trend active -> forcing SINGLE_STAGE\")\n",
    "    TWO_STAGE = False\n",
    "\n",
    "# Check if this XGBoost build supports CUDA\n",
    "use_cuda = False\n",
    "try:\n",
    "    info = xgb.build_info()\n",
    "    use_cuda = bool(info.get(\"USE_CUDA\", False))\n",
    "    print(f\"XGBoost build_info USE_CUDA = {info.get('USE_CUDA', None)}\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to read build_info:\", e)\n",
    "\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "print(f\"Using device={device}\")\n",
    "\n",
    "if BINARY_TREND:\n",
    "    label_names = [\"DOWN\", \"UP\"]\n",
    "    label_ids = [0, 1]\n",
    "else:\n",
    "    label_names = [\"DOWN\", \"SIDEWAYS\", \"UP\"]\n",
    "    label_ids = [0, 1, 2]\n",
    "N_CLASSES = len(label_ids)\n",
    "\n",
    "\n",
    "def majority_baseline_pred(y_true, lbls):\n",
    "    counts = [int((y_true == lbl).sum()) for lbl in lbls]\n",
    "    majority_label = lbls[int(np.argmax(counts))]\n",
    "    return np.full_like(y_true, majority_label)\n",
    "\n",
    "\n",
    "def prev_label_baseline_pred(y_true, fallback_label: int = 0):\n",
    "    if len(y_true) == 0:\n",
    "        return np.array([], dtype=y_true.dtype)\n",
    "    pred = np.roll(y_true, 1)\n",
    "    pred[0] = fallback_label\n",
    "    return pred\n",
    "\n",
    "\n",
    "def calc_metrics(y_true, y_pred, lbls):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    bal = recall_score(y_true, y_pred, labels=lbls, average=\"macro\", zero_division=0)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    f1m = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    return {\n",
    "        \"acc\": acc,\n",
    "        \"bal_acc\": bal,\n",
    "        \"mcc\": mcc,\n",
    "        \"f1_macro\": f1m,\n",
    "        \"summary\": 0.5 * (bal + f1m),\n",
    "    }\n",
    "\n",
    "\n",
    "def bootstrap_metrics(y_true, y_pred, lbls, n_boot=200, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "    if n == 0:\n",
    "        return None\n",
    "    samples = {\"acc\": [], \"bal_acc\": [], \"mcc\": [], \"f1_macro\": [], \"summary\": []}\n",
    "    for _ in range(n_boot):\n",
    "        idx = rng.integers(0, n, size=n)\n",
    "        m = calc_metrics(y_true[idx], y_pred[idx], lbls)\n",
    "        for k in samples:\n",
    "            samples[k].append(m[k])\n",
    "    out = {}\n",
    "    for k, vals in samples.items():\n",
    "        lo, hi = np.percentile(vals, [2.5, 97.5])\n",
    "        out[k] = (float(lo), float(hi))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae1216f761ad021",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_ci(ci, key, name):\n",
    "    if ci is None:\n",
    "        return\n",
    "    lo, hi = ci[key]\n",
    "    print(f\"  {name} 95% CI: [{lo:.4f}, {hi:.4f}]\")\n",
    "\n",
    "\n",
    "def print_basic_metrics(y_true, y_pred, lbls, names, title: str) -> None:\n",
    "    print()\n",
    "    print(title)\n",
    "\n",
    "    metrics = calc_metrics(y_true, y_pred, lbls)\n",
    "    print(\"Accuracy:\", metrics[\"acc\"])\n",
    "    print(\"Balanced acc:\", metrics[\"bal_acc\"])\n",
    "    print(\"MCC:\", metrics[\"mcc\"])\n",
    "    print(\"F1 macro:\", metrics[\"f1_macro\"])\n",
    "    print(\"Summary score (avg bal_acc + f1_macro):\", metrics[\"summary\"])\n",
    "\n",
    "    counts = [int((y_true == lbl).sum()) for lbl in lbls]\n",
    "    n = len(y_true)\n",
    "    dist_parts = []\n",
    "    for lbl, name, cnt in zip(lbls, names, counts):\n",
    "        pct = 100.0 * cnt / n if n else 0.0\n",
    "        dist_parts.append(f\"{name}={cnt} ({pct:.1f}%)\")\n",
    "    print(\"Class distribution:\", \", \".join(dist_parts))\n",
    "\n",
    "    report_str = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=lbls,\n",
    "        target_names=names,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    report_dict = classification_report(\n",
    "        y_true,\n",
    "        y_pred,\n",
    "        labels=lbls,\n",
    "        target_names=names,\n",
    "        output_dict=True,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    print(\"Classification report:\")\n",
    "    print(report_str)\n",
    "\n",
    "    # Baseline 1: always predict majority class\n",
    "    base_pred = majority_baseline_pred(y_true, lbls)\n",
    "    base_metrics = calc_metrics(y_true, base_pred, lbls)\n",
    "    print(\n",
    "        f\"Majority baseline -> acc={base_metrics['acc']:.4f}, \"\n",
    "        f\"bal_acc={base_metrics['bal_acc']:.4f}, f1_macro={base_metrics['f1_macro']:.4f}, \"\n",
    "        f\"summary={base_metrics['summary']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Baseline 2: predict previous label (naive time baseline)\n",
    "    prev_pred = prev_label_baseline_pred(y_true, fallback_label=lbls[0])\n",
    "    prev_metrics = calc_metrics(y_true, prev_pred, lbls)\n",
    "    print(\n",
    "        f\"Prev-label baseline -> acc={prev_metrics['acc']:.4f}, \"\n",
    "        f\"bal_acc={prev_metrics['bal_acc']:.4f}, f1_macro={prev_metrics['f1_macro']:.4f}, \"\n",
    "        f\"summary={prev_metrics['summary']:.4f}\"\n",
    "    )\n",
    "\n",
    "    # Bootstrap CI for model metrics\n",
    "    ci = bootstrap_metrics(y_true, y_pred, lbls, n_boot=200, seed=42)\n",
    "    if ci is not None:\n",
    "        print(\"Model 95% bootstrap CI:\")\n",
    "        print_ci(ci, \"acc\", \"acc\")\n",
    "        print_ci(ci, \"bal_acc\", \"bal_acc\")\n",
    "        print_ci(ci, \"f1_macro\", \"f1_macro\")\n",
    "        print_ci(ci, \"summary\", \"summary\")\n",
    "\n",
    "    # Sanity warnings\n",
    "    warn_margin = 0.02\n",
    "    if metrics[\"acc\"] < max(base_metrics[\"acc\"], prev_metrics[\"acc\"]) + warn_margin:\n",
    "        print(\"WARNING: accuracy barely above naive baselines\")\n",
    "    if metrics[\"bal_acc\"] < max(base_metrics[\"bal_acc\"], prev_metrics[\"bal_acc\"]) + warn_margin:\n",
    "        print(\"WARNING: balanced accuracy barely above naive baselines\")\n",
    "    if metrics[\"f1_macro\"] < max(base_metrics[\"f1_macro\"], prev_metrics[\"f1_macro\"]) + warn_margin:\n",
    "        print(\"WARNING: macro F1 barely above naive baselines\")\n",
    "    if metrics[\"summary\"] < max(base_metrics[\"summary\"], prev_metrics[\"summary\"]) + warn_margin:\n",
    "        print(\"WARNING: summary score barely above naive baselines\")\n",
    "\n",
    "    low_recall = []\n",
    "    for name in names:\n",
    "        if name in report_dict and report_dict[name][\"recall\"] < 0.2:\n",
    "            low_recall.append(f\"{name} (recall={report_dict[name]['recall']:.2f})\")\n",
    "    if low_recall:\n",
    "        print(\"WARNING: low recall ->\", \", \".join(low_recall))\n",
    "\n",
    "    if len(counts) > 0 and min(counts) < 30:\n",
    "        print(\"WARNING: some classes have <30 samples; metrics may be unstable\")\n",
    "\n",
    "\n",
    "def plot_confusion(y_true, y_pred, lbls, names, title: str) -> None:\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=lbls)\n",
    "    plt.figure(figsize=(4.5, 3.8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=names,\n",
    "        yticklabels=names,\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if TWO_STAGE:\n",
    "    print(\"Training mode: TWO_STAGE (MOVE/NO_MOVE -> UP/DOWN)\")\n",
    "\n",
    "    # --- Stage 1: MOVE vs NO_MOVE ---\n",
    "    y_train_move = (y_train != 1).astype(np.int32)\n",
    "    y_val_move = (y_val != 1).astype(np.int32)\n",
    "    y_test_move = (y_test != 1).astype(np.int32)\n",
    "\n",
    "    w_train_move = compute_sample_weight(class_weight=\"balanced\", y=y_train_move)\n",
    "    w_val_move = compute_sample_weight(class_weight=\"balanced\", y=y_val_move)\n",
    "\n",
    "    model_move = XGBBaseline(\n",
    "        n_classes=2,\n",
    "        device=device,\n",
    "        random_state=42,\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "    )\n",
    "\n",
    "    model_move.fit(\n",
    "        X_train, y_train_move,\n",
    "        X_val=X_val, y_val=y_val_move,\n",
    "        feature_names=feature_cols,\n",
    "        sample_weight=w_train_move,\n",
    "        sample_weight_val=w_val_move,\n",
    "    )\n",
    "\n",
    "    # --- Stage 2: direction (UP vs DOWN) only on MOVE rows ---\n",
    "    mask_train_dir = y_train != 1\n",
    "    mask_val_dir = y_val != 1\n",
    "    mask_test_dir = y_test != 1\n",
    "\n",
    "    X_train_dir = X_train[mask_train_dir]\n",
    "    y_train_dir = (y_train[mask_train_dir] == 2).astype(np.int32)\n",
    "    X_val_dir = X_val[mask_val_dir]\n",
    "    y_val_dir = (y_val[mask_val_dir] == 2).astype(np.int32)\n",
    "\n",
    "    w_train_dir = compute_sample_weight(class_weight=\"balanced\", y=y_train_dir)\n",
    "    w_val_dir = compute_sample_weight(class_weight=\"balanced\", y=y_val_dir)\n",
    "\n",
    "    model_dir = XGBBaseline(\n",
    "        n_classes=2,\n",
    "        device=device,\n",
    "        random_state=42,\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "    )\n",
    "\n",
    "    model_dir.fit(\n",
    "        X_train_dir, y_train_dir,\n",
    "        X_val=X_val_dir, y_val=y_val_dir,\n",
    "        feature_names=feature_cols,\n",
    "        sample_weight=w_train_dir,\n",
    "        sample_weight_val=w_val_dir,\n",
    "    )\n",
    "\n",
    "    # --- Combine predictions to preserve the original sequence ---\n",
    "    move_pred = model_move.predict(X_test)\n",
    "    dir_pred_full = model_dir.predict(X_test)\n",
    "\n",
    "    # If MOVE then UP/DOWN else SIDEWAYS(1)\n",
    "    y_pred = np.where(move_pred == 1, np.where(dir_pred_full == 1, 2, 0), 1)\n",
    "else:\n",
    "    if BINARY_TREND:\n",
    "        print(\"Training mode: SINGLE_STAGE (binary)\")\n",
    "    else:\n",
    "        print(\"Training mode: SINGLE_STAGE (3 classes)\")\n",
    "\n",
    "    w_train = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "    w_val = compute_sample_weight(class_weight=\"balanced\", y=y_val)\n",
    "\n",
    "    model = XGBBaseline(\n",
    "        n_classes=N_CLASSES,\n",
    "        device=device,\n",
    "        random_state=42,\n",
    "        n_estimators=300,\n",
    "        max_depth=3,\n",
    "        learning_rate=0.01,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        tree_method=\"hist\",\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        X_val=X_val, y_val=y_val,\n",
    "        feature_names=feature_cols,\n",
    "        sample_weight=w_train,\n",
    "        sample_weight_val=w_val,\n",
    "    )\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "# --- Metrics: overall 3-class ---\n",
    "overall_title = \"Overall (binary) metrics\" if BINARY_TREND else \"Overall (3-class) metrics\"\n",
    "print_basic_metrics(y_test, y_pred, label_ids, label_names, overall_title)\n",
    "cm_title = \"Confusion matrix (binary)\" if BINARY_TREND else \"Confusion matrix (3-class)\"\n",
    "plot_confusion(y_test, y_pred, label_ids, label_names, cm_title)\n",
    "\n",
    "if TWO_STAGE:\n",
    "    # Stage 1 metrics (MOVE vs NO_MOVE)\n",
    "    move_names = [\"NO_MOVE\", \"MOVE\"]\n",
    "    print_basic_metrics(y_test_move, move_pred, [0, 1], move_names, \"Stage 1 (MOVE vs NO_MOVE) metrics\")\n",
    "    plot_confusion(y_test_move, move_pred, [0, 1], move_names, \"Confusion matrix (MOVE vs NO_MOVE)\")\n",
    "\n",
    "    # Stage 2 metrics (UP vs DOWN) only on MOVE rows\n",
    "    if mask_test_dir.sum() > 0:\n",
    "        X_test_dir = X_test[mask_test_dir]\n",
    "        y_test_dir = (y_test[mask_test_dir] == 2).astype(np.int32)\n",
    "        dir_pred = model_dir.predict(X_test_dir)\n",
    "        dir_names = [\"DOWN\", \"UP\"]\n",
    "        print_basic_metrics(y_test_dir, dir_pred, [0, 1], dir_names, \"Stage 2 (UP vs DOWN) metrics\")\n",
    "        plot_confusion(y_test_dir, dir_pred, [0, 1], dir_names, \"Confusion matrix (UP vs DOWN)\")\n",
    "    else:\n",
    "        print()\n",
    "        print(\"Stage 2 metrics skipped: no MOVE samples in test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot BTC close with prediction background\n",
    "# Green: UP, Red: DOWN, no color: SIDEWAYS\n",
    "\n",
    "# --- Plot options ---\n",
    "PLOT_SCOPE = \"test\"  # \"test\", \"val\", \"train\", \"full\"\n",
    "PLOT_START = None    # e.g. \"2023-01-01\"\n",
    "PLOT_END = None      # e.g. \"2024-01-01\"\n",
    "PLOT_LAST_N = 1400    # set None to disable\n",
    "PRED_MODE = \"dir_only\"  # \"three_class\" or \"dir_only\"\n",
    "PRED_DIR_MASK_MOVE = False  # if True, show dir preds only when MOVE predicted\n",
    "SHOW_TRUE = True           # second panel with true labels\n",
    "PRICE_COL = \"close\"\n",
    "\n",
    "# Select base dataframe\n",
    "if PLOT_SCOPE == \"full\":\n",
    "    base_df = df_dataset.copy()\n",
    "elif PLOT_SCOPE == \"train\":\n",
    "    base_df = train_df.copy()\n",
    "elif PLOT_SCOPE == \"val\":\n",
    "    base_df = val_df.copy()\n",
    "else:\n",
    "    base_df = test_df.copy()\n",
    "\n",
    "if PLOT_SCOPE != \"test\":\n",
    "    print(\"NOTE: PLOT_SCOPE is not test; this is in-sample visualization.\")\n",
    "\n",
    "base_df[\"date\"] = pd.to_datetime(base_df[\"date\"])\n",
    "\n",
    "# Compute predictions for chosen scope\n",
    "X_plot = base_df[feature_cols].to_numpy(dtype=np.float64)\n",
    "if TWO_STAGE:\n",
    "    move_pred_plot = model_move.predict(X_plot)\n",
    "    dir_pred_plot = model_dir.predict(X_plot)\n",
    "    pred_3c_plot = np.where(move_pred_plot == 1, np.where(dir_pred_plot == 1, 2, 0), 1)\n",
    "else:\n",
    "    move_pred_plot = np.full(len(base_df), np.nan)\n",
    "    dir_pred_plot = np.full(len(base_df), np.nan)\n",
    "    pred_3c_plot = model.predict(X_plot)\n",
    "\n",
    "plot_df = base_df[[\"date\", \"target\"]].copy()\n",
    "plot_df[\"pred_3c\"] = pred_3c_plot\n",
    "plot_df[\"pred_move\"] = move_pred_plot\n",
    "plot_df[\"pred_dir\"] = dir_pred_plot\n",
    "\n",
    "market_dates = df_market[[\"date\", PRICE_COL]].copy()\n",
    "market_dates[\"date\"] = pd.to_datetime(market_dates[\"date\"])\n",
    "\n",
    "plot_df = plot_df.merge(market_dates, on=\"date\", how=\"left\")\n",
    "plot_df = plot_df.dropna(subset=[PRICE_COL]).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# Apply date window\n",
    "if PLOT_START is not None:\n",
    "    plot_df = plot_df[plot_df[\"date\"] >= pd.to_datetime(PLOT_START)]\n",
    "if PLOT_END is not None:\n",
    "    plot_df = plot_df[plot_df[\"date\"] <= pd.to_datetime(PLOT_END)]\n",
    "if PLOT_LAST_N is not None and len(plot_df) > PLOT_LAST_N:\n",
    "    plot_df = plot_df.tail(PLOT_LAST_N)\n",
    "\n",
    "if plot_df.empty:\n",
    "    raise ValueError(\"Plot window is empty. Check PLOT_START/PLOT_END/PLOT_LAST_N\")\n",
    "\n",
    "# Helper to shade UP/DOWN zones\n",
    "\n",
    "def shade_up_down(ax, dates, close, up_mask, down_mask, title: str, y_label: str):\n",
    "    ax.plot(dates, close, color=\"black\", linewidth=1.2, label=\"BTC close\")\n",
    "    ax.fill_between(\n",
    "        dates,\n",
    "        0,\n",
    "        1,\n",
    "        where=up_mask,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        color=\"green\",\n",
    "        alpha=0.15,\n",
    "        label=\"UP\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        dates,\n",
    "        0,\n",
    "        1,\n",
    "        where=down_mask,\n",
    "        transform=ax.get_xaxis_transform(),\n",
    "        color=\"red\",\n",
    "        alpha=0.15,\n",
    "        label=\"DOWN\",\n",
    "    )\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.legend(loc=\"upper left\")\n",
    "\n",
    "# Choose prediction masks\n",
    "preds_3c = plot_df[\"pred_3c\"].to_numpy()\n",
    "if BINARY_TREND:\n",
    "    up_mask_pred = preds_3c == 1\n",
    "    down_mask_pred = preds_3c == 0\n",
    "    title_pred = \"Predicted binary (UP/DOWN shaded)\"\n",
    "elif PRED_MODE == \"dir_only\" and TWO_STAGE:\n",
    "    dir_pred = plot_df[\"pred_dir\"].to_numpy().astype(int)\n",
    "    if PRED_DIR_MASK_MOVE:\n",
    "        move_mask = plot_df[\"pred_move\"].to_numpy() == 1\n",
    "        up_mask_pred = (dir_pred == 1) & move_mask\n",
    "        down_mask_pred = (dir_pred == 0) & move_mask\n",
    "        title_pred = \"Predicted direction (dir model, MOVE only)\"\n",
    "    else:\n",
    "        up_mask_pred = dir_pred == 1\n",
    "        down_mask_pred = dir_pred == 0\n",
    "        title_pred = \"Predicted direction (dir model, all points)\"\n",
    "else:\n",
    "    up_mask_pred = preds_3c == 2\n",
    "    down_mask_pred = preds_3c == 0\n",
    "    title_pred = \"Predicted 3-class (UP/DOWN shaded)\"\n",
    "\n",
    "dates = plot_df[\"date\"].to_numpy()\n",
    "close = plot_df[PRICE_COL].to_numpy()\n",
    "if PLOT_PRICE_MODE == 'log':\n",
    "    close = np.log(close)\n",
    "    y_label = 'log(price)'\n",
    "else:\n",
    "    y_label = 'Close'\n",
    "\n",
    "if SHOW_TRUE:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 7), sharex=True)\n",
    "    shade_up_down(axes[0], dates, close, up_mask_pred, down_mask_pred, title_pred, y_label)\n",
    "\n",
    "    true_labels = plot_df[\"target\"].to_numpy()\n",
    "    if BINARY_TREND:\n",
    "        up_mask_true = true_labels == 1\n",
    "        down_mask_true = true_labels == 0\n",
    "    else:\n",
    "        up_mask_true = true_labels == 2\n",
    "        down_mask_true = true_labels == 0\n",
    "    shade_up_down(axes[1], dates, close, up_mask_true, down_mask_true, \"True labels (UP/DOWN shaded)\", y_label)\n",
    "\n",
    "    axes[1].set_xlabel(\"Date\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    shade_up_down(ax, dates, close, up_mask_pred, down_mask_pred, title_pred, y_label)\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aff00381dc9f34c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "if BINARY_TREND:\n",
    "    labels = ['DOWN', 'UP']\n",
    "    lbl_ids = [0, 1]\n",
    "else:\n",
    "    labels = ['DOWN', 'SIDEWAYS', 'UP']\n",
    "    lbl_ids = [0, 1, 2]\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=lbl_ids)\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243188f193cdd910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (top 20)\n",
    "# In two-stage mode you can plot one stage or both.\n",
    "IMP_MODEL_STAGE = \"dir\"  # \"dir\", \"move\", or \"both\"\n",
    "\n",
    "if TWO_STAGE:\n",
    "    if IMP_MODEL_STAGE == \"both\":\n",
    "        stage_models = [\n",
    "            (\"MOVE vs NO_MOVE\", model_move),\n",
    "            (\"UP vs DOWN\", model_dir),\n",
    "        ]\n",
    "    elif IMP_MODEL_STAGE == \"move\":\n",
    "        stage_models = [(\"MOVE vs NO_MOVE\", model_move)]\n",
    "    else:\n",
    "        stage_models = [(\"UP vs DOWN\", model_dir)]\n",
    "else:\n",
    "    stage_models = [(\"3-class\", model)]\n",
    "\n",
    "for stage_name, stage_model in stage_models:\n",
    "    importances = stage_model.model.feature_importances_\n",
    "    imp_df = pd.DataFrame({\n",
    "        \"feature\": feature_cols,\n",
    "        \"importance\": importances,\n",
    "    }).sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(data=imp_df.head(20), x=\"importance\", y=\"feature\", color=\"tab:blue\")\n",
    "    plt.title(f\"Top-20 astro features by importance ({stage_name})\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf572e7ba9c6280d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Save model (optional)\n",
    "from joblib import dump\n",
    "\n",
    "artifact_dir = PROJECT_ROOT / \"models_artifacts\"\n",
    "artifact_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if TWO_STAGE:\n",
    "    artifact = {\n",
    "        \"mode\": \"two_stage\",\n",
    "        \"move\": {\n",
    "            \"model\": model_move.model,\n",
    "            \"scaler\": model_move.scaler,\n",
    "        },\n",
    "        \"dir\": {\n",
    "            \"model\": model_dir.model,\n",
    "            \"scaler\": model_dir.scaler,\n",
    "        },\n",
    "        \"feature_names\": feature_cols,\n",
    "        \"config\": {\n",
    "            \"sigma\": SIGMA,\n",
    "            \"threshold\": THRESHOLD,\n",
    "            \"horizon\": HORIZON,\n",
    "        },\n",
    "    }\n",
    "    out_path = artifact_dir / f\"xgb_astro_baseline_two_stage_h{HORIZON}.joblib\"\n",
    "else:\n",
    "    artifact = {\n",
    "        \"mode\": \"single_stage\",\n",
    "        \"model\": model.model,\n",
    "        \"scaler\": model.scaler,\n",
    "        \"feature_names\": feature_cols,\n",
    "        \"config\": {\n",
    "            \"sigma\": SIGMA,\n",
    "            \"threshold\": THRESHOLD,\n",
    "            \"horizon\": HORIZON,\n",
    "        },\n",
    "    }\n",
    "    out_path = artifact_dir / f\"xgb_astro_baseline_h{HORIZON}.joblib\"\n",
    "\n",
    "dump(artifact, out_path)\n",
    "print(f\"Saved: {out_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d50cd5e9c91440",
   "metadata": {},
   "source": [
    "## 8. Ideas for improvement\n",
    "\n",
    "- Pick sigma/threshold based on model metrics, not only class balance.\n",
    "- Add transit-to-natal aspects as extra features.\n",
    "- Use separate models for different market regimes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cab9b36-ce9b-43bf-bd9a-0807f487445f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}