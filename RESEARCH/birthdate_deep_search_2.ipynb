{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # üß† Deep Grid Search 2.0: Astro + Model Tuning\n",
    "\n",
    "\n",
    "\n",
    " –¶–µ–ª—å: –ù–∞–π—Ç–∏ –∫–æ–º–±–∏–Ω–∞—Ü–∏—é –ê—Å—Ç—Ä–æ-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ú–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–±—å–µ—Ç Baseline (R_MIN > 0.587).\n",
    "\n",
    "\n",
    "\n",
    " –î–∞—Ç–∞: **2009-10-10** (Economic Birth)\n",
    "\n",
    " –ü—Ä–∏–∑–Ω–∞–∫–∏: –¢—Ä–∞–Ω–∑–∏—Ç—ã –∫ –Ω–∞—Ç–∞–ª—É + –ê—Å–ø–µ–∫—Ç—ã —Ç—Ä–∞–Ω–∑–∏—Ç–æ–≤ + –§–∞–∑—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, date, timezone\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef, confusion_matrix\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/rut/ostrofun\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RESEARCH.config import cfg\n",
    "from RESEARCH.data_loader import load_market_data\n",
    "from RESEARCH.labeling import create_balanced_labels\n",
    "from RESEARCH.astro_engine import (\n",
    "    init_ephemeris,\n",
    "    calculate_bodies_for_dates_multi,\n",
    "    calculate_aspects_for_dates,\n",
    "    calculate_transits_for_dates,\n",
    "    calculate_phases_for_dates,\n",
    "    get_natal_bodies,\n",
    ")\n",
    "from RESEARCH.features import build_full_features, merge_features_with_labels\n",
    "from RESEARCH.model_training import split_dataset, prepare_xy, train_xgb_model, tune_threshold, predict_with_threshold, check_cuda_available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Deep Tuning 2.0 for Date: 2009-10-10\n",
      "Astro Grid Size: 72\n",
      "Model Grid Size: 36\n",
      "Total Combinations: 2592\n"
     ]
    }
   ],
   "source": [
    "# 1. Configuration Grid\n",
    "TARGET_DATE = date(2009, 10, 10)\n",
    "print(f\"üß† Deep Tuning 2.0 for Date: {TARGET_DATE}\")\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤–ª–∏—è—é—Ç –Ω–∞ –î–ê–ù–ù–´–ï\n",
    "ASTRO_GRID = {\n",
    "    \"coord_mode\": [\"both\"],\n",
    "    \"orb_mult\": [0.05, 0.075, 0.1, 0.125],\n",
    "    \"gauss_window\": [150, 200, 250],\n",
    "    \"gauss_std\": [50.0, 70.0, 90.0],\n",
    "    \"exclude_bodies\": [None, [\"Uranus\", \"Pluto\"]], # –ü—Ä–æ–±—É–µ–º —Å/–±–µ–∑\n",
    "}\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ú–û–î–ï–õ–ò (Refined around Winner: depth=6, est=500, col=0.6)\n",
    "MODEL_GRID = {\n",
    "    \"n_estimators\": [300, 500, 800],\n",
    "    \"max_depth\": [4, 5, 6, 7],\n",
    "    \"learning_rate\": [0.03], \n",
    "    \"colsample_bytree\": [0.5, 0.6, 0.7], # Winner was 0.6\n",
    "    \"subsample\": [0.8],\n",
    "}\n",
    "\n",
    "astro_size = len(list(product(*ASTRO_GRID.values())))\n",
    "model_size = len(list(product(*MODEL_GRID.values())))\n",
    "print(f\"Astro Grid Size: {astro_size}\")\n",
    "print(f\"Model Grid Size: {model_size}\")\n",
    "print(f\"Total Combinations: {astro_size * model_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5677 rows from DB for subject=btc\n",
      "Date range: 2010-07-18 -> 2026-01-31\n",
      "\n",
      "========================================\n",
      "üéØ TARGET BASELINE: R_MIN > 0.601\n",
      "========================================\n",
      "\n",
      "üìç Pre-calculating bodies (both)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rut/ostrofun/RESEARCH/data_loader.py:55: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql_query(query, conn, params=params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåô Pre-calculating phases...\n"
     ]
    }
   ],
   "source": [
    "# 2. Setup\n",
    "df_market_raw = load_market_data()\n",
    "df_market_raw = df_market_raw[df_market_raw[\"date\"] >= \"2017-11-01\"].reset_index(drop=True)\n",
    "settings = init_ephemeris()\n",
    "_, device = check_cuda_available()\n",
    "\n",
    "# Baseline Evaluation\n",
    "BASELINE_RMIN = 0.601  # Updated Baseline!\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"üéØ TARGET BASELINE: R_MIN > {BASELINE_RMIN}\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "# Pre-calculate bodies for BOTH mode\n",
    "print(\"üìç Pre-calculating bodies (both)...\")\n",
    "df_bodies_both, geo_dict, helio_dict = calculate_bodies_for_dates_multi(\n",
    "    df_market_raw[\"date\"], settings, \"both\", progress=False\n",
    ")\n",
    "# Cache phases as they depend only on bodies\n",
    "print(\"üåô Pre-calculating phases...\")\n",
    "df_phases_geo = calculate_phases_for_dates(geo_dict, progress=False)\n",
    "\n",
    "# Natal bodies (static)\n",
    "natal_dt_str = f\"{TARGET_DATE.isoformat()}T12:00:00\"\n",
    "natal_bodies = get_natal_bodies(natal_dt_str, settings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   0%|          | 0/2592 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2028\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/w/WSL/btc/lib/python3.12/site-packages/xgboost/core.py:774: UserWarning: [07:26:46] WARNING: /workspace/src/common/error_msg.cc:62: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  return func(**kwargs)\n",
      "Grid Search:   0%|          | 1/2592 [00:01<1:10:47,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NEW BEST: R_MIN=0.2876 MCC=0.0657 Gap=0.4823 | Orb=0.05 Win=150 Excl=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   0%|          | 3/2592 [00:03<39:31,  1.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NEW BEST: R_MIN=0.3407 MCC=0.0918 Gap=0.4027 | Orb=0.05 Win=150 Excl=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   0%|          | 9/2592 [00:07<33:04,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NEW BEST: R_MIN=0.4204 MCC=0.0774 Gap=0.2345 | Orb=0.05 Win=150 Excl=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   0%|          | 12/2592 [00:11<48:47,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NEW BEST: R_MIN=0.5044 MCC=0.0620 Gap=0.0531 | Orb=0.05 Win=150 Excl=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   1%|‚ñè         | 36/2592 [00:29<35:34,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 1608\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   1%|‚ñè         | 37/2592 [00:30<37:00,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NEW BEST: R_MIN=0.5575 MCC=0.1239 Gap=0.0088 | Orb=0.05 Win=150 Excl=['Uranus', 'Pluto']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   3%|‚ñé         | 72/2592 [00:58<32:13,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2028\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   4%|‚ñç         | 108/2592 [01:27<34:48,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 1608\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   6%|‚ñå         | 144/2592 [01:55<31:52,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2028\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   7%|‚ñã         | 180/2592 [02:24<32:32,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 1608\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   7%|‚ñã         | 182/2592 [02:26<31:03,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NEW BEST: R_MIN=0.5708 MCC=0.1726 Gap=0.0310 | Orb=0.05 Win=150 Excl=['Uranus', 'Pluto']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   7%|‚ñã         | 190/2592 [02:32<32:22,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ NEW BEST: R_MIN=0.5796 MCC=0.1637 Gap=0.0044 | Orb=0.05 Win=150 Excl=['Uranus', 'Pluto']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:   8%|‚ñä         | 216/2592 [02:52<33:24,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2028\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  10%|‚ñâ         | 252/2592 [03:20<39:31,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 1608\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  11%|‚ñà         | 288/2592 [03:47<30:05,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2028\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  12%|‚ñà‚ñé        | 324/2592 [04:16<31:11,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 1608\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  14%|‚ñà‚ñç        | 360/2592 [04:44<28:48,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2028\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  15%|‚ñà‚ñå        | 396/2592 [05:13<29:58,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 1608\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  17%|‚ñà‚ñã        | 432/2592 [05:41<28:52,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2028\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  18%|‚ñà‚ñä        | 468/2592 [06:11<28:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 1608\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  19%|‚ñà‚ñâ        | 504/2592 [06:38<27:13,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2028\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  21%|‚ñà‚ñà        | 540/2592 [07:07<28:59,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 1608\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  22%|‚ñà‚ñà‚ñè       | 576/2592 [07:35<26:18,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2028\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  24%|‚ñà‚ñà‚ñé       | 612/2592 [08:05<33:16,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 1608\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  25%|‚ñà‚ñà‚ñå       | 648/2592 [08:34<42:25,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels created: 1506 samples\n",
      "  UP: 753 (50.0%)\n",
      "  DOWN: 753 (50.0%)\n",
      "  Date range: 2017-11-05 -> 2026-01-30\n",
      "Merged dataset: 3010 samples (ALL days, forward-filled)\n",
      "Features: 2038\n",
      "Split: Train=2107, Val=451, Test=452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Grid Search:  25%|‚ñà‚ñà‚ñå       | 658/2592 [08:42<26:40,  1.21it/s]"
     ]
    }
   ],
   "source": [
    "# 3. Main Loop\n",
    "results = []\n",
    "best_model_info = {\"score\": -1, \"y_test\": None, \"y_pred\": None, \"params\": None}\n",
    "\n",
    "astro_keys = ASTRO_GRID.keys()\n",
    "astro_combos = list(product(*ASTRO_GRID.values()))\n",
    "\n",
    "model_keys = MODEL_GRID.keys()\n",
    "model_combos = list(product(*MODEL_GRID.values()))\n",
    "\n",
    "total_steps = len(astro_combos) * len(model_combos)\n",
    "\n",
    "# –ò—Å–ø–æ–ª—å–∑—É–µ–º custom format –¥–ª—è –≤—ã–≤–æ–¥–∞\n",
    "pbar = tqdm(total=total_steps, desc=\"Grid Search\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')\n",
    "\n",
    "for astro_vals in astro_combos:\n",
    "    astro_params = dict(zip(astro_keys, astro_vals))\n",
    "    \n",
    "    # 3.1. Build Data\n",
    "    try:\n",
    "        # Labels\n",
    "        df_labels = create_balanced_labels(\n",
    "            df_market_raw, \n",
    "            gauss_window=astro_params[\"gauss_window\"], \n",
    "            gauss_std=astro_params[\"gauss_std\"]\n",
    "        )\n",
    "        \n",
    "        # Transits & Aspects (depend on orb_mult)\n",
    "        target_bodies_dict = geo_dict \n",
    "        \n",
    "        df_transits = calculate_transits_for_dates(\n",
    "            target_bodies_dict, natal_bodies, settings, \n",
    "            orb_mult=astro_params[\"orb_mult\"], progress=False\n",
    "        )\n",
    "        df_aspects = calculate_aspects_for_dates(\n",
    "            target_bodies_dict, settings, \n",
    "            orb_mult=astro_params[\"orb_mult\"], progress=False\n",
    "        )\n",
    "        \n",
    "        # Features with exclusion\n",
    "        df_features = build_full_features(\n",
    "            df_bodies_both, df_aspects, df_transits=df_transits, df_phases=df_phases_geo,\n",
    "            include_pair_aspects=True, include_transit_aspects=True,\n",
    "            exclude_bodies=astro_params[\"exclude_bodies\"]\n",
    "        )\n",
    "        \n",
    "        df_dataset = merge_features_with_labels(df_features, df_labels)\n",
    "        \n",
    "        # Split\n",
    "        train_df, val_df, test_df = split_dataset(df_dataset)\n",
    "        feat_cols = [c for c in df_dataset.columns if c not in [\"date\", \"target\"]]\n",
    "        X_train, y_train = prepare_xy(train_df, feat_cols)\n",
    "        X_val, y_val = prepare_xy(val_df, feat_cols)\n",
    "        X_test, y_test = prepare_xy(test_df, feat_cols)\n",
    "        \n",
    "        # 3.2. Models\n",
    "        for model_vals in model_combos:\n",
    "            model_params = dict(zip(model_keys, model_vals))\n",
    "            \n",
    "            model = train_xgb_model(\n",
    "                X_train, y_train, X_val, y_val, feat_cols,\n",
    "                n_classes=2, device=device, verbose=False, early_stopping_rounds=50,\n",
    "                **model_params\n",
    "            )\n",
    "            \n",
    "            best_t, _ = tune_threshold(model, X_val, y_val, metric=\"recall_min\", verbose=False)\n",
    "            y_pred = predict_with_threshold(model, X_test, threshold=best_t)\n",
    "            \n",
    "            # Metrics\n",
    "            mcc = matthews_corrcoef(y_test, y_pred)\n",
    "            report = classification_report(y_test, y_pred, output_dict=True, zero_division=0)\n",
    "            r_min = min(report[\"0\"][\"recall\"], report[\"1\"][\"recall\"])\n",
    "            r_up = report[\"1\"][\"recall\"]\n",
    "            r_down = report[\"0\"][\"recall\"]\n",
    "            gap = abs(r_up - r_down)\n",
    "            \n",
    "            # Save\n",
    "            res = astro_params.copy()\n",
    "            res.update(model_params)\n",
    "            res[\"R_MIN\"] = r_min\n",
    "            res[\"MCC\"] = mcc\n",
    "            res[\"GAP\"] = gap\n",
    "            results.append(res)\n",
    "            \n",
    "            # Check Best\n",
    "            if r_min > best_model_info[\"score\"]:\n",
    "                best_model_info = {\n",
    "                    \"score\": r_min,\n",
    "                    \"mcc\": mcc,\n",
    "                    \"y_test\": y_test,\n",
    "                    \"y_pred\": y_pred,\n",
    "                    \"params\": res,\n",
    "                    \"model\": model,\n",
    "                    \"threshold\": best_t\n",
    "                }\n",
    "                # Live Log Update\n",
    "                tqdm.write(f\"üöÄ NEW BEST: R_MIN={r_min:.4f} MCC={mcc:.4f} Gap={gap:.4f} | \"\n",
    "                           f\"Orb={astro_params['orb_mult']} Win={astro_params['gauss_window']} \"\n",
    "                           f\"Excl={astro_params['exclude_bodies']}\")\n",
    "            \n",
    "            pbar.update(1)\n",
    "            \n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"‚ùå Error config {astro_params}: {e}\")\n",
    "        pbar.update(len(model_combos))\n",
    "\n",
    "pbar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Analysis & Viz\n",
    "df_res = pd.DataFrame(results).sort_values(\"R_MIN\", ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"üèÜ TOP 10 CONFIGURATIONS (Baseline: {BASELINE_RMIN})\")\n",
    "print(\"=\"*80)\n",
    "# Format columns for readability\n",
    "cols_show = [\"orb_mult\", \"gauss_window\", \"exclude_bodies\", \"n_estimators\", \"max_depth\", \"R_MIN\", \"MCC\", \"GAP\"]\n",
    "print(df_res.head(10)[cols_show].to_string(index=False))\n",
    "\n",
    "best = best_model_info\n",
    "print(f\"\\nü•á WINNER DETAILS:\")\n",
    "print(f\"   R_MIN:     {best['score']:.4f}\")\n",
    "print(f\"   MCC:       {best['mcc']:.4f}\")\n",
    "print(f\"   Params:    {best['params']}\")\n",
    "\n",
    "if best[\"score\"] > BASELINE_RMIN:\n",
    "    print(f\"\\nüéâ SUCCESS! We beat baseline {BASELINE_RMIN}!\")\n",
    "else:\n",
    "    print(f\"\\n‚ùÑÔ∏è FAIL. Baseline {BASELINE_RMIN} is still King.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Visualization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìä BEST MODEL DIAGNOSTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm = confusion_matrix(best[\"y_test\"], best[\"y_pred\"])\n",
    "cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax[0], cbar=False)\n",
    "ax[0].set_title(f\"Confusion Matrix (Target: {TARGET_DATE})\")\n",
    "ax[0].set_xlabel('Predicted')\n",
    "ax[0].set_ylabel('Actual')\n",
    "ax[0].set_xticklabels(['DOWN', 'UP'])\n",
    "ax[0].set_yticklabels(['DOWN', 'UP'])\n",
    "\n",
    "sns.heatmap(cm_norm, annot=True, fmt='.2%', cmap='Greens', ax=ax[1], cbar=False)\n",
    "ax[1].set_title(f\"Normalized Matrix (Recall Analysis)\")\n",
    "ax[1].set_xlabel('Predicted')\n",
    "ax[1].set_ylabel('Actual')\n",
    "ax[1].set_xticklabels(['DOWN', 'UP'])\n",
    "ax[1].set_yticklabels(['DOWN', 'UP'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Detailed Report\n",
    "print(\"\\nüìù Detailed Classification Report:\")\n",
    "print(classification_report(best[\"y_test\"], best[\"y_pred\"], target_names=[\"DOWN\", \"UP\"], digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
