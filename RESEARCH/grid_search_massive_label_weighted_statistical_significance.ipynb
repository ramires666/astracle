{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Turning Massive Grid: Statistical Significance of Regime-Bifurcation Detection\n", "\n", "This notebook performs **post-run statistical analysis** of the saved massive grid results.\n", "It does **not** rerun the giant grid search.\n", "\n", "Goals:\n", "- Evaluate whether astro-only model predictions align with real market regime-switch points in time.\n", "- Quantify event-level alignment (hit-rate, precision, lag).\n", "- Test significance with circular-shift permutation null and conservative multiple-testing correction.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from __future__ import annotations\n", "\n", "import sys\n", "from pathlib import Path\n", "from typing import Any, Dict\n", "from IPython.display import display\n", "\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "from sklearn.utils.class_weight import compute_sample_weight\n", "\n", "PROJECT_ROOT = Path.cwd().resolve()\n", "if not (PROJECT_ROOT / \"RESEARCH\").exists():\n", "    for parent in PROJECT_ROOT.parents:\n", "        if (parent / \"RESEARCH\").exists():\n", "            PROJECT_ROOT = parent\n", "            break\n", "\n", "if str(PROJECT_ROOT) not in sys.path:\n", "    sys.path.insert(0, str(PROJECT_ROOT))\n", "\n", "from RESEARCH.config import cfg as project_cfg\n", "from RESEARCH.data_loader import load_market_data\n", "from RESEARCH.model_training import check_cuda_available\n", "from src.models.xgb import XGBBaseline\n", "from src.pipeline.astro_xgb.metrics import bootstrap_metrics\n", "\n", "from RESEARCH2.Moon_cycles.eval_utils import compute_binary_metrics, compute_statistical_significance\n", "from RESEARCH2.Moon_cycles.splits import make_classic_split\n", "from RESEARCH2.Moon_cycles.turning_astro_features import TurningAstroFeatureConfig, build_turning_astro_feature_set\n", "from RESEARCH2.Moon_cycles.turning_points import TurningPointLabelConfig, label_turning_points\n", "from RESEARCH2.Moon_cycles.turning_targets import build_turning_target_frame, merge_features_with_turning_target\n", "\n", "pd.set_option(\"display.max_columns\", None)\n", "pd.set_option(\"display.expand_frame_repr\", False)\n", "\n", "print(\"Python:\", sys.version.split()[0])\n", "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Analysis config\n", "RUN_TAG = \"turning_massive_label_grid\"\n", "DATA_START = \"2017-11-01\"\n", "SEED = 42\n", "TRAIN_RATIO = 0.70\n", "VAL_RATIO = 0.15\n", "EVENT_WINDOWS = [1, 2, 3, 5, 7]\n", "TRUE_EVENT_MODE = \"market_sign_change\"  # market_sign_change | turning_points\n", "TRUE_EVENT_MIN_MOVE_PCT = 0.0  # deadzone for market sign change (e.g. 0.002 = 0.2%)\n", "TRUE_EVENT_MIN_SEGMENT_DAYS = 2  # suppress 1-day flip noise in market-truth events\n", "\n", "# Honest selection rules (same philosophy as post-analysis notebook).\n", "HONEST_RULE_STRICT = {\n", "    \"test_recall_min\": 0.55,\n", "    \"test_recall_gap\": 0.25,\n", "    \"val_recall_min\": 0.50,\n", "    \"val_recall_gap\": 0.25,\n", "}\n", "HONEST_RULE_RELAXED = {\n", "    \"test_recall_min\": 0.50,\n", "    \"test_recall_gap\": 0.35,\n", "    \"val_recall_min\": 0.45,\n", "    \"val_recall_gap\": 0.35,\n", "}\n", "\n", "REPORTS_DIR = project_cfg.reports_dir if hasattr(project_cfg, \"reports_dir\") else (PROJECT_ROOT / \"data\" / \"market\" / \"reports\")\n", "CHECKPOINT_PATH = Path(REPORTS_DIR) / f\"{RUN_TAG}_checkpoint.csv\"\n", "\n", "if not CHECKPOINT_PATH.exists():\n", "    raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT_PATH}\")\n", "\n", "print(\"CHECKPOINT:\", CHECKPOINT_PATH)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def _as_bool(v: Any) -> bool:\n", "    if isinstance(v, (bool, np.bool_)):\n", "        return bool(v)\n", "    if v is None or (isinstance(v, float) and np.isnan(v)):\n", "        return False\n", "    if isinstance(v, (int, np.integer, float, np.floating)):\n", "        return bool(int(v))\n", "    return str(v).strip().lower() in {\"1\", \"true\", \"yes\", \"y\", \"t\"}\n", "\n", "\n", "def sort_results_frame(df: pd.DataFrame) -> pd.DataFrame:\n", "    if df.empty:\n", "        return df\n", "\n", "    out = df.copy()\n", "    defaults = {\n", "        \"is_feasible\": 0,\n", "        \"total_constraint_violation\": 1e9,\n", "        \"test_profit_y_obj\": -1e9,\n", "        \"test_profit_y\": -1e9,\n", "        \"test_recall_min\": -1.0,\n", "        \"test_recall_gap\": 1e9,\n", "        \"mcc\": -1e9,\n", "    }\n", "    for k, v in defaults.items():\n", "        if k not in out.columns:\n", "            out[k] = v\n", "\n", "    return out.sort_values(\n", "        [\n", "            \"is_feasible\",\n", "            \"total_constraint_violation\",\n", "            \"test_profit_y_obj\",\n", "            \"test_profit_y\",\n", "            \"test_recall_min\",\n", "            \"test_recall_gap\",\n", "            \"mcc\",\n", "        ],\n", "        ascending=[False, True, False, False, False, True, False],\n", "    )\n", "\n", "\n", "def pick_grid_best_and_honest(df_sorted: pd.DataFrame) -> tuple[pd.Series, pd.Series, dict[str, int]]:\n", "    if df_sorted.empty:\n", "        raise ValueError(\"Checkpoint frame is empty\")\n", "\n", "    best_row = df_sorted.iloc[0].copy()\n", "    feas = df_sorted[df_sorted.get(\"is_feasible\", 0) == 1].copy()\n", "\n", "    strict = feas[\n", "        (feas[\"test_recall_min\"] >= HONEST_RULE_STRICT[\"test_recall_min\"])\n", "        & (feas[\"test_recall_gap\"] <= HONEST_RULE_STRICT[\"test_recall_gap\"])\n", "        & (feas[\"val_recall_min\"] >= HONEST_RULE_STRICT[\"val_recall_min\"])\n", "        & (feas[\"val_recall_gap\"] <= HONEST_RULE_STRICT[\"val_recall_gap\"])\n", "    ].copy()\n", "\n", "    if strict.empty:\n", "        strict = feas[\n", "            (feas[\"test_recall_min\"] >= HONEST_RULE_RELAXED[\"test_recall_min\"])\n", "            & (feas[\"test_recall_gap\"] <= HONEST_RULE_RELAXED[\"test_recall_gap\"])\n", "            & (feas[\"val_recall_min\"] >= HONEST_RULE_RELAXED[\"val_recall_min\"])\n", "            & (feas[\"val_recall_gap\"] <= HONEST_RULE_RELAXED[\"val_recall_gap\"])\n", "        ].copy()\n", "\n", "    if strict.empty:\n", "        strict = feas.copy() if not feas.empty else df_sorted.copy()\n", "\n", "    honest_row = strict.sort_values(\n", "        [\"test_recall_min\", \"test_recall_gap\", \"mcc\", \"bal_acc\", \"test_profit_y_obj\"],\n", "        ascending=[False, True, False, False, False],\n", "    ).iloc[0].copy()\n", "\n", "    sizes = {\n", "        \"n_all\": int(len(df_sorted)),\n", "        \"n_feasible\": int(len(feas)),\n", "        \"n_honest_pool\": int(len(strict)),\n", "    }\n", "    return best_row, honest_row, sizes\n", "\n", "\n", "def _extract_label_cfg(row: pd.Series) -> Dict[str, Any]:\n", "    return {\n", "        \"up_move_pct\": float(row[\"label_up_move_pct\"]),\n", "        \"down_move_pct\": float(row[\"label_down_move_pct\"]),\n", "        \"cluster_gap_days\": int(row[\"label_cluster_gap_days\"]),\n", "        \"min_turn_gap_days\": int(row[\"label_min_turn_gap_days\"]),\n", "        \"past_horizon_days\": int(row[\"label_past_horizon_days\"]),\n", "        \"past_up_move_pct\": float(row[\"label_past_up_move_pct\"]),\n", "        \"past_down_move_pct\": float(row[\"label_past_down_move_pct\"]),\n", "    }\n", "\n", "\n", "def _extract_target_cfg(row: pd.Series) -> Dict[str, Any]:\n", "    mode = str(row[\"target_mode\"])\n", "    cfg: Dict[str, Any] = {\n", "        \"mode\": mode,\n", "        \"min_weight\": float(row[\"target_min_weight\"]),\n", "        \"use_amplitude_weight\": _as_bool(row[\"target_use_amplitude_weight\"]),\n", "    }\n", "    if mode == \"window_kernel\":\n", "        cfg.update(\n", "            {\n", "                \"window_radius_days\": int(row[\"target_window_radius_days\"]),\n", "                \"window_distance_power\": float(row[\"target_window_distance_power\"]),\n", "            }\n", "        )\n", "    elif mode == \"segment_midpoint\":\n", "        cfg.update(\n", "            {\n", "                \"segment_center_power\": float(row[\"target_segment_center_power\"]),\n", "                \"segment_direction_anchor\": str(row[\"target_segment_direction_anchor\"]),\n", "                \"include_last_open_segment\": _as_bool(row[\"target_include_last_open_segment\"]),\n", "                \"segment_open_tail_direction_mode\": str(row[\"target_segment_open_tail_direction_mode\"]),\n", "                \"segment_open_tail_min_move_pct\": float(row[\"target_segment_open_tail_min_move_pct\"]),\n", "            }\n", "        )\n", "    else:\n", "        raise ValueError(f\"Unsupported target_mode: {mode}\")\n", "    return cfg\n", "\n", "\n", "def _extract_model_cfg(row: pd.Series) -> Dict[str, Any]:\n", "    return {\n", "        \"n_estimators\": int(row[\"model_n_estimators\"]),\n", "        \"max_depth\": int(row[\"model_max_depth\"]),\n", "        \"learning_rate\": float(row[\"model_learning_rate\"]),\n", "        \"subsample\": float(row[\"model_subsample\"]),\n", "        \"colsample_bytree\": float(row[\"model_colsample_bytree\"]),\n", "        \"early_stopping_rounds\": int(row[\"model_early_stopping_rounds\"]),\n", "    }\n", "\n", "\n", "def _safe_predict_proba_up(model_obj: XGBBaseline, X: np.ndarray) -> np.ndarray:\n", "    const_cls = getattr(model_obj, \"constant_class\", None)\n", "    if const_cls is not None:\n", "        c = int(const_cls)\n", "        return np.full(X.shape[0], 1.0 if c == 1 else 0.0, dtype=float)\n", "\n", "    Xs = model_obj.scaler.transform(X)\n", "    booster = None\n", "    restore_device = None\n", "    try:\n", "        booster = model_obj.model.get_booster()\n", "        restore_device = str(getattr(model_obj, \"device\", \"cpu\"))\n", "        booster.set_param({\"device\": \"cpu\"})\n", "    except Exception:\n", "        booster = None\n", "\n", "    try:\n", "        proba_up = model_obj.model.predict_proba(Xs)[:, 1]\n", "    finally:\n", "        if booster is not None and restore_device and restore_device.startswith(\"cuda\"):\n", "            try:\n", "                booster.set_param({\"device\": restore_device})\n", "            except Exception:\n", "                pass\n", "\n", "    return np.asarray(proba_up, dtype=float)\n", "\n", "\n", "def _profit_y(y_pred: np.ndarray, next_ret: np.ndarray) -> float:\n", "    p = np.where(np.asarray(y_pred, dtype=np.int32) == 1, 1.0, -1.0)\n", "    y = np.asarray(next_ret, dtype=float)\n", "    return float(np.mean(p * y)) if len(y) > 0 else 0.0\n", "\n", "\n", "def _weighted_move_vector(next_ret: np.ndarray, sample_weight: np.ndarray, power: float = 1.5, clip_q: float = 0.98) -> np.ndarray:\n", "    base = np.abs(np.asarray(next_ret, dtype=float))\n", "    if base.size == 0:\n", "        return np.array([], dtype=float)\n", "    cap = float(np.quantile(base, clip_q))\n", "    if not np.isfinite(cap) or cap <= 0.0:\n", "        cap = float(np.nanmax(base)) if np.isfinite(np.nanmax(base)) and np.nanmax(base) > 0 else 1.0\n", "    move_part = np.clip(base / cap, 0.0, 1.0) ** float(power)\n", "    w = move_part * np.asarray(sample_weight, dtype=float)\n", "    return np.maximum(w, 1e-8)\n", "\n", "\n", "def _profit_y_obj(y_pred: np.ndarray, next_ret: np.ndarray, sample_weight: np.ndarray) -> float:\n", "    p = np.where(np.asarray(y_pred, dtype=np.int32) == 1, 1.0, -1.0)\n", "    y = np.asarray(next_ret, dtype=float)\n", "    w = _weighted_move_vector(next_ret=y, sample_weight=sample_weight)\n", "    return float(np.sum(w * (p * y)) / np.sum(w))\n", "\n", "\n", "def build_market_and_close_map(data_start: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n", "    df_market = load_market_data()\n", "    df_market = df_market[df_market[\"date\"] >= data_start].copy()\n", "    df_market[\"date\"] = pd.to_datetime(df_market[\"date\"])\n", "    df_market[\"close\"] = pd.to_numeric(df_market[\"close\"], errors=\"coerce\")\n", "    df_market = df_market.dropna(subset=[\"date\", \"close\"]).sort_values(\"date\").drop_duplicates(\"date\").reset_index(drop=True)\n", "\n", "    close_map = df_market[[\"date\", \"close\"]].copy()\n", "    close_map[\"next_close\"] = close_map[\"close\"].shift(-1)\n", "    close_map[\"next_ret\"] = close_map[\"next_close\"] / close_map[\"close\"] - 1.0\n", "    return df_market, close_map\n", "\n", "\n", "def get_or_build_features_for_row(\n", "    row: pd.Series,\n", "    df_market: pd.DataFrame,\n", "    feature_cache: dict[tuple[str, str, float], pd.DataFrame],\n", "    cache_namespace: str = \"research2_turning_grid\",\n", ") -> pd.DataFrame:\n", "    birth_dt_utc = str(row.get(\"birth_dt_utc\", project_cfg.subject.get(\"birth_dt_utc\", \"2009-10-10T18:15:05Z\")))\n", "    coord_mode = str(row.get(\"feature_coord_mode\", \"both\"))\n", "    orb_mult = float(row.get(\"feature_orb_mult\", 0.10))\n", "\n", "    key = (birth_dt_utc, coord_mode, round(orb_mult, 8))\n", "    if key in feature_cache:\n", "        return feature_cache[key]\n", "\n", "    astro_cfg = TurningAstroFeatureConfig(\n", "        coord_mode=coord_mode,\n", "        orb_mult=orb_mult,\n", "        include_pair_aspects=True,\n", "        include_phases=True,\n", "        include_transit_aspects=True,\n", "        add_trig_for_longitudes=True,\n", "        add_trig_for_moon_phase=True,\n", "        add_trig_for_elongations=True,\n", "    )\n", "\n", "    df_features = build_turning_astro_feature_set(\n", "        df_market=df_market,\n", "        birth_dt_utc=birth_dt_utc,\n", "        cfg=astro_cfg,\n", "        cache_namespace=cache_namespace,\n", "        use_cache=True,\n", "        verbose=True,\n", "        progress=True,\n", "    )\n", "    feature_cache[key] = df_features\n", "    return df_features\n", "\n", "\n", "def evaluate_candidate(\n", "    row: pd.Series,\n", "    tag: str,\n", "    df_market: pd.DataFrame,\n", "    close_map: pd.DataFrame,\n", "    feature_cache: dict[tuple[str, str, float], pd.DataFrame],\n", "    seed: int = 42,\n", ") -> Dict[str, Any]:\n", "    df_features = get_or_build_features_for_row(row=row, df_market=df_market, feature_cache=feature_cache)\n", "\n", "    label_cfg = _extract_label_cfg(row)\n", "    target_cfg = _extract_target_cfg(row)\n", "    model_cfg = _extract_model_cfg(row)\n", "\n", "    turn_cfg = TurningPointLabelConfig(\n", "        horizon_days=int(row.get(\"horizon_days_fixed\", 10)),\n", "        up_move_pct=float(label_cfg[\"up_move_pct\"]),\n", "        down_move_pct=float(label_cfg[\"down_move_pct\"]),\n", "        cluster_gap_days=int(label_cfg[\"cluster_gap_days\"]),\n", "        min_turn_gap_days=int(label_cfg[\"min_turn_gap_days\"]),\n", "        past_horizon_days=int(label_cfg[\"past_horizon_days\"]),\n", "        past_up_move_pct=float(label_cfg[\"past_up_move_pct\"]),\n", "        past_down_move_pct=float(label_cfg[\"past_down_move_pct\"]),\n", "        tail_direction_mode=str(row.get(\"tail_direction_mode_fixed\", \"endpoint_sign\")),\n", "        tail_min_move_pct=float(row.get(\"tail_min_move_pct_fixed\", 0.0)),\n", "    )\n", "\n", "    _, df_turns, _ = label_turning_points(df_market=df_market, cfg=turn_cfg)\n", "\n", "    if target_cfg[\"mode\"] == \"window_kernel\":\n", "        df_target = build_turning_target_frame(\n", "            df_market=df_market,\n", "            df_turning_points=df_turns,\n", "            mode=\"window_kernel\",\n", "            window_radius_days=int(target_cfg[\"window_radius_days\"]),\n", "            window_distance_power=float(target_cfg[\"window_distance_power\"]),\n", "            min_weight=float(target_cfg[\"min_weight\"]),\n", "            use_amplitude_weight=bool(target_cfg[\"use_amplitude_weight\"]),\n", "            use_numba=True,\n", "        )\n", "    else:\n", "        df_target = build_turning_target_frame(\n", "            df_market=df_market,\n", "            df_turning_points=df_turns,\n", "            mode=\"segment_midpoint\",\n", "            segment_center_power=float(target_cfg[\"segment_center_power\"]),\n", "            segment_direction_anchor=str(target_cfg[\"segment_direction_anchor\"]),\n", "            include_last_open_segment=bool(target_cfg[\"include_last_open_segment\"]),\n", "            segment_open_tail_direction_mode=str(target_cfg[\"segment_open_tail_direction_mode\"]),\n", "            segment_open_tail_min_move_pct=float(target_cfg[\"segment_open_tail_min_move_pct\"]),\n", "            min_weight=float(target_cfg[\"min_weight\"]),\n", "            use_amplitude_weight=bool(target_cfg[\"use_amplitude_weight\"]),\n", "            use_numba=True,\n", "        )\n", "\n", "    df_dataset = merge_features_with_turning_target(\n", "        df_features=df_features,\n", "        df_target=df_target,\n", "        df_market_close=df_market[[\"date\", \"close\"]],\n", "    )\n", "    df_dataset = pd.merge(df_dataset, close_map[[\"date\", \"next_ret\"]], on=\"date\", how=\"left\")\n", "    df_dataset = df_dataset.dropna(subset=[\"next_ret\", \"target\", \"sample_weight\", \"close\"]).sort_values(\"date\").reset_index(drop=True)\n", "\n", "    split = make_classic_split(df_dataset, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO)\n", "    train_df = df_dataset.iloc[split.train_idx].copy().reset_index(drop=True)\n", "    val_df = df_dataset.iloc[split.val_idx].copy().reset_index(drop=True)\n", "    test_df = df_dataset.iloc[split.test_idx].copy().reset_index(drop=True)\n", "\n", "    feature_cols = [\n", "        c for c in df_dataset.columns\n", "        if c not in {\n", "            \"date\", \"target\", \"close\", \"next_ret\",\n", "            \"turning_direction\", \"sample_weight\", \"target_mode\",\n", "            \"event_index\", \"segment_index\",\n", "        }\n", "    ]\n", "\n", "    X_train = train_df[feature_cols].to_numpy(dtype=np.float32)\n", "    y_train = train_df[\"target\"].to_numpy(dtype=np.int32)\n", "    X_val = val_df[feature_cols].to_numpy(dtype=np.float32)\n", "    y_val = val_df[\"target\"].to_numpy(dtype=np.int32)\n", "    X_test = test_df[feature_cols].to_numpy(dtype=np.float32)\n", "    y_test = test_df[\"target\"].to_numpy(dtype=np.int32)\n", "\n", "    sw_train_base = pd.to_numeric(train_df[\"sample_weight\"], errors=\"coerce\").fillna(1.0).to_numpy(dtype=np.float32)\n", "    sw_val_base = pd.to_numeric(val_df[\"sample_weight\"], errors=\"coerce\").fillna(1.0).to_numpy(dtype=np.float32)\n", "    sw_test_base = pd.to_numeric(test_df[\"sample_weight\"], errors=\"coerce\").fillna(1.0).to_numpy(dtype=np.float32)\n", "\n", "    sw_train = sw_train_base * compute_sample_weight(class_weight=\"balanced\", y=y_train).astype(np.float32)\n", "    sw_val = sw_val_base * compute_sample_weight(class_weight=\"balanced\", y=y_val).astype(np.float32)\n", "    sw_test = sw_test_base * compute_sample_weight(class_weight=\"balanced\", y=y_test).astype(np.float32)\n", "\n", "    _, device = check_cuda_available()\n", "\n", "    def _make_model(device_name: str) -> XGBBaseline:\n", "        return XGBBaseline(\n", "            n_classes=2,\n", "            device=device_name,\n", "            random_state=seed,\n", "            early_stopping_rounds=int(model_cfg[\"early_stopping_rounds\"]),\n", "            n_estimators=int(model_cfg[\"n_estimators\"]),\n", "            max_depth=int(model_cfg[\"max_depth\"]),\n", "            learning_rate=float(model_cfg[\"learning_rate\"]),\n", "            subsample=float(model_cfg[\"subsample\"]),\n", "            colsample_bytree=float(model_cfg[\"colsample_bytree\"]),\n", "            tree_method=\"hist\",\n", "            eval_metric=\"logloss\",\n", "        )\n", "\n", "    used_device = str(device)\n", "    model = _make_model(used_device)\n", "    try:\n", "        model.fit(\n", "            X_train=X_train,\n", "            y_train=y_train,\n", "            X_val=X_val,\n", "            y_val=y_val,\n", "            feature_names=feature_cols,\n", "            sample_weight=sw_train,\n", "            sample_weight_val=sw_val,\n", "        )\n", "    except Exception:\n", "        used_device = \"cpu\"\n", "        model = _make_model(used_device)\n", "        model.fit(\n", "            X_train=X_train,\n", "            y_train=y_train,\n", "            X_val=X_val,\n", "            y_val=y_val,\n", "            feature_names=feature_cols,\n", "            sample_weight=sw_train,\n", "            sample_weight_val=sw_val,\n", "        )\n", "\n", "    p_val = _safe_predict_proba_up(model, X_val)\n", "    p_test = _safe_predict_proba_up(model, X_test)\n", "\n", "    threshold = float(row.get(\"threshold\", 0.5))\n", "    pred_val = (p_val >= threshold).astype(np.int32)\n", "    pred_test = (p_test >= threshold).astype(np.int32)\n", "\n", "    val_metrics = compute_binary_metrics(y_val, pred_val)\n", "    test_metrics = compute_binary_metrics(y_test, pred_test)\n", "    sig_test = compute_statistical_significance(y_true=y_test, y_pred=pred_test, random_baseline=0.5)\n", "\n", "    boot_ci = bootstrap_metrics(y_true=y_test, y_pred=pred_test, labels=[0, 1], n_boot=400, seed=seed)\n", "\n", "    ret_val = pd.to_numeric(val_df[\"next_ret\"], errors=\"coerce\").fillna(0.0).to_numpy(dtype=np.float32)\n", "    ret_test = pd.to_numeric(test_df[\"next_ret\"], errors=\"coerce\").fillna(0.0).to_numpy(dtype=np.float32)\n", "\n", "    test_start = pd.to_datetime(test_df[\"date\"].min())\n", "    test_end = pd.to_datetime(test_df[\"date\"].max())\n", "    turns_test = df_turns[(pd.to_datetime(df_turns[\"date\"]) >= test_start) & (pd.to_datetime(df_turns[\"date\"]) <= test_end)].copy()\n", "\n", "    out = {\n", "        \"tag\": tag,\n", "        \"used_device\": used_device,\n", "        \"threshold\": threshold,\n", "        \"val_metrics\": val_metrics,\n", "        \"test_metrics\": test_metrics,\n", "        \"significance_test\": sig_test,\n", "        \"bootstrap_ci\": boot_ci,\n", "        \"val_profit_y\": _profit_y(pred_val, ret_val),\n", "        \"test_profit_y\": _profit_y(pred_test, ret_test),\n", "        \"val_profit_y_obj\": _profit_y_obj(pred_val, ret_val, sw_val),\n", "        \"test_profit_y_obj\": _profit_y_obj(pred_test, ret_test, sw_test),\n", "        \"rows\": {\n", "            \"dataset\": int(len(df_dataset)),\n", "            \"train\": int(len(train_df)),\n", "            \"val\": int(len(val_df)),\n", "            \"test\": int(len(test_df)),\n", "        },\n", "        \"turns_test\": turns_test[[\"date\", \"turning_direction\"]].copy(),\n", "        \"test_frame\": test_df[[\"date\", \"close\", \"next_ret\", \"target\"]].assign(\n", "            pred=pred_test,\n", "            proba_up=p_test,\n", "            match=(pred_test == y_test).astype(np.int32),\n", "        ),\n", "    }\n", "    return out\n", "\n", "\n", "def build_pred_switch_events(dates: pd.Series, labels: np.ndarray) -> pd.DataFrame:\n", "    d = pd.to_datetime(dates).reset_index(drop=True)\n", "    y = np.asarray(labels, dtype=np.int32)\n", "    rows: list[dict[str, Any]] = []\n", "    if len(y) < 2:\n", "        return pd.DataFrame(columns=[\"date\", \"new_regime\", \"prev_regime\"])\n", "    for i in range(1, len(y)):\n", "        if int(y[i]) != int(y[i - 1]):\n", "            rows.append(\n", "                {\n", "                    \"date\": pd.to_datetime(d.iloc[i]),\n", "                    \"new_regime\": int(y[i]),\n", "                    \"prev_regime\": int(y[i - 1]),\n", "                }\n", "            )\n", "    return pd.DataFrame(rows)\n", "\n", "\n", "def _segments_from_labels(labels: np.ndarray) -> list[tuple[int, int, int]]:\n", "    y = np.asarray(labels, dtype=np.int32)\n", "    if y.size == 0:\n", "        return []\n", "    segs: list[tuple[int, int, int]] = []\n", "    s = 0\n", "    cur = int(y[0])\n", "    for i in range(1, len(y)):\n", "        if int(y[i]) != cur:\n", "            segs.append((s, i, cur))\n", "            s = i\n", "            cur = int(y[i])\n", "    segs.append((s, len(y), cur))\n", "    return segs\n", "\n", "\n", "def _stabilize_short_segments(labels: np.ndarray, min_segment_days: int = 1) -> np.ndarray:\n", "    y = np.asarray(labels, dtype=np.int32).copy()\n", "    m = int(max(1, min_segment_days))\n", "    if y.size == 0 or m <= 1:\n", "        return y\n", "\n", "    for _ in range(10):\n", "        changed = False\n", "        segs = _segments_from_labels(y)\n", "        if len(segs) <= 1:\n", "            break\n", "        for i, (s, e, val) in enumerate(segs):\n", "            seg_len = int(e - s)\n", "            if seg_len >= m:\n", "                continue\n", "            if i == 0 and len(segs) > 1:\n", "                y[s:e] = int(segs[i + 1][2])\n", "                changed = True\n", "            elif i == len(segs) - 1 and len(segs) > 1:\n", "                y[s:e] = int(segs[i - 1][2])\n", "                changed = True\n", "            elif 0 < i < len(segs) - 1:\n", "                prev_len = int(segs[i - 1][1] - segs[i - 1][0])\n", "                next_len = int(segs[i + 1][1] - segs[i + 1][0])\n", "                pick = int(segs[i - 1][2]) if prev_len >= next_len else int(segs[i + 1][2])\n", "                y[s:e] = pick\n", "                changed = True\n", "        if not changed:\n", "            break\n", "    return y\n", "\n", "\n", "def build_true_turn_events_from_turning_points(df_turns_test: pd.DataFrame) -> pd.DataFrame:\n", "    if df_turns_test.empty:\n", "        return pd.DataFrame(columns=[\"date\", \"new_regime\"])\n", "    out = df_turns_test.copy()\n", "    out[\"date\"] = pd.to_datetime(out[\"date\"])\n", "    out[\"new_regime\"] = (pd.to_numeric(out[\"turning_direction\"], errors=\"coerce\").fillna(0).astype(int) == 1).astype(int)\n", "    out = out[[\"date\", \"new_regime\"]].sort_values(\"date\").reset_index(drop=True)\n", "    return out\n", "\n", "\n", "def build_true_turn_events_from_market(\n", "    test_frame: pd.DataFrame,\n", "    min_move_pct: float = 0.0,\n", "    min_segment_days: int = 1,\n", ") -> pd.DataFrame:\n", "    if test_frame.empty:\n", "        return pd.DataFrame(columns=[\"date\", \"new_regime\"])\n", "\n", "    f = test_frame[[\"date\", \"next_ret\"]].copy().reset_index(drop=True)\n", "    f[\"date\"] = pd.to_datetime(f[\"date\"])\n", "    ret = pd.to_numeric(f[\"next_ret\"], errors=\"coerce\").fillna(0.0).to_numpy(dtype=float)\n", "    n = len(ret)\n", "    if n == 0:\n", "        return pd.DataFrame(columns=[\"date\", \"new_regime\"])\n", "\n", "    dead = float(max(0.0, min_move_pct))\n", "    regime = np.zeros(n, dtype=np.int32)\n", "\n", "    if ret[0] > dead:\n", "        regime[0] = 1\n", "    elif ret[0] < -dead:\n", "        regime[0] = 0\n", "    else:\n", "        idx = np.where(np.abs(ret) > dead)[0]\n", "        regime[0] = 1 if (idx.size == 0 or ret[int(idx[0])] >= 0.0) else 0\n", "\n", "    for i in range(1, n):\n", "        r = float(ret[i])\n", "        if r > dead:\n", "            regime[i] = 1\n", "        elif r < -dead:\n", "            regime[i] = 0\n", "        else:\n", "            regime[i] = regime[i - 1]\n", "\n", "    regime = _stabilize_short_segments(regime, min_segment_days=int(min_segment_days))\n", "\n", "    rows: list[dict[str, Any]] = []\n", "    for i in range(1, n):\n", "        if int(regime[i]) != int(regime[i - 1]):\n", "            rows.append({\"date\": pd.to_datetime(f.loc[i, \"date\"]), \"new_regime\": int(regime[i])})\n", "\n", "    return pd.DataFrame(rows)\n", "\n", "\n", "def build_true_turn_events(\n", "    eval_result: Dict[str, Any],\n", "    mode: str = \"market_sign_change\",\n", "    min_move_pct: float = 0.0,\n", "    min_segment_days: int = 1,\n", ") -> pd.DataFrame:\n", "    m = str(mode).lower().strip()\n", "    if m in {\"turning_points\", \"turning\", \"tp\"}:\n", "        return build_true_turn_events_from_turning_points(eval_result.get(\"turns_test\", pd.DataFrame()))\n", "    if m in {\"market_sign_change\", \"market\", \"sign_change\", \"market_truth\"}:\n", "        return build_true_turn_events_from_market(\n", "            test_frame=eval_result.get(\"test_frame\", pd.DataFrame()),\n", "            min_move_pct=float(min_move_pct),\n", "            min_segment_days=int(min_segment_days),\n", "        )\n", "    raise ValueError(f\"Unsupported true event mode: {mode}\")\n", "\n", "\n", "def match_events_by_window(\n", "    true_events: pd.DataFrame,\n", "    pred_events: pd.DataFrame,\n", "    window_days: int,\n", ") -> pd.DataFrame:\n", "    if true_events.empty or pred_events.empty:\n", "        return pd.DataFrame(columns=[\"true_date\", \"pred_date\", \"new_regime\", \"lag_days\", \"abs_lag\"])\n", "\n", "    used_pred: set[int] = set()\n", "    rows: list[dict[str, Any]] = []\n", "\n", "    for _, t in true_events.iterrows():\n", "        t_date = pd.to_datetime(t[\"date\"])\n", "        t_reg = int(t[\"new_regime\"])\n", "\n", "        best_key: tuple[int, int, int] | None = None\n", "        best_data: dict[str, Any] | None = None\n", "\n", "        for p_idx, p in pred_events.iterrows():\n", "            if int(p_idx) in used_pred:\n", "                continue\n", "            if int(p[\"new_regime\"]) != t_reg:\n", "                continue\n", "\n", "            p_date = pd.to_datetime(p[\"date\"])\n", "            lag = int((p_date - t_date).days)\n", "            abs_lag = abs(lag)\n", "            if abs_lag > int(window_days):\n", "                continue\n", "\n", "            # Prefer minimal absolute lag; on tie prefer earlier/same prediction over later.\n", "            key = (abs_lag, 0 if lag <= 0 else 1, int(p_idx))\n", "            if best_key is None or key < best_key:\n", "                best_key = key\n", "                best_data = {\n", "                    \"pred_idx\": int(p_idx),\n", "                    \"pred_date\": p_date,\n", "                    \"lag_days\": int(lag),\n", "                    \"abs_lag\": int(abs_lag),\n", "                    \"new_regime\": int(t_reg),\n", "                }\n", "\n", "        if best_data is not None:\n", "            used_pred.add(int(best_data[\"pred_idx\"]))\n", "            rows.append(\n", "                {\n", "                    \"true_date\": t_date,\n", "                    \"pred_date\": best_data[\"pred_date\"],\n", "                    \"new_regime\": best_data[\"new_regime\"],\n", "                    \"lag_days\": best_data[\"lag_days\"],\n", "                    \"abs_lag\": best_data[\"abs_lag\"],\n", "                }\n", "            )\n", "\n", "    return pd.DataFrame(rows)\n", "\n", "\n", "def compute_event_metrics(\n", "    true_events: pd.DataFrame,\n", "    pred_events: pd.DataFrame,\n", "    matches: pd.DataFrame,\n", ") -> Dict[str, float]:\n", "    n_true = int(len(true_events))\n", "    n_pred = int(len(pred_events))\n", "    n_match = int(len(matches))\n", "\n", "    recall_true = float(n_match / n_true) if n_true > 0 else np.nan\n", "    precision_pred = float(n_match / n_pred) if n_pred > 0 else np.nan\n", "\n", "    if np.isfinite(recall_true) and np.isfinite(precision_pred) and (recall_true + precision_pred) > 0:\n", "        f1_event = float(2.0 * recall_true * precision_pred / (recall_true + precision_pred))\n", "    else:\n", "        f1_event = np.nan\n", "\n", "    if n_match > 0:\n", "        lags = pd.to_numeric(matches[\"lag_days\"], errors=\"coerce\").dropna().to_numpy(dtype=float)\n", "        abs_lags = np.abs(lags)\n", "        mean_abs_lag = float(np.mean(abs_lags))\n", "        median_lag = float(np.median(lags))\n", "        lead_share = float(np.mean(lags <= 0.0))\n", "    else:\n", "        mean_abs_lag = np.nan\n", "        median_lag = np.nan\n", "        lead_share = np.nan\n", "\n", "    return {\n", "        \"n_true_events\": float(n_true),\n", "        \"n_pred_events\": float(n_pred),\n", "        \"n_matched\": float(n_match),\n", "        \"recall_true\": recall_true,\n", "        \"precision_pred\": precision_pred,\n", "        \"f1_event\": f1_event,\n", "        \"mean_abs_lag_days\": mean_abs_lag,\n", "        \"median_lag_days\": median_lag,\n", "        \"lead_share\": lead_share,\n", "    }\n", "\n", "\n", "def circular_shift_permutation_test(\n", "    dates: pd.Series,\n", "    pred_labels: np.ndarray,\n", "    true_events: pd.DataFrame,\n", "    window_days: int,\n", ") -> Dict[str, Any]:\n", "    y = np.asarray(pred_labels, dtype=np.int32)\n", "    n = len(y)\n", "\n", "    obs_pred_events = build_pred_switch_events(dates=dates, labels=y)\n", "    obs_matches = match_events_by_window(true_events=true_events, pred_events=obs_pred_events, window_days=window_days)\n", "    obs = compute_event_metrics(true_events=true_events, pred_events=obs_pred_events, matches=obs_matches)\n", "\n", "    if n < 3:\n", "        return {\n", "            \"obs\": obs,\n", "            \"n_permutations\": 0,\n", "            \"p_recall\": np.nan,\n", "            \"p_abs_lag\": np.nan,\n", "            \"null_recall_mean\": np.nan,\n", "            \"null_recall_std\": np.nan,\n", "            \"null_abs_lag_mean\": np.nan,\n", "        }\n", "\n", "    null_recalls: list[float] = []\n", "    null_abs_lags: list[float] = []\n", "\n", "    # Exact circular-shift null over all non-zero shifts.\n", "    for shift in range(1, n):\n", "        y_shift = np.roll(y, shift)\n", "        p_events = build_pred_switch_events(dates=dates, labels=y_shift)\n", "        m = match_events_by_window(true_events=true_events, pred_events=p_events, window_days=window_days)\n", "        met = compute_event_metrics(true_events=true_events, pred_events=p_events, matches=m)\n", "\n", "        if np.isfinite(met[\"recall_true\"]):\n", "            null_recalls.append(float(met[\"recall_true\"]))\n", "        if np.isfinite(met[\"mean_abs_lag_days\"]):\n", "            null_abs_lags.append(float(met[\"mean_abs_lag_days\"]))\n", "\n", "    null_rec_arr = np.asarray(null_recalls, dtype=float) if null_recalls else np.array([], dtype=float)\n", "    null_lag_arr = np.asarray(null_abs_lags, dtype=float) if null_abs_lags else np.array([], dtype=float)\n", "\n", "    if np.isfinite(obs[\"recall_true\"]) and null_rec_arr.size > 0:\n", "        p_recall = float((1 + np.sum(null_rec_arr >= float(obs[\"recall_true\"]))) / (1 + null_rec_arr.size))\n", "    else:\n", "        p_recall = np.nan\n", "\n", "    if np.isfinite(obs[\"mean_abs_lag_days\"]) and null_lag_arr.size > 0:\n", "        p_abs_lag = float((1 + np.sum(null_lag_arr <= float(obs[\"mean_abs_lag_days\"]))) / (1 + null_lag_arr.size))\n", "    else:\n", "        p_abs_lag = np.nan\n", "\n", "    return {\n", "        \"obs\": obs,\n", "        \"n_permutations\": int(max(0, n - 1)),\n", "        \"p_recall\": p_recall,\n", "        \"p_abs_lag\": p_abs_lag,\n", "        \"null_recall_mean\": float(np.mean(null_rec_arr)) if null_rec_arr.size > 0 else np.nan,\n", "        \"null_recall_std\": float(np.std(null_rec_arr)) if null_rec_arr.size > 0 else np.nan,\n", "        \"null_abs_lag_mean\": float(np.mean(null_lag_arr)) if null_lag_arr.size > 0 else np.nan,\n", "    }\n", "\n", "\n", "def bonferroni_correction(p_value: float, family_size: int) -> float:\n", "    if not np.isfinite(p_value):\n", "        return np.nan\n", "    k = max(1, int(family_size))\n", "    return float(min(1.0, p_value * k))\n", "\n", "\n", "def plot_event_alignment(\n", "    eval_result: Dict[str, Any],\n", "    window_days: int,\n", "    title_prefix: str,\n", "    price_color: str = \"#1f77b4\",\n", "    up_color: str = \"green\",\n", "    down_color: str = \"red\",\n", "    shade_alpha: float = 0.20,\n", ") -> None:\n", "    frame = eval_result[\"test_frame\"].copy().reset_index(drop=True)\n", "    frame[\"date\"] = pd.to_datetime(frame[\"date\"])\n", "\n", "    true_events = build_true_turn_events(\n", "        eval_result=eval_result,\n", "        mode=TRUE_EVENT_MODE,\n", "        min_move_pct=TRUE_EVENT_MIN_MOVE_PCT,\n", "        min_segment_days=TRUE_EVENT_MIN_SEGMENT_DAYS,\n", "    )\n", "    pred_events = build_pred_switch_events(frame[\"date\"], frame[\"pred\"].to_numpy(dtype=np.int32))\n", "    matches = match_events_by_window(true_events=true_events, pred_events=pred_events, window_days=window_days)\n", "    m = compute_event_metrics(true_events=true_events, pred_events=pred_events, matches=matches)\n", "\n", "    dates = frame[\"date\"]\n", "    prices = pd.to_numeric(frame[\"close\"], errors=\"coerce\").to_numpy(dtype=float)\n", "    pred = frame[\"pred\"].to_numpy(dtype=np.int32)\n", "\n", "    if len(frame) == 0:\n", "        print(f\"[{title_prefix}] empty frame\")\n", "        return\n", "\n", "    p_min = float(np.nanmin(prices))\n", "    p_max = float(np.nanmax(prices))\n", "    margin = (p_max - p_min) * 0.05 if p_max > p_min else 1.0\n", "    fill_min = p_min - margin\n", "    fill_max = p_max + margin\n", "\n", "    fig, ax = plt.subplots(1, 1, figsize=(16, 5))\n", "    ax.plot(dates, prices, color=price_color, linewidth=1.5, label=\"Price\")\n", "    ax.fill_between(dates, fill_min, fill_max, where=(pred == 1), color=up_color, alpha=shade_alpha, step=\"mid\", label=\"Pred UP\")\n", "    ax.fill_between(dates, fill_min, fill_max, where=(pred == 0), color=down_color, alpha=shade_alpha, step=\"mid\", label=\"Pred DOWN\")\n", "\n", "    for _, r in true_events.iterrows():\n", "        clr = \"#0b6e0b\" if int(r[\"new_regime\"]) == 1 else \"#b30000\"\n", "        ax.axvline(pd.to_datetime(r[\"date\"]), color=clr, linestyle=\"--\", alpha=0.6, linewidth=1.2)\n", "\n", "    for _, r in matches.iterrows():\n", "        ax.plot(pd.to_datetime(r[\"pred_date\"]), fill_max, marker=\"o\", markersize=4, color=\"black\")\n", "\n", "    ax.set_ylim(fill_min, fill_max)\n", "    ax.set_ylabel(\"Price\")\n", "    ax.set_xlabel(\"Date\")\n", "    ax.grid(True, alpha=0.3, linestyle=\":\")\n", "    ax.legend(loc=\"upper left\")\n", "    ax.set_title(\n", "        f\"{title_prefix} | true_mode={TRUE_EVENT_MODE} | event_window=±{window_days}d | \"\n", "        f\"recall_true={m['recall_true']:.3f} precision_pred={m['precision_pred']:.3f} \"\n", "        f\"mean_abs_lag={m['mean_abs_lag_days']:.2f}d\"\n", "    )\n", "    plt.tight_layout()\n", "    plt.show()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_results_raw = pd.read_csv(CHECKPOINT_PATH)\n", "df_results = sort_results_frame(df_results_raw).reset_index(drop=True)\n", "\n", "best_row, honest_row, pool_sizes = pick_grid_best_and_honest(df_results)\n", "\n", "print(f\"rows={len(df_results)}\")\n", "print(f\"feasible={pool_sizes['n_feasible']}/{pool_sizes['n_all']}\")\n", "print(f\"honest_pool={pool_sizes['n_honest_pool']}\")\n", "\n", "metric_cols = [\n", "    \"test_profit_y_obj\", \"test_profit_y\",\n", "    \"val_recall_min\", \"val_recall_gap\",\n", "    \"test_recall_min\", \"test_recall_gap\",\n", "    \"mcc\", \"bal_acc\",\n", "]\n", "print(\"\\n[A] grid_best from checkpoint\")\n", "display(pd.DataFrame([best_row[metric_cols]]))\n", "print(\"[B] honest candidate from checkpoint\")\n", "display(pd.DataFrame([honest_row[metric_cols]]))\n", "\n", "candidate_rows = {\n", "    \"grid_best\": best_row,\n", "    \"honest\": honest_row,\n", "}\n", "candidate_family_size = {\n", "    \"grid_best\": int(pool_sizes[\"n_all\"]),\n", "    \"honest\": int(pool_sizes[\"n_honest_pool\"]),\n", "}\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["df_market, close_map = build_market_and_close_map(data_start=DATA_START)\n", "feature_cache: dict[tuple[str, str, float], pd.DataFrame] = {}\n", "\n", "eval_results: dict[str, dict] = {}\n", "for tag, row in candidate_rows.items():\n", "    print(f\"[EVAL] {tag}\")\n", "    eval_results[tag] = evaluate_candidate(\n", "        row=row,\n", "        tag=tag,\n", "        df_market=df_market,\n", "        close_map=close_map,\n", "        feature_cache=feature_cache,\n", "        seed=SEED,\n", "    )\n", "\n", "summary_rows = []\n", "for tag, res in eval_results.items():\n", "    tm = res[\"test_metrics\"]\n", "    vm = res[\"val_metrics\"]\n", "    sig = res[\"significance_test\"]\n", "    bci = res[\"bootstrap_ci\"]\n", "\n", "    summary_rows.append(\n", "        {\n", "            \"candidate\": tag,\n", "            \"device\": res[\"used_device\"],\n", "            \"threshold\": res[\"threshold\"],\n", "            \"test_profit_y_obj\": res[\"test_profit_y_obj\"],\n", "            \"test_profit_y\": res[\"test_profit_y\"],\n", "            \"test_recall_up\": tm[\"recall_up\"],\n", "            \"test_recall_down\": tm[\"recall_down\"],\n", "            \"test_recall_min\": tm[\"recall_min\"],\n", "            \"test_recall_gap\": tm[\"recall_gap\"],\n", "            \"test_bal_acc\": tm[\"balanced_accuracy\"],\n", "            \"test_mcc\": tm[\"mcc\"],\n", "            \"val_recall_min\": vm[\"recall_min\"],\n", "            \"val_recall_gap\": vm[\"recall_gap\"],\n", "            \"acc_p_value_vs_random\": sig[\"p_value_vs_random\"],\n", "            \"acc_ci95_low\": sig[\"ci95_low\"],\n", "            \"acc_ci95_high\": sig[\"ci95_high\"],\n", "            \"boot_bal_acc_ci\": bci[\"bal_acc\"] if bci else None,\n", "            \"boot_mcc_ci\": bci[\"mcc\"] if bci else None,\n", "            \"test_rows\": res[\"rows\"][\"test\"],\n", "        }\n", "    )\n", "\n", "df_candidate_summary = pd.DataFrame(summary_rows)\n", "display(df_candidate_summary)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["event_rows = []\n", "\n", "for tag, res in eval_results.items():\n", "    frame = res[\"test_frame\"].copy().reset_index(drop=True)\n", "    frame[\"date\"] = pd.to_datetime(frame[\"date\"])\n", "    true_events = build_true_turn_events(\n", "        eval_result=res,\n", "        mode=TRUE_EVENT_MODE,\n", "        min_move_pct=TRUE_EVENT_MIN_MOVE_PCT,\n", "        min_segment_days=TRUE_EVENT_MIN_SEGMENT_DAYS,\n", "    )\n", "\n", "    for w in EVENT_WINDOWS:\n", "        perm = circular_shift_permutation_test(\n", "            dates=frame[\"date\"],\n", "            pred_labels=frame[\"pred\"].to_numpy(dtype=np.int32),\n", "            true_events=true_events,\n", "            window_days=int(w),\n", "        )\n", "\n", "        obs = perm[\"obs\"]\n", "        fam = int(candidate_family_size.get(tag, len(df_results)))\n", "\n", "        event_rows.append(\n", "            {\n", "                \"candidate\": tag,\n", "                \"window_days\": int(w),\n", "                \"n_true_events\": int(obs[\"n_true_events\"]),\n", "                \"n_pred_events\": int(obs[\"n_pred_events\"]),\n", "                \"n_matched\": int(obs[\"n_matched\"]),\n", "                \"recall_true\": obs[\"recall_true\"],\n", "                \"precision_pred\": obs[\"precision_pred\"],\n", "                \"f1_event\": obs[\"f1_event\"],\n", "                \"mean_abs_lag_days\": obs[\"mean_abs_lag_days\"],\n", "                \"median_lag_days\": obs[\"median_lag_days\"],\n", "                \"lead_share\": obs[\"lead_share\"],\n", "                \"p_shift_recall\": perm[\"p_recall\"],\n", "                \"p_shift_recall_bonf\": bonferroni_correction(perm[\"p_recall\"], fam),\n", "                \"p_shift_abs_lag\": perm[\"p_abs_lag\"],\n", "                \"p_shift_abs_lag_bonf\": bonferroni_correction(perm[\"p_abs_lag\"], fam),\n", "                \"null_recall_mean\": perm[\"null_recall_mean\"],\n", "                \"null_recall_std\": perm[\"null_recall_std\"],\n", "                \"null_abs_lag_mean\": perm[\"null_abs_lag_mean\"],\n", "                \"n_permutations\": perm[\"n_permutations\"],\n", "                \"family_size_correction\": fam,\n", "            }\n", "        )\n", "\n", "df_event_stats = pd.DataFrame(event_rows).sort_values([\"candidate\", \"window_days\"]).reset_index(drop=True)\n", "print(\"Event-level alignment statistics (real turns vs predicted switches):\")\n", "display(df_event_stats)\n", "\n", "# Focus view: strongest temporal evidence per candidate (smallest corrected p for recall).\n", "focus = df_event_stats.sort_values([\"candidate\", \"p_shift_recall_bonf\", \"window_days\"]).groupby(\"candidate\", as_index=False).head(1)\n", "print(\"Best event-window per candidate (by corrected recall p-value):\")\n", "display(focus)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["PLOT_WINDOW = 3\n", "for tag, res in eval_results.items():\n", "    plot_event_alignment(\n", "        eval_result=res,\n", "        window_days=PLOT_WINDOW,\n", "        title_prefix=f\"{tag}\",\n", "        price_color=\"#1f77b4\",\n", "        up_color=\"green\",\n", "        down_color=\"red\",\n", "        shade_alpha=0.20,\n", "    )\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"Statistical conclusion summary:\")\n", "\n", "for tag in sorted(eval_results.keys()):\n", "    cls = df_candidate_summary[df_candidate_summary[\"candidate\"] == tag].iloc[0]\n", "    evt = df_event_stats[df_event_stats[\"candidate\"] == tag].sort_values([\"p_shift_recall_bonf\", \"window_days\"]).iloc[0]\n", "\n", "    print(\"\\n\" + \"=\" * 90)\n", "    print(f\"Candidate: {tag}\")\n", "    print(\"Classification significance:\")\n", "    print(\n", "        f\"  accuracy p-value vs random = {float(cls['acc_p_value_vs_random']):.6g}, \"\n", "        f\"95% CI = [{float(cls['acc_ci95_low']):.3f}, {float(cls['acc_ci95_high']):.3f}]\"\n", "    )\n", "    print(\n", "        f\"  test_recall_min = {float(cls['test_recall_min']):.3f}, \"\n", "        f\"test_recall_gap = {float(cls['test_recall_gap']):.3f}, \"\n", "        f\"test_profit_y_obj = {float(cls['test_profit_y_obj']):+.6f}\"\n", "    )\n", "\n", "    print(\"Event-time alignment significance (best window by corrected p):\")\n", "    print(\n", "        f\"  window = ±{int(evt['window_days'])}d, recall_true = {float(evt['recall_true']):.3f}, \"\n", "        f\"precision_pred = {float(evt['precision_pred']):.3f}, mean_abs_lag = {float(evt['mean_abs_lag_days']):.2f}d\"\n", "    )\n", "    print(\n", "        f\"  circular-shift p(recall) = {float(evt['p_shift_recall']):.6g}, \"\n", "        f\"Bonferroni corrected = {float(evt['p_shift_recall_bonf']):.6g} \"\n", "        f\"(family={int(evt['family_size_correction'])})\"\n", "    )\n", "\n", "    if np.isfinite(evt[\"p_shift_recall_bonf\"]) and float(evt[\"p_shift_recall_bonf\"]) < 0.05:\n", "        print(\"  Verdict: temporal alignment is statistically significant even after conservative correction.\")\n", "    elif np.isfinite(evt[\"p_shift_recall\"]) and float(evt[\"p_shift_recall\"]) < 0.05:\n", "        print(\"  Verdict: raw significance exists, but conservative correction removes formal significance.\")\n", "    else:\n", "        print(\"  Verdict: no strong event-time significance under current conservative test.\")\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## What Dashed Vertical Lines Mean\n", "\n", "- Now default truth mode is **market-based** (`TRUE_EVENT_MODE=\"market_sign_change\"`).\n", "- Dashed lines are **market-truth regime switch events** built from `next_ret` sign changes, with deadzone and short-segment filtering.\n", "- Green dashed line: switch to UP regime.\n", "- Red dashed line: switch to DOWN regime.\n", "- Black markers at top: predicted switches matched to those market-truth events under current `event_window`.\n", "- Background shading remains model prediction (green=UP, red=DOWN).\n", "- If needed, set `TRUE_EVENT_MODE=\"turning_points\"` only for debug, not for final inference.\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Sweep broader radii for already evaluated candidates (grid_best/honest).\n", "RADIUS_SWEEP_DAYS = [1, 2, 3, 4, 5, 6, 7, 10, 14]\n", "\n", "wide_rows = []\n", "for tag, res in eval_results.items():\n", "    frame = res[\"test_frame\"].copy().reset_index(drop=True)\n", "    frame[\"date\"] = pd.to_datetime(frame[\"date\"])\n", "    true_events = build_true_turn_events(\n", "        eval_result=res,\n", "        mode=TRUE_EVENT_MODE,\n", "        min_move_pct=TRUE_EVENT_MIN_MOVE_PCT,\n", "        min_segment_days=TRUE_EVENT_MIN_SEGMENT_DAYS,\n", "    )\n", "\n", "    for w in RADIUS_SWEEP_DAYS:\n", "        perm = circular_shift_permutation_test(\n", "            dates=frame[\"date\"],\n", "            pred_labels=frame[\"pred\"].to_numpy(dtype=np.int32),\n", "            true_events=true_events,\n", "            window_days=int(w),\n", "        )\n", "        obs = perm[\"obs\"]\n", "        fam = int(candidate_family_size.get(tag, len(df_results)))\n", "        wide_rows.append({\n", "            \"candidate\": tag,\n", "            \"window_days\": int(w),\n", "            \"n_true_events\": int(obs[\"n_true_events\"]),\n", "            \"n_pred_events\": int(obs[\"n_pred_events\"]),\n", "            \"n_matched\": int(obs[\"n_matched\"]),\n", "            \"recall_true\": obs[\"recall_true\"],\n", "            \"precision_pred\": obs[\"precision_pred\"],\n", "            \"f1_event\": obs[\"f1_event\"],\n", "            \"mean_abs_lag_days\": obs[\"mean_abs_lag_days\"],\n", "            \"p_shift_recall\": perm[\"p_recall\"],\n", "            \"p_shift_recall_bonf\": bonferroni_correction(perm[\"p_recall\"], fam),\n", "            \"null_recall_mean\": perm[\"null_recall_mean\"],\n", "            \"delta_recall_vs_null\": (obs[\"recall_true\"] - perm[\"null_recall_mean\"]) if (np.isfinite(obs[\"recall_true\"]) and np.isfinite(perm[\"null_recall_mean\"])) else np.nan,\n", "        })\n", "\n", "df_radius_sweep_two = pd.DataFrame(wide_rows).sort_values([\"candidate\", \"window_days\"]).reset_index(drop=True)\n", "print(\"Broader radius sweep for grid_best/honest:\")\n", "display(df_radius_sweep_two)\n", "\n", "for tag in sorted(df_radius_sweep_two[\"candidate\"].unique()):\n", "    sub = df_radius_sweep_two[df_radius_sweep_two[\"candidate\"] == tag].copy()\n", "    best = sub.sort_values([\"p_shift_recall_bonf\", \"window_days\"]).iloc[0]\n", "    print(f\"[{tag}] best radius by corrected p: ±{int(best['window_days'])}d | recall={float(best['recall_true']):.3f} | p_bonf={float(best['p_shift_recall_bonf']):.6g}\")\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "from datetime import timedelta\n", "\n", "TOP_N = 100\n", "TOP_POOL = \"feasible\"  # \"feasible\" or \"all\"\n", "TOP_WINDOW_SWEEP = [1, 2, 3, 4, 5, 6, 7, 10, 14]\n", "RUN_TOP100_NOW = True\n", "\n", "TOP_STATS_PATH = Path(REPORTS_DIR) / f\"{RUN_TAG}_top{TOP_N}_event_stats.csv\"\n", "\n", "\n", "def _select_top_candidates(df_sorted: pd.DataFrame, top_n: int, pool: str = \"feasible\") -> pd.DataFrame:\n", "    if str(pool).lower() == \"feasible\":\n", "        d = df_sorted[df_sorted.get(\"is_feasible\", 0) == 1].copy()\n", "        if d.empty:\n", "            d = df_sorted.copy()\n", "    else:\n", "        d = df_sorted.copy()\n", "    d = d.head(int(top_n)).copy().reset_index(drop=True)\n", "    d[\"candidate_rank\"] = np.arange(1, len(d) + 1, dtype=int)\n", "    return d\n", "\n", "\n", "def _candidate_key(row: pd.Series) -> str:\n", "    rank = int(row.get(\"candidate_rank\", -1))\n", "    eval_id = int(row.get(\"eval_id\", -1)) if np.isfinite(pd.to_numeric(row.get(\"eval_id\", np.nan), errors=\"coerce\")) else -1\n", "    return f\"rank{rank:03d}_eval{eval_id}\"\n", "\n", "\n", "def _eta_str(elapsed_sec: float, done: int, total: int) -> str:\n", "    if done <= 0:\n", "        return \"?\"\n", "    left = max(0, int(total - done))\n", "    per = elapsed_sec / max(1, done)\n", "    eta = timedelta(seconds=int(per * left))\n", "    return str(eta)\n", "\n", "\n", "def run_topn_event_sweep(\n", "    df_sorted: pd.DataFrame,\n", "    df_market_local: pd.DataFrame,\n", "    close_map_local: pd.DataFrame,\n", "    feature_cache_local: dict[tuple[str, str, float], pd.DataFrame],\n", "    top_n: int = 100,\n", "    pool: str = \"feasible\",\n", "    windows: list[int] | None = None,\n", "    out_path: Path | None = None,\n", ") -> pd.DataFrame:\n", "    ws = windows or [1, 2, 3, 5, 7]\n", "    out_path = out_path or TOP_STATS_PATH\n", "    selected = _select_top_candidates(df_sorted, top_n=top_n, pool=pool)\n", "\n", "    if out_path.exists():\n", "        df_existing = pd.read_csv(out_path)\n", "    else:\n", "        df_existing = pd.DataFrame()\n", "\n", "    done_keys = set(df_existing[\"candidate_key\"].astype(str).tolist()) if not df_existing.empty and \"candidate_key\" in df_existing.columns else set()\n", "    rows_acc = []\n", "\n", "    t0 = time.time()\n", "    total = len(selected)\n", "    done = 0\n", "\n", "    print(f\"[TOP-N] selected={total} pool={pool} windows={ws}\")\n", "    if len(done_keys) > 0:\n", "        print(f\"[TOP-N] resume from checkpoint: {len(done_keys)} candidate(s) already done\")\n", "\n", "    for _, row in selected.iterrows():\n", "        key = _candidate_key(row)\n", "        if key in done_keys:\n", "            done += 1\n", "            continue\n", "\n", "        tag = f\"top{int(row[\"candidate_rank\"]):03d}\"\n", "        print(f\"[TOP-N EVAL] {tag} key={key} ({done+1}/{total})\")\n", "\n", "        ev = evaluate_candidate(\n", "            row=row,\n", "            tag=tag,\n", "            df_market=df_market_local,\n", "            close_map=close_map_local,\n", "            feature_cache=feature_cache_local,\n", "            seed=SEED,\n", "        )\n", "\n", "        frame = ev[\"test_frame\"].copy().reset_index(drop=True)\n", "        frame[\"date\"] = pd.to_datetime(frame[\"date\"])\n", "        true_events = build_true_turn_events(\n", "            eval_result=ev,\n", "            mode=TRUE_EVENT_MODE,\n", "            min_move_pct=TRUE_EVENT_MIN_MOVE_PCT,\n", "            min_segment_days=TRUE_EVENT_MIN_SEGMENT_DAYS,\n", "        )\n", "        family_within = len(ws)\n", "\n", "        for w in ws:\n", "            perm = circular_shift_permutation_test(\n", "                dates=frame[\"date\"],\n", "                pred_labels=frame[\"pred\"].to_numpy(dtype=np.int32),\n", "                true_events=true_events,\n", "                window_days=int(w),\n", "            )\n", "            obs = perm[\"obs\"]\n", "            p_raw = perm[\"p_recall\"]\n", "\n", "            rows_acc.append({\n", "                \"candidate_key\": key,\n", "                \"candidate_rank\": int(row[\"candidate_rank\"]),\n", "                \"eval_id\": int(row.get(\"eval_id\", -1)) if np.isfinite(pd.to_numeric(row.get(\"eval_id\", np.nan), errors=\"coerce\")) else -1,\n", "                \"window_days\": int(w),\n", "                \"test_profit_y_obj\": float(ev[\"test_profit_y_obj\"]),\n", "                \"test_profit_y\": float(ev[\"test_profit_y\"]),\n", "                \"test_recall_min\": float(ev[\"test_metrics\"][\"recall_min\"]),\n", "                \"test_recall_gap\": float(ev[\"test_metrics\"][\"recall_gap\"]),\n", "                \"test_mcc\": float(ev[\"test_metrics\"][\"mcc\"]),\n", "                \"n_true_events\": int(obs[\"n_true_events\"]),\n", "                \"n_pred_events\": int(obs[\"n_pred_events\"]),\n", "                \"n_matched\": int(obs[\"n_matched\"]),\n", "                \"recall_true\": obs[\"recall_true\"],\n", "                \"precision_pred\": obs[\"precision_pred\"],\n", "                \"f1_event\": obs[\"f1_event\"],\n", "                \"mean_abs_lag_days\": obs[\"mean_abs_lag_days\"],\n", "                \"p_shift_recall\": p_raw,\n", "                \"p_shift_recall_within_bonf\": bonferroni_correction(p_raw, family_within),\n", "                \"null_recall_mean\": perm[\"null_recall_mean\"],\n", "                \"null_recall_std\": perm[\"null_recall_std\"],\n", "                \"delta_recall_vs_null\": (obs[\"recall_true\"] - perm[\"null_recall_mean\"]) if (np.isfinite(obs[\"recall_true\"]) and np.isfinite(perm[\"null_recall_mean\"])) else np.nan,\n", "                \"n_permutations\": int(perm[\"n_permutations\"]),\n", "            })\n", "\n", "        done += 1\n", "        elapsed = time.time() - t0\n", "        speed = done / max(1e-9, elapsed)\n", "        print(f\"[TOP-N PROGRESS] done={done}/{total} elapsed={timedelta(seconds=int(elapsed))} eta~{_eta_str(elapsed, done, total)} speed={speed:.3f}/s\")\n", "\n", "        # checkpoint after every candidate\n", "        if len(rows_acc) > 0:\n", "            df_new = pd.DataFrame(rows_acc)\n", "            if df_existing.empty:\n", "                df_existing = df_new.copy()\n", "            else:\n", "                df_existing = pd.concat([df_existing, df_new], ignore_index=True)\n", "            rows_acc = []\n", "            df_existing.to_csv(out_path, index=False)\n", "            print(f\"[TOP-N CHECKPOINT] {out_path} rows={len(df_existing)}\")\n", "\n", "    if len(rows_acc) > 0:\n", "        df_new = pd.DataFrame(rows_acc)\n", "        if df_existing.empty:\n", "            df_existing = df_new.copy()\n", "        else:\n", "            df_existing = pd.concat([df_existing, df_new], ignore_index=True)\n", "        df_existing.to_csv(out_path, index=False)\n", "\n", "    return df_existing\n", "\n", "\n", "def bh_fdr(p_values: np.ndarray) -> np.ndarray:\n", "    p = np.asarray(p_values, dtype=float)\n", "    n = len(p)\n", "    out = np.full(n, np.nan, dtype=float)\n", "    mask = np.isfinite(p)\n", "    idx = np.where(mask)[0]\n", "    if idx.size == 0:\n", "        return out\n", "    pv = p[idx]\n", "    order = np.argsort(pv)\n", "    ranked = pv[order]\n", "    m = len(ranked)\n", "    q = np.empty(m, dtype=float)\n", "    q[-1] = ranked[-1]\n", "    for i in range(m - 2, -1, -1):\n", "        q[i] = min(q[i + 1], ranked[i] * m / (i + 1))\n", "    q = np.clip(q, 0.0, 1.0)\n", "    unsorted = np.empty(m, dtype=float)\n", "    unsorted[order] = q\n", "    out[idx] = unsorted\n", "    return out\n", "\n", "\n", "def safe_binomtest_greater(k: int, n: int, p0: float = 0.05) -> float:\n", "    if n <= 0:\n", "        return np.nan\n", "    try:\n", "        from scipy.stats import binomtest  # type: ignore\n", "        return float(binomtest(k=k, n=n, p=p0, alternative=\"greater\").pvalue)\n", "    except Exception:\n", "        # fallback Monte-Carlo approximation\n", "        rng = np.random.default_rng(42)\n", "        sims = rng.binomial(n=n, p=p0, size=50000)\n", "        return float((1 + np.sum(sims >= k)) / (1 + len(sims)))\n", "\n", "\n", "def safe_fisher_method(p_values: np.ndarray) -> float:\n", "    pv = np.asarray(p_values, dtype=float)\n", "    pv = pv[np.isfinite(pv)]\n", "    pv = np.clip(pv, 1e-15, 1.0)\n", "    if pv.size == 0:\n", "        return np.nan\n", "    try:\n", "        from scipy.stats import combine_pvalues  # type: ignore\n", "        _, p = combine_pvalues(pv, method=\"fisher\")\n", "        return float(p)\n", "    except Exception:\n", "        stat = -2.0 * float(np.sum(np.log(pv)))\n", "        # rough fallback: return NaN if scipy unavailable\n", "        return np.nan\n", "\n", "\n", "if RUN_TOP100_NOW:\n", "    df_top100_stats = run_topn_event_sweep(\n", "        df_sorted=df_results,\n", "        df_market_local=df_market,\n", "        close_map_local=close_map,\n", "        feature_cache_local=feature_cache,\n", "        top_n=TOP_N,\n", "        pool=TOP_POOL,\n", "        windows=TOP_WINDOW_SWEEP,\n", "        out_path=TOP_STATS_PATH,\n", "    )\n", "else:\n", "    if TOP_STATS_PATH.exists():\n", "        df_top100_stats = pd.read_csv(TOP_STATS_PATH)\n", "    else:\n", "        raise FileNotFoundError(f\"Top-N stats file not found: {TOP_STATS_PATH}. Set RUN_TOP100_NOW=True to compute.\")\n", "\n", "print(f\"Top-N stats rows: {len(df_top100_stats)}\")\n", "display(df_top100_stats.head(20))\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Global statistical summary over top-100 candidates.\n", "\n", "df_top = df_top100_stats.copy()\n", "if df_top.empty:\n", "    raise ValueError(\"Top-N stats are empty\")\n", "\n", "# Per-window aggregate (does a wider radius improve event-time signal?).\n", "agg_window = df_top.groupby(\"window_days\", as_index=False).agg(\n", "    n_rows=(\"candidate_key\", \"count\"),\n", "    n_candidates=(\"candidate_key\", pd.Series.nunique),\n", "    mean_recall_true=(\"recall_true\", \"mean\"),\n", "    mean_null_recall=(\"null_recall_mean\", \"mean\"),\n", "    mean_delta_recall=(\"delta_recall_vs_null\", \"mean\"),\n", "    median_delta_recall=(\"delta_recall_vs_null\", \"median\"),\n", "    share_delta_pos=(\"delta_recall_vs_null\", lambda x: float(np.mean(pd.to_numeric(x, errors=\"coerce\") > 0.0))),\n", "    share_raw_p_lt_005=(\"p_shift_recall\", lambda x: float(np.mean(pd.to_numeric(x, errors=\"coerce\") < 0.05))),\n", ")\n", "agg_window = agg_window.sort_values(\"window_days\").reset_index(drop=True)\n", "print(\"Per-window aggregate:\")\n", "display(agg_window)\n", "\n", "# Candidate-level best window by smallest within-candidate Bonferroni p.\n", "cand_best = (\n", "    df_top.sort_values([\"candidate_key\", \"p_shift_recall_within_bonf\", \"window_days\"])\n", "    .groupby(\"candidate_key\", as_index=False)\n", "    .head(1)\n", "    .reset_index(drop=True)\n", ")\n", "cand_best[\"q_bh_across_candidates\"] = bh_fdr(cand_best[\"p_shift_recall_within_bonf\"].to_numpy(dtype=float))\n", "\n", "n_cand = int(cand_best[\"candidate_key\"].nunique())\n", "k_raw = int(np.sum(pd.to_numeric(cand_best[\"p_shift_recall_within_bonf\"], errors=\"coerce\") < 0.05))\n", "k_fdr = int(np.sum(pd.to_numeric(cand_best[\"q_bh_across_candidates\"], errors=\"coerce\") < 0.10))\n", "\n", "p_binom = safe_binomtest_greater(k=k_raw, n=n_cand, p0=0.05)\n", "p_fisher = safe_fisher_method(cand_best[\"p_shift_recall_within_bonf\"].to_numpy(dtype=float))\n", "\n", "mean_delta = float(pd.to_numeric(cand_best[\"delta_recall_vs_null\"], errors=\"coerce\").mean())\n", "share_delta_pos = float(np.mean(pd.to_numeric(cand_best[\"delta_recall_vs_null\"], errors=\"coerce\") > 0.0))\n", "\n", "best_window_row = agg_window.sort_values([\"mean_delta_recall\", \"share_raw_p_lt_005\"], ascending=[False, False]).iloc[0]\n", "best_window = int(best_window_row[\"window_days\"])\n", "\n", "print(\"\\nGlobal inference summary (Top-N):\")\n", "print(f\"  candidates analyzed: {n_cand}\")\n", "print(f\"  raw significant candidates (p_within<0.05): {k_raw}/{n_cand}\")\n", "print(f\"  FDR significant candidates (q<0.10): {k_fdr}/{n_cand}\")\n", "print(f\"  binomial p-value for excess significant candidates vs 5% null: {p_binom:.6g}\")\n", "print(f\"  Fisher combined p-value (candidate best-window p-values): {p_fisher:.6g}\")\n", "print(f\"  mean delta recall vs null at candidate-best windows: {mean_delta:+.4f}\")\n", "print(f\"  share(delta_recall_vs_null > 0): {share_delta_pos:.3f}\")\n", "print(f\"  empirically best radius (by aggregate delta recall): ±{best_window} days\")\n", "\n", "display(cand_best.sort_values([\"p_shift_recall_within_bonf\", \"q_bh_across_candidates\"]).head(30))\n", "\n", "if np.isfinite(p_binom) and p_binom < 0.05:\n", "    print(\"\\nVerdict: there is aggregate statistical evidence that astro-only models align with real regime-switch timing above null.\")\n", "else:\n", "    print(\"\\nVerdict: under this conservative test, aggregate timing dependence is not yet statistically proven.\")\n"]}], "metadata": {"kernelspec": {"display_name": "btc", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}