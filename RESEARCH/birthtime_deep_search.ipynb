{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fdd6871",
   "metadata": {},
   "source": [
    "# ðŸ§  Deep Model Tuning for Natal Chart\n",
    "\n",
    "ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð³Ð¸Ð¿Ð¾Ñ‚ÐµÐ·Ñ‹: \"Ð£Ð²ÐµÐ»Ð¸Ñ‡ÐµÐ½Ð¸Ðµ ÑÐ»Ð¾Ð¶Ð½Ð¾ÑÑ‚Ð¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (Ð³Ð»ÑƒÐ±Ð¸Ð½Ñ‹ Ð´ÐµÑ€ÐµÐ²ÑŒÐµÐ²) Ð¿Ð¾Ð¼Ð¾Ð¶ÐµÑ‚ Ð¿ÐµÑ€ÐµÐ²Ð°Ñ€Ð¸Ñ‚ÑŒ 2000+ Ð¿Ñ€Ð¸Ð·Ð½Ð°ÐºÐ¾Ð² Ð½Ð°Ñ‚Ð°Ð»ÑŒÐ½Ð¾Ð¹ ÐºÐ°Ñ€Ñ‚Ñ‹\".\n",
    "\n",
    "Ð”Ð°Ñ‚Ð°: **2009-10-10 20:50 UTC** (Ð›ÑƒÑ‡ÑˆÐ°Ñ Ð¸Ð· birthtime search)\n",
    "ÐŸÑ€Ð¸Ð·Ð½Ð°ÐºÐ¸: Ð¢Ñ€Ð°Ð½Ð·Ð¸Ñ‚Ñ‹ + ÐÑÐ¿ÐµÐºÑ‚Ñ‹ + Ð”Ð¾Ð¼Ð° (Placidus) + Ð¤Ð°Ð·Ñ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6870eafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, date, timezone\n",
    "from sklearn.metrics import classification_report, matthews_corrcoef\n",
    "\n",
    "PROJECT_ROOT = Path(\"/home/rut/ostrofun\")\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from RESEARCH.config import cfg\n",
    "from RESEARCH.data_loader import load_market_data\n",
    "from RESEARCH.labeling import create_balanced_labels\n",
    "from RESEARCH.astro_engine import (\n",
    "    init_ephemeris,\n",
    "    calculate_bodies_for_dates_multi,\n",
    "    calculate_aspects_for_dates,\n",
    "    calculate_transits_for_dates,\n",
    "    calculate_phases_for_dates,\n",
    "    get_natal_bodies,\n",
    ")\n",
    "from RESEARCH.features import build_full_features, merge_features_with_labels\n",
    "from RESEARCH.model_training import split_dataset, prepare_xy, train_xgb_model, tune_threshold, predict_with_threshold, check_cuda_available\n",
    "# Ð˜Ð¼Ð¿Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ð´Ð¾Ð¼Ð¾Ð² Ð¸Ð· birthtime_search (ÐºÐ¾Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ñ… ÑÑŽÐ´Ð° Ð´Ð»Ñ Ð°Ð²Ñ‚Ð¾Ð½Ð¾Ð¼Ð½Ð¾ÑÑ‚Ð¸)\n",
    "import swisseph as swe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbfa55f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Config\n",
    "TARGET_DT = datetime(2009, 10, 10, 20, 50, 0, tzinfo=timezone.utc)\n",
    "LAT, LON = 60.1699, 24.9384 # Helsinki\n",
    "\n",
    "ASTRO_CONFIG = {\n",
    "    \"coord_mode\": \"both\",\n",
    "    \"orb_mult\": 0.15,\n",
    "    \"gauss_window\": 300,\n",
    "    \"gauss_std\": 70.0,\n",
    "    \"exclude_bodies\": None,\n",
    "}\n",
    "\n",
    "# Grid Search Space\n",
    "PARAM_GRID = {\n",
    "    \"n_estimators\": [300, 500, 800, 1200],\n",
    "    \"max_depth\": [3, 4, 6, 8],\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05],\n",
    "    \"colsample_bytree\": [0.6, 0.8], # ÐœÐµÐ½ÑŒÑˆÐµ = Ð±Ð¾Ð»ÑŒÑˆÐµ Ñ€Ð°Ð·Ð½Ð¾Ð¾Ð±Ñ€Ð°Ð·Ð¸Ñ Ð´ÐµÑ€ÐµÐ²ÑŒÐµÐ²\n",
    "    \"subsample\": [0.8],\n",
    "}\n",
    "\n",
    "print(f\"ðŸ§  Tuning for: {TARGET_DT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22893478",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Functions (Local copies to be self-contained)\n",
    "def calculate_houses_local(dt, lat, lon):\n",
    "    jd = swe.julday(dt.year, dt.month, dt.day, dt.hour + dt.minute/60.0 + dt.second/3600.0)\n",
    "    cusps, ascmc = swe.houses(jd, lat, lon, b'P')\n",
    "    return list(cusps)\n",
    "\n",
    "def get_house_positions_local(bodies, cusps):\n",
    "    result = {}\n",
    "    for body in bodies:\n",
    "        lon = body.body # FIXED from body.name\n",
    "        for i in range(12):\n",
    "            c_start, c_end = cusps[i], cusps[(i+1)%12]\n",
    "            if c_start > c_end:\n",
    "                if lon >= c_start or lon < c_end:\n",
    "                    result[body.body] = i + 1; break\n",
    "            elif c_start <= lon < c_end:\n",
    "                result[body.body] = i + 1; break\n",
    "        else: result[body.body] = 1\n",
    "    return result\n",
    "\n",
    "def build_house_features_local(transit_bodies, natal_cusps, natal_houses, orb=5.0):\n",
    "    features = {}\n",
    "    # 1. House Pos\n",
    "    t_houses = get_house_positions_local(transit_bodies, natal_cusps)\n",
    "    for b_name, h_num in t_houses.items():\n",
    "        for h in range(1, 13): features[f\"t_{b_name}_h{h}\"] = 1 if h_num == h else 0\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8dc14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare Data\n",
    "print(\"Loading data...\")\n",
    "df_market = load_market_data()\n",
    "df_market = df_market[df_market[\"date\"] >= \"2017-11-01\"].reset_index(drop=True)\n",
    "df_labels = create_balanced_labels(df_market, ASTRO_CONFIG[\"gauss_window\"], ASTRO_CONFIG[\"gauss_std\"])\n",
    "settings = init_ephemeris()\n",
    "_, device = check_cuda_available()\n",
    "\n",
    "print(\"Calculating astro...\")\n",
    "df_bodies, geo_by_date, helio_by_date = calculate_bodies_for_dates_multi(\n",
    "    df_market[\"date\"], settings, coord_mode=\"both\"\n",
    ")\n",
    "bodies_by_date = geo_by_date\n",
    "df_phases = calculate_phases_for_dates(bodies_by_date)\n",
    "\n",
    "# 2. Build Natal Features\n",
    "print(f\"Building natal features for {TARGET_DT}...\")\n",
    "natal_cusps = calculate_houses_local(TARGET_DT, LAT, LON)\n",
    "natal_bodies = get_natal_bodies(TARGET_DT.strftime(\"%Y-%m-%dT%H:%M:%S\"), settings)\n",
    "natal_houses = get_house_positions_local(natal_bodies, natal_cusps)\n",
    "\n",
    "house_feats = []\n",
    "for dt, t_bodies in tqdm(bodies_by_date.items(), desc=\"House Features\"):\n",
    "    hf = build_house_features_local(t_bodies, natal_cusps, natal_houses)\n",
    "    hf[\"date\"] = pd.to_datetime(dt)\n",
    "    house_feats.append(hf)\n",
    "df_house = pd.DataFrame(house_feats)\n",
    "\n",
    "df_transits = calculate_transits_for_dates(bodies_by_date, natal_bodies, settings, orb_mult=0.15)\n",
    "df_aspects = calculate_aspects_for_dates(bodies_by_date, settings, orb_mult=0.15)\n",
    "\n",
    "# 3. Full Dataset\n",
    "print(\"Merging dataset...\")\n",
    "df_base = build_full_features(\n",
    "    df_bodies, df_aspects, df_transits=df_transits, df_phases=df_phases, \n",
    "    include_pair_aspects=True, include_transit_aspects=True\n",
    ")\n",
    "df_base[\"date\"] = pd.to_datetime(df_base[\"date\"])\n",
    "df_full = df_base.merge(df_house, on=\"date\", how=\"left\").fillna(0)\n",
    "df_dataset = merge_features_with_labels(df_full, df_labels)\n",
    "\n",
    "print(f\"Dataset Shape: {df_dataset.shape}\")\n",
    "print(f\"Columns: {len(df_dataset.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911c92cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Grid Search\n",
    "print(\"ðŸš€ Starting Deep Grid Search...\")\n",
    "\n",
    "train_df, val_df, test_df = split_dataset(df_dataset)\n",
    "feature_cols = [c for c in df_dataset.columns if c not in [\"date\", \"target\"]]\n",
    "X_train, y_train = prepare_xy(train_df, feature_cols)\n",
    "X_val, y_val = prepare_xy(val_df, feature_cols)\n",
    "X_test, y_test = prepare_xy(test_df, feature_cols)\n",
    "\n",
    "results = []\n",
    "keys = PARAM_GRID.keys()\n",
    "combinations = list(product(*PARAM_GRID.values()))\n",
    "\n",
    "for vals in tqdm(combinations, desc=\"Grid Search\"):\n",
    "    params = dict(zip(keys, vals))\n",
    "    \n",
    "    # Train\n",
    "    model = train_xgb_model(\n",
    "        X_train, y_train, X_val, y_val, feature_cols, \n",
    "        n_classes=2, device=device, early_stopping_rounds=50, verbose=False,\n",
    "        **params\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    best_t, _ = tune_threshold(model, X_val, y_val, metric=\"recall_min\")\n",
    "    y_pred = predict_with_threshold(model, X_val, threshold=best_t) # Optimize on Val first\n",
    "    \n",
    "    # Test Metrics\n",
    "    y_test_pred = predict_with_threshold(model, X_test, threshold=best_t)\n",
    "    report = classification_report(y_test, y_test_pred, output_dict=True, zero_division=0)\n",
    "    r_min = min(report[\"0\"][\"recall\"], report[\"1\"][\"recall\"])\n",
    "    mcc = matthews_corrcoef(y_test, y_test_pred)\n",
    "    \n",
    "    res_row = params.copy()\n",
    "    res_row[\"R_MIN\"] = r_min\n",
    "    res_row[\"MCC\"] = mcc\n",
    "    results.append(res_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ede06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Analysis\n",
    "df_res = pd.DataFrame(results).sort_values(\"R_MIN\", ascending=False)\n",
    "print(\"\\nðŸ† TOP 10 MODELS:\")\n",
    "print(df_res.head(10))\n",
    "\n",
    "best = df_res.iloc[0]\n",
    "print(f\"\\nðŸ¥‡ WINNER PARAMS:\")\n",
    "print(best.to_dict())\n",
    "\n",
    "baseline_rmin = 0.587\n",
    "if best[\"R_MIN\"] > baseline_rmin:\n",
    "    print(f\"\\nðŸš€ SUCCESS! Deep model beat baseline! ({best['R_MIN']:.3f} > {baseline_rmin})\")\n",
    "else:\n",
    "    print(f\"\\nðŸ’€ FAILURE. Feature overload confirmed. ({best['R_MIN']:.3f} <= {baseline_rmin})\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
