{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# üî¨ Body Ablation Research\n",
                "\n",
                "Grid search over:\n",
                "- **Gauss params**: window √ó std\n",
                "- **Coord modes**: geo, helio, both\n",
                "- **Body exclusions**: top performers from single-body study"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from datetime import datetime\n",
                "from itertools import product\n",
                "\n",
                "# RESEARCH imports\n",
                "from RESEARCH.data_loader import load_market_data\n",
                "from RESEARCH.labeling import create_balanced_labels\n",
                "from RESEARCH.astro_engine import (\n",
                "    init_ephemeris,\n",
                "    calculate_bodies_for_dates_multi,\n",
                "    calculate_aspects_for_dates,\n",
                "    calculate_phases_for_dates,\n",
                ")\n",
                "from RESEARCH.features import build_full_features, merge_features_with_labels\n",
                "from RESEARCH.model_training import (\n",
                "    split_dataset,\n",
                "    prepare_xy,\n",
                "    train_xgb_model,\n",
                "    tune_threshold,\n",
                "    predict_with_threshold,\n",
                "    check_cuda_available,\n",
                ")\n",
                "from RESEARCH.evaluation import evaluate_model_full, compare_models"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model params (fixed)\n",
                "MODEL_PARAMS = {\n",
                "    'n_estimators': 500,\n",
                "    'max_depth': 6,\n",
                "    'learning_rate': 0.03,\n",
                "    'colsample_bytree': 0.6,\n",
                "    'subsample': 0.8,\n",
                "}\n",
                "\n",
                "# GRID SEARCH PARAMETERS\n",
                "GRID_PARAMS = {\n",
                "    'gauss_windows': [150, 200, 250],\n",
                "    'gauss_stds': [50.0, 70.0, 90.0],\n",
                "    'coord_modes': ['geo', 'helio', 'both'],  # Added helio!\n",
                "    'orb_mults': [0.1],\n",
                "}\n",
                "\n",
                "# Best bodies to exclude (from single-body ablation study)\n",
                "# Top 5: MeanNode, Pluto, Saturn, Venus, Neptune\n",
                "ABLATION_BODIES = [\n",
                "    [],  # Baseline\n",
                "    ['MeanNode'],\n",
                "    ['Pluto'],\n",
                "    ['Saturn'],\n",
                "    ['Venus'],\n",
                "    ['Neptune'],\n",
                "    ['MeanNode', 'Pluto'],\n",
                "    ['MeanNode', 'Saturn'],\n",
                "    ['MeanNode', 'Venus'],\n",
                "    ['Pluto', 'Saturn'],\n",
                "    ['Pluto', 'Venus'],\n",
                "]\n",
                "\n",
                "# Calculate total\n",
                "n_combos = len(GRID_PARAMS['coord_modes']) * len(GRID_PARAMS['gauss_windows']) * len(GRID_PARAMS['gauss_stds']) * len(ABLATION_BODIES)\n",
                "print(f'Total combinations: {n_combos}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Helper Functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_and_evaluate(\n",
                "    df_market, df_bodies, geo_by_date, settings,\n",
                "    gauss_window, gauss_std, orb_mult,\n",
                "    exclude_bodies=None, device='cpu', verbose=False,\n",
                "):\n",
                "    \"\"\"Train model with specific params and return evaluation.\"\"\"\n",
                "    # 1. Create labels\n",
                "    df_labels = create_balanced_labels(df_market, gauss_window=gauss_window, gauss_std=gauss_std)\n",
                "    \n",
                "    # 2. Calculate aspects\n",
                "    df_aspects = calculate_aspects_for_dates(geo_by_date, settings, orb_mult=orb_mult, progress=False)\n",
                "    \n",
                "    # 3. Calculate phases\n",
                "    df_phases = calculate_phases_for_dates(geo_by_date, progress=False)\n",
                "    \n",
                "    # 4. Build features\n",
                "    df_features = build_full_features(df_bodies, df_aspects, df_phases=df_phases, exclude_bodies=exclude_bodies)\n",
                "    \n",
                "    # 5. Merge with labels\n",
                "    df_dataset = merge_features_with_labels(df_features, df_labels)\n",
                "    if len(df_dataset) < 100:\n",
                "        return None\n",
                "    \n",
                "    # 6. Split\n",
                "    train_df, val_df, test_df = split_dataset(df_dataset)\n",
                "    feature_cols = [c for c in df_dataset.columns if c not in ['date', 'target']]\n",
                "    X_train, y_train = prepare_xy(train_df, feature_cols)\n",
                "    X_val, y_val = prepare_xy(val_df, feature_cols)\n",
                "    X_test, y_test = prepare_xy(test_df, feature_cols)\n",
                "    \n",
                "    # 7. Train\n",
                "    model = train_xgb_model(X_train, y_train, X_val, y_val, feature_cols, n_classes=2, device=device, **MODEL_PARAMS)\n",
                "    \n",
                "    # 8. Tune threshold\n",
                "    best_t, _ = tune_threshold(model, X_val, y_val, metric='recall_min', verbose=verbose)\n",
                "    \n",
                "    # 9. Predict\n",
                "    y_pred = predict_with_threshold(model, X_test, threshold=best_t)\n",
                "    \n",
                "    # 10. Metrics\n",
                "    from sklearn.metrics import classification_report, balanced_accuracy_score, matthews_corrcoef\n",
                "    report = classification_report(y_test, y_pred, labels=[0, 1], target_names=['DOWN', 'UP'], output_dict=True, zero_division=0)\n",
                "    \n",
                "    recall_down, recall_up = report['DOWN']['recall'], report['UP']['recall']\n",
                "    \n",
                "    return {\n",
                "        'model': model,\n",
                "        'threshold': best_t,\n",
                "        'n_features': len(feature_cols),\n",
                "        'recall_min': min(recall_down, recall_up),\n",
                "        'recall_gap': abs(recall_down - recall_up),\n",
                "        'recall_down': recall_down,\n",
                "        'recall_up': recall_up,\n",
                "        'balanced_accuracy': balanced_accuracy_score(y_test, y_pred),\n",
                "        'mcc': matthews_corrcoef(y_test, y_pred),\n",
                "        'f1_macro': report['macro avg']['f1-score'],\n",
                "        'y_test': y_test,\n",
                "        'y_pred': y_pred,\n",
                "        'test_dates': test_df['date'].reset_index(drop=True),\n",
                "    }"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data & Initialize"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Check device\n",
                "_, device = check_cuda_available()\n",
                "print(f'Device: {device}')\n",
                "\n",
                "# Load market data\n",
                "df_market = load_market_data()\n",
                "df_market = df_market[df_market['date'] >= '2017-11-01'].reset_index(drop=True)\n",
                "print(f'Market data: {len(df_market)} rows')\n",
                "\n",
                "# Initialize ephemeris\n",
                "settings = init_ephemeris()\n",
                "print(f'Bodies: {[b.name for b in settings.bodies]}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Pre-calculate Body Positions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Pre-calculate bodies for each coord mode\n",
                "cached_bodies = {}\n",
                "\n",
                "for coord_mode in GRID_PARAMS['coord_modes']:\n",
                "    print(f'\\nüìç Calculating bodies for {coord_mode}...')\n",
                "    df_bodies, geo_by_date, helio_by_date = calculate_bodies_for_dates_multi(\n",
                "        df_market['date'], settings, coord_mode=coord_mode, progress=True\n",
                "    )\n",
                "    cached_bodies[coord_mode] = (df_bodies, geo_by_date, helio_by_date)\n",
                "    print(f'  ‚Üí {len(df_bodies)} records, {len(df_bodies.columns)} columns')\n",
                "\n",
                "print('\\n‚úÖ All body positions cached!')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Baseline Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Baseline: coord=both, gauss=(200, 70), no exclusion\n",
                "df_bodies, geo_by_date, _ = cached_bodies['both']\n",
                "\n",
                "baseline = train_and_evaluate(\n",
                "    df_market, df_bodies, geo_by_date, settings,\n",
                "    gauss_window=200, gauss_std=70.0, orb_mult=0.1,\n",
                "    exclude_bodies=None, device=device, verbose=True\n",
                ")\n",
                "\n",
                "print('\\n' + '='*60)\n",
                "print('üìä BASELINE RESULTS')\n",
                "print('='*60)\n",
                "print(f\"R_MIN:   {baseline['recall_min']:.4f}\")\n",
                "print(f\"BAL_ACC: {baseline['balanced_accuracy']:.4f}\")\n",
                "print(f\"MCC:     {baseline['mcc']:.4f}\")\n",
                "\n",
                "# Show full evaluation\n",
                "evaluate_model_full(\n",
                "    baseline['y_test'], baseline['y_pred'],\n",
                "    dates=baseline['test_dates'],\n",
                "    title='BASELINE (both, W=200, S=70, no exclusion)'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Full Grid Search"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate all combinations\n",
                "combos = list(product(\n",
                "    GRID_PARAMS['coord_modes'],\n",
                "    GRID_PARAMS['gauss_windows'],\n",
                "    GRID_PARAMS['gauss_stds'],\n",
                "    GRID_PARAMS['orb_mults'],\n",
                "    ABLATION_BODIES,\n",
                "))\n",
                "\n",
                "print(f'Total combinations: {len(combos)}')\n",
                "\n",
                "# Run grid search\n",
                "results = []\n",
                "\n",
                "for i, (coord, gw, gs, orb, excl) in enumerate(combos):\n",
                "    excl_str = ','.join(excl) if excl else 'none'\n",
                "    \n",
                "    # Get cached bodies\n",
                "    df_bodies, geo_by_date, _ = cached_bodies[coord]\n",
                "    \n",
                "    # Train and evaluate\n",
                "    result = train_and_evaluate(\n",
                "        df_market, df_bodies, geo_by_date, settings,\n",
                "        gauss_window=gw, gauss_std=gs, orb_mult=orb,\n",
                "        exclude_bodies=excl if excl else None,\n",
                "        device=device, verbose=False\n",
                "    )\n",
                "    \n",
                "    if result is None:\n",
                "        continue\n",
                "    \n",
                "    results.append({\n",
                "        'coord_mode': coord,\n",
                "        'gauss_window': gw,\n",
                "        'gauss_std': gs,\n",
                "        'orb_mult': orb,\n",
                "        'exclude_bodies': excl_str,\n",
                "        'n_features': result['n_features'],\n",
                "        'recall_min': result['recall_min'],\n",
                "        'recall_gap': result['recall_gap'],\n",
                "        'balanced_accuracy': result['balanced_accuracy'],\n",
                "        'mcc': result['mcc'],\n",
                "        'f1_macro': result['f1_macro'],\n",
                "        'threshold': result['threshold'],\n",
                "    })\n",
                "    \n",
                "    # Print progress every 10\n",
                "    if (i + 1) % 10 == 0 or i == len(combos) - 1:\n",
                "        print(f'[{i+1:3d}/{len(combos)}] {coord:5s} W={gw} S={gs:.0f} excl={excl_str:20s} ‚Üí R_MIN={result[\"recall_min\"]:.3f} MCC={result[\"mcc\"]:.3f}')\n",
                "\n",
                "results_df = pd.DataFrame(results)\n",
                "print(f'\\n‚úÖ Grid search complete! {len(results_df)} results')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Results Analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sort by R_MIN\n",
                "results_df = results_df.sort_values('recall_min', ascending=False)\n",
                "\n",
                "print('='*80)\n",
                "print('üìä TOP 20 RESULTS (by R_MIN)')\n",
                "print('='*80)\n",
                "display(results_df.head(20))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Best by coord mode\n",
                "print('\\nüìä BEST BY COORD MODE:')\n",
                "for coord in GRID_PARAMS['coord_modes']:\n",
                "    best_for_coord = results_df[results_df['coord_mode'] == coord].iloc[0]\n",
                "    print(f\"  {coord:5s}: R_MIN={best_for_coord['recall_min']:.4f} MCC={best_for_coord['mcc']:.4f} excl={best_for_coord['exclude_bodies']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Best by body exclusion\n",
                "print('\\nüìä BEST BY BODY EXCLUSION:')\n",
                "best_by_excl = results_df.groupby('exclude_bodies').agg({\n",
                "    'recall_min': 'max',\n",
                "    'mcc': 'max',\n",
                "    'balanced_accuracy': 'max'\n",
                "}).sort_values('recall_min', ascending=False)\n",
                "display(best_by_excl)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Best Model Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Get best configuration\n",
                "best = results_df.iloc[0]\n",
                "\n",
                "print('='*60)\n",
                "print('üèÜ BEST CONFIGURATION')\n",
                "print('='*60)\n",
                "print(f\"Coord mode:     {best['coord_mode']}\")\n",
                "print(f\"Gauss window:   {best['gauss_window']}\")\n",
                "print(f\"Gauss std:      {best['gauss_std']}\")\n",
                "print(f\"Orb mult:       {best['orb_mult']}\")\n",
                "print(f\"Exclude bodies: {best['exclude_bodies']}\")\n",
                "print(f\"Features:       {best['n_features']}\")\n",
                "print('-'*40)\n",
                "print(f\"R_MIN:          {best['recall_min']:.4f}\")\n",
                "print(f\"BAL_ACC:        {best['balanced_accuracy']:.4f}\")\n",
                "print(f\"MCC:            {best['mcc']:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Re-train best model with verbose output\n",
                "coord_mode = best['coord_mode']\n",
                "df_bodies, geo_by_date, _ = cached_bodies[coord_mode]\n",
                "\n",
                "excl = best['exclude_bodies'].split(',') if best['exclude_bodies'] != 'none' else None\n",
                "\n",
                "best_result = train_and_evaluate(\n",
                "    df_market, df_bodies, geo_by_date, settings,\n",
                "    gauss_window=int(best['gauss_window']),\n",
                "    gauss_std=float(best['gauss_std']),\n",
                "    orb_mult=float(best['orb_mult']),\n",
                "    exclude_bodies=excl,\n",
                "    device=device, verbose=True\n",
                ")\n",
                "\n",
                "# Full evaluation with plots\n",
                "evaluate_model_full(\n",
                "    best_result['y_test'], best_result['y_pred'],\n",
                "    dates=best_result['test_dates'],\n",
                "    title=f\"BEST: {best['coord_mode']} W={best['gauss_window']} S={best['gauss_std']} excl={best['exclude_bodies']}\"\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Save Results"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save to CSV\n",
                "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
                "results_path = f'RESEARCH/reports/grid_search_{timestamp}.csv'\n",
                "results_df.to_csv(results_path, index=False)\n",
                "print(f'üíæ Results saved to: {results_path}')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "btc",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
