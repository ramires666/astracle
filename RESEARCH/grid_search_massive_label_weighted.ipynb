{  "cells": [    {      "cell_type": "markdown",      "metadata": {},      "source": [        "# Massive Label Grid + On-the-Fly Model Grid Search\n",        "\n",        "This notebook runs a large grid search over labeling parameters and, for each label setup, a small model hyperparameter grid.\n",        "\n",        "Primary objective: `move_weighted_acc` on the test split.\n",        "\n",        "`move_weighted_acc` measures closeness to true labels with sample weights based on absolute future move `|Y|`. Large moves dominate; small moves have limited impact."      ]    },    {      "cell_type": "code",      "execution_count": null,      "metadata": {},      "outputs": [],      "source": [        "import sys\n",        "import io\n",        "import time\n",        "import itertools\n",        "import contextlib\n",        "from pathlib import Path\n",        "from typing import Dict, List, Any\n",        "\n",        "import numpy as np\n",        "import pandas as pd\n",        "import matplotlib.pyplot as plt\n",        "\n",        "PROJECT_ROOT = Path.cwd().resolve()\n",        "if not (PROJECT_ROOT / \"RESEARCH\").exists():\n",        "    for parent in PROJECT_ROOT.parents:\n",        "        if (parent / \"RESEARCH\").exists():\n",        "            PROJECT_ROOT = parent\n",        "            break\n",        "\n",        "if str(PROJECT_ROOT) not in sys.path:\n",        "    sys.path.insert(0, str(PROJECT_ROOT))\n",        "\n",        "from RESEARCH.config import cfg\n",        "from RESEARCH.data_loader import load_market_data\n",        "from RESEARCH.labeling import create_balanced_labels, gaussian_smooth_centered\n",        "from RESEARCH.astro_engine import (\n",        "    init_ephemeris,\n",        "    calculate_bodies_for_dates_multi,\n",        "    calculate_aspects_from_cache,\n",        "    calculate_phases_for_dates,\n",        "    precompute_angles_for_dates,\n",        ")\n",        "from RESEARCH.features import build_full_features\n",        "from RESEARCH.model_training import split_dataset, prepare_xy, train_xgb_model, calc_metrics, check_cuda_available\n",        "\n",        "pd.set_option(\"display.max_columns\", None)\n",        "pd.set_option(\"display.expand_frame_repr\", False)\n",        "\n",        "print(f\"Python: {sys.version.split()[0]}\")\n",        "print(f\"PROJECT_ROOT: {PROJECT_ROOT}\")"      ]    },    {      "cell_type": "code",      "execution_count": null,      "metadata": {},      "outputs": [],      "source": [        "# Search configuration\n",        "DATA_START = \"2017-11-01\"\n",        "RUN_TAG = \"massive_label_weighted\"\n",        "\n",        "# Giant labeling grid\n",        "LABEL_GRID = {\n",        "    \"horizon\": [1, 2, 3],\n",        "    \"move_share\": [0.35, 0.50, 0.65],\n",        "    \"gauss_window\": [51, 101, 151, 201, 251, 301, 401],\n",        "    \"gauss_std\": [15.0, 25.0, 35.0, 50.0, 70.0, 90.0, 110.0],\n",        "    \"price_mode\": [\"raw\", \"log\"],\n",        "    \"label_mode\": [\"balanced_detrended\", \"balanced_future_return\"],\n",        "}\n",        "\n",        "# Astro feature grid\n",        "FEATURE_GRID = {\n",        "    \"coord_mode\": [\"geo\", \"helio\", \"both\"],\n",        "    \"orb_multiplier\": [0.10, 0.15, 0.25, 0.50, 1.00],\n",        "    \"include_phases\": [True],\n",        "}\n",        "\n",        "# Small model grid (on-the-fly per label combo)\n",        "MODEL_GRID = {\n",        "    \"n_estimators\": [300, 500],\n",        "    \"max_depth\": [3, 5],\n",        "    \"learning_rate\": [0.03, 0.05],\n",        "    \"subsample\": [0.8],\n",        "    \"colsample_bytree\": [0.8],\n",        "    \"weight_power\": [1.0, 1.5],\n",        "}\n",        "\n",        "# Metric settings: stronger focus on large |Y|\n",        "MOVE_WEIGHT_POWER = 1.5\n",        "MOVE_WEIGHT_CLIP_Q = 0.98\n",        "TOP_MOVE_QUANTILE = 0.80\n",        "\n",        "# Runtime and checkpoint controls\n",        "SEED = 42\n",        "SHUFFLE_LABEL_COMBOS = True\n",        "MAX_LABEL_COMBOS = None\n",        "MAX_TOTAL_MODEL_EVALS = None\n",        "CHECKPOINT_EVERY = 25\n",        "MIN_DATASET_ROWS = 300\n",        "RESUME_FROM_CHECKPOINT = True\n",        "\n",        "# Quick dry-run mode\n",        "TEST_MODE = False\n",        "if TEST_MODE:\n",        "    LABEL_GRID = {\n",        "        \"horizon\": [1],\n",        "        \"move_share\": [0.50],\n",        "        \"gauss_window\": [201],\n",        "        \"gauss_std\": [50.0],\n",        "        \"price_mode\": [\"raw\"],\n",        "        \"label_mode\": [\"balanced_detrended\"],\n",        "    }\n",        "    FEATURE_GRID = {\n",        "        \"coord_mode\": [\"both\"],\n",        "        \"orb_multiplier\": [0.15],\n",        "        \"include_phases\": [True],\n",        "    }\n",        "    MODEL_GRID = {\n",        "        \"n_estimators\": [300],\n",        "        \"max_depth\": [4],\n",        "        \"learning_rate\": [0.03],\n",        "        \"subsample\": [0.8],\n",        "        \"colsample_bytree\": [0.8],\n",        "        \"weight_power\": [1.0, 1.5],\n",        "    }\n",        "    MAX_LABEL_COMBOS = 4\n",        "    RUN_TAG = \"massive_label_weighted_test\"\n",        "\n",        "print(\"Configured. TEST_MODE=\", TEST_MODE)"      ]    },    {      "cell_type": "code",      "execution_count": null,      "metadata": {},      "outputs": [],      "source": [        "def generate_grid(grid: Dict[str, List[Any]]) -> List[Dict[str, Any]]:\n",        "    keys = list(grid.keys())\n",        "    values = [grid[k] for k in keys]\n",        "    return [dict(zip(keys, combo)) for combo in itertools.product(*values)]\n",        "\n",        "\n",        "def pair_signature(feature_combo: Dict[str, Any], label_combo: Dict[str, Any]) -> str:\n",        "    return str((tuple(sorted(feature_combo.items())), tuple(sorted(label_combo.items()))))\n",        "\n",        "\n",        "def move_weights(y_move: np.ndarray, power: float = MOVE_WEIGHT_POWER, clip_q: float = MOVE_WEIGHT_CLIP_Q) -> np.ndarray:\n",        "    abs_move = np.abs(np.asarray(y_move, dtype=np.float64))\n",        "    if len(abs_move) == 0:\n",        "        return np.array([], dtype=np.float64)\n",        "    cap = float(np.quantile(abs_move, clip_q))\n",        "    if cap <= 0.0:\n",        "        cap = float(abs_move.max()) if abs_move.max() > 0 else 1.0\n",        "    w = np.clip(abs_move / cap, 0.0, 1.0) ** power\n",        "    return np.maximum(w, 1e-8)\n",        "\n",        "\n",        "def move_weighted_acc(y_true: np.ndarray, y_pred: np.ndarray, y_move: np.ndarray) -> float:\n",        "    w = move_weights(y_move)\n",        "    ok = (y_true == y_pred).astype(np.float64)\n",        "    return float(np.sum(w * ok) / np.sum(w))\n",        "\n",        "\n",        "def move_direction_capture(y_pred: np.ndarray, y_move: np.ndarray) -> float:\n",        "    w = move_weights(y_move)\n",        "    pred_sign = np.where(y_pred == 1, 1.0, -1.0)\n",        "    true_sign = np.where(np.asarray(y_move, dtype=np.float64) >= 0, 1.0, -1.0)\n",        "    signed = pred_sign * true_sign\n",        "    return float(np.sum(w * signed) / np.sum(w))\n",        "\n",        "\n",        "def top_move_acc(y_true: np.ndarray, y_pred: np.ndarray, y_move: np.ndarray, q: float = TOP_MOVE_QUANTILE) -> float:\n",        "    abs_move = np.abs(np.asarray(y_move, dtype=np.float64))\n",        "    thr = float(np.quantile(abs_move, q))\n",        "    mask = abs_move >= thr\n",        "    if mask.sum() == 0:\n",        "        return 0.0\n",        "    return float((y_true[mask] == y_pred[mask]).mean())\n",        "\n",        "\n",        "def model_predict_binary(model, X: np.ndarray, threshold: float) -> np.ndarray:\n",        "    constant_class = getattr(model, \"constant_class\", None)\n",        "    if constant_class is not None:\n",        "        return np.full(X.shape[0], int(constant_class), dtype=np.int32)\n",        "    X_scaled = model.scaler.transform(X)\n",        "    proba = model.model.predict_proba(X_scaled)[:, 1]\n",        "    return (proba >= threshold).astype(np.int32)\n",        "\n",        "\n",        "def tune_threshold_by_move_weighted_score(model, X_val, y_val, y_move_val):\n",        "    constant_class = getattr(model, \"constant_class\", None)\n",        "    if constant_class is not None:\n",        "        pred = np.full(X_val.shape[0], int(constant_class), dtype=np.int32)\n",        "        return 0.5, move_weighted_acc(y_val, pred, y_move_val)\n",        "\n",        "    X_scaled = model.scaler.transform(X_val)\n",        "    proba = model.model.predict_proba(X_scaled)[:, 1]\n",        "\n",        "    best_t = 0.5\n",        "    best_score = -1.0\n",        "    best_recall_min = -1.0\n",        "\n",        "    for t in np.linspace(0.05, 0.95, 91):\n",        "        pred = (proba >= t).astype(np.int32)\n",        "        score = move_weighted_acc(y_val, pred, y_move_val)\n",        "        m = calc_metrics(y_val, pred, [0, 1])\n",        "\n",        "        if score > best_score:\n",        "            best_t = float(t)\n",        "            best_score = float(score)\n",        "            best_recall_min = float(m[\"recall_min\"])\n",        "        elif np.isclose(score, best_score) and m[\"recall_min\"] > best_recall_min:\n",        "            best_t = float(t)\n",        "            best_recall_min = float(m[\"recall_min\"])\n",        "\n",        "    return best_t, best_score\n",        "\n",        "\n",        "def split_dataset_silent(df: pd.DataFrame):\n",        "    with contextlib.redirect_stdout(io.StringIO()):\n",        "        return split_dataset(df)\n",        "\n",        "\n",        "def prefix_non_date_columns(df: pd.DataFrame, prefix: str) -> pd.DataFrame:\n",        "    if df is None or df.empty:\n",        "        return pd.DataFrame()\n",        "    rename_map = {c: f\"{prefix}{c}\" for c in df.columns if c != \"date\"}\n",        "    return df.rename(columns=rename_map)\n",        "\n",        "\n",        "def build_label_frame(df_market: pd.DataFrame, combo: Dict[str, Any]) -> pd.DataFrame:\n",        "    horizon = int(combo[\"horizon\"])\n",        "    price_mode = str(combo[\"price_mode\"])\n",        "    label_mode = str(combo[\"label_mode\"])\n",        "\n",        "    df_labels = create_balanced_labels(\n",        "        df_market=df_market,\n",        "        horizon=horizon,\n",        "        move_share=float(combo[\"move_share\"]),\n",        "        gauss_window=int(combo[\"gauss_window\"]),\n",        "        gauss_std=float(combo[\"gauss_std\"]),\n",        "        price_mode=price_mode,\n",        "        label_mode=label_mode,\n",        "        verbose=False,\n",        "    )\n",        "\n",        "    close = df_market[\"close\"].astype(float)\n",        "    raw_move = close.shift(-horizon) - close\n",        "\n",        "    if price_mode == \"log\":\n",        "        base = np.log(close)\n",        "    else:\n",        "        base = close\n",        "\n",        "    if label_mode == \"balanced_detrended\":\n",        "        smooth = gaussian_smooth_centered(base, int(combo[\"gauss_window\"]), float(combo[\"gauss_std\"]))\n",        "        detrended = base - smooth\n",        "        label_space_move = detrended.shift(-horizon) - detrended\n",        "    else:\n",        "        label_space_move = base.shift(-horizon) - base\n",        "\n",        "    df_y = pd.DataFrame({\n",        "        \"date\": pd.to_datetime(df_market[\"date\"]),\n",        "        \"y_move_raw\": raw_move.to_numpy(dtype=np.float64),\n",        "        \"y_move_label\": label_space_move.to_numpy(dtype=np.float64),\n",        "    })\n",        "\n",        "    df_labels = df_labels.copy()\n",        "    df_labels[\"date\"] = pd.to_datetime(df_labels[\"date\"])\n",        "    out = df_labels.merge(df_y, on=\"date\", how=\"left\")\n",        "    out = out.dropna(subset=[\"y_move_raw\", \"y_move_label\"]).sort_values(\"date\").reset_index(drop=True)\n",        "    return out\n",        "\n",        "\n",        "def prepare_astro_state(df_market: pd.DataFrame, settings, coord_mode: str, include_phases: bool = True) -> Dict[str, Any]:\n",        "    df_bodies, geo_by_date, helio_by_date = calculate_bodies_for_dates_multi(\n",        "        df_market[\"date\"], settings, coord_mode=coord_mode, progress=True\n",        "    )\n",        "    df_bodies = df_bodies.copy()\n",        "    df_bodies[\"date\"] = pd.to_datetime(df_bodies[\"date\"])\n",        "\n",        "    state = {\"df_bodies\": df_bodies, \"angles\": {}, \"df_phases\": None}\n",        "\n",        "    if coord_mode in {\"geo\", \"both\"} and geo_by_date:\n",        "        state[\"angles\"][\"geo\"] = precompute_angles_for_dates(geo_by_date, progress=True)\n",        "    if coord_mode in {\"helio\", \"both\"} and helio_by_date:\n",        "        state[\"angles\"][\"helio\"] = precompute_angles_for_dates(helio_by_date, progress=True)\n",        "\n",        "    if include_phases:\n",        "        if coord_mode == \"geo\":\n",        "            df_phases = calculate_phases_for_dates(geo_by_date, progress=False)\n",        "            df_phases[\"date\"] = pd.to_datetime(df_phases[\"date\"])\n",        "            state[\"df_phases\"] = df_phases\n",        "        elif coord_mode == \"helio\":\n",        "            df_phases = calculate_phases_for_dates(helio_by_date, progress=False)\n",        "            df_phases = prefix_non_date_columns(df_phases, \"helio_\")\n",        "            df_phases[\"date\"] = pd.to_datetime(df_phases[\"date\"])\n",        "            state[\"df_phases\"] = df_phases\n",        "        else:\n",        "            df_geo = prefix_non_date_columns(calculate_phases_for_dates(geo_by_date, progress=False), \"geo_\")\n",        "            df_hel = prefix_non_date_columns(calculate_phases_for_dates(helio_by_date, progress=False), \"helio_\")\n",        "            df_geo[\"date\"] = pd.to_datetime(df_geo[\"date\"])\n",        "            df_hel[\"date\"] = pd.to_datetime(df_hel[\"date\"])\n",        "            state[\"df_phases\"] = df_geo.merge(df_hel, on=\"date\", how=\"outer\")\n",        "\n",        "    return state\n",        "\n",        "\n",        "def build_aspects_for_mode(astro_state: Dict[str, Any], settings, coord_mode: str, orb_mult: float) -> pd.DataFrame:\n",        "    if coord_mode == \"geo\":\n",        "        return calculate_aspects_from_cache(astro_state[\"angles\"][\"geo\"], settings, orb_mult=orb_mult, prefix=\"\", progress=False)\n",        "    if coord_mode == \"helio\":\n",        "        return calculate_aspects_from_cache(astro_state[\"angles\"][\"helio\"], settings, orb_mult=orb_mult, prefix=\"helio_\", progress=False)\n",        "\n",        "    df_geo = calculate_aspects_from_cache(astro_state[\"angles\"][\"geo\"], settings, orb_mult=orb_mult, prefix=\"geo_\", progress=False)\n",        "    df_hel = calculate_aspects_from_cache(astro_state[\"angles\"][\"helio\"], settings, orb_mult=orb_mult, prefix=\"helio_\", progress=False)\n",        "    return pd.concat([df_geo, df_hel], ignore_index=True)\n",        "\n",        "\n",        "def is_better(candidate: Dict[str, Any], current: Dict[str, Any]) -> bool:\n",        "    if candidate is None:\n",        "        return False\n",        "    if current is None:\n",        "        return True\n",        "\n",        "    c1 = float(candidate.get(\"test_move_weighted_acc\", np.nan))\n",        "    c2 = float(current.get(\"test_move_weighted_acc\", np.nan))\n",        "\n",        "    if np.isnan(c1):\n",        "        return False\n",        "    if np.isnan(c2):\n",        "        return True\n",        "\n",        "    if c1 > c2:\n",        "        return True\n",        "    if np.isclose(c1, c2) and float(candidate.get(\"recall_min\", -1)) > float(current.get(\"recall_min\", -1)):\n",        "        return True\n",        "    if np.isclose(c1, c2) and np.isclose(float(candidate.get(\"recall_min\", -1)), float(current.get(\"recall_min\", -1))):\n",        "        return float(candidate.get(\"mcc\", -1)) > float(current.get(\"mcc\", -1))\n",        "    return False"      ]    },    {      "cell_type": "code",      "execution_count": null,      "metadata": {},      "outputs": [],      "source": [        "rng = np.random.default_rng(SEED)\n",        "\n",        "label_combos = generate_grid(LABEL_GRID)\n",        "feature_combos = generate_grid(FEATURE_GRID)\n",        "model_combos = generate_grid(MODEL_GRID)\n",        "\n",        "if SHUFFLE_LABEL_COMBOS:\n",        "    rng.shuffle(label_combos)\n",        "if MAX_LABEL_COMBOS is not None:\n",        "    label_combos = label_combos[: int(MAX_LABEL_COMBOS)]\n",        "\n",        "print(f\"Label combos:   {len(label_combos)}\")\n",        "print(f\"Feature combos: {len(feature_combos)}\")\n",        "print(f\"Model combos:   {len(model_combos)}\")\n",        "print(f\"Total model evals (upper bound): {len(label_combos) * len(feature_combos) * len(model_combos)}\")\n",        "\n",        "df_market = load_market_data()\n",        "df_market = df_market[df_market[\"date\"] >= DATA_START].copy()\n",        "df_market[\"date\"] = pd.to_datetime(df_market[\"date\"])\n",        "df_market = df_market.sort_values(\"date\").reset_index(drop=True)\n",        "\n",        "print(f\"Market rows: {len(df_market)}\")\n",        "print(f\"Date range: {df_market['date'].min().date()} -> {df_market['date'].max().date()}\")\n",        "\n",        "settings = init_ephemeris()\n",        "_, device = check_cuda_available()\n",        "print(f\"Training device: {device}\")\n",        "\n",        "# Precompute astro data per coordinate mode\n",        "astro_by_mode: Dict[str, Dict[str, Any]] = {}\n",        "coord_modes_needed = sorted(set(c[\"coord_mode\"] for c in feature_combos))\n",        "\n",        "for mode in coord_modes_needed:\n",        "    print(f\"\\n[ASTRO PREP] mode={mode}\")\n",        "    astro_by_mode[mode] = prepare_astro_state(df_market, settings, mode, include_phases=True)\n",        "\n",        "label_cache: Dict[str, pd.DataFrame] = {}\n",        "feature_cache: Dict[str, pd.DataFrame] = {}\n",        "results: List[Dict[str, Any]] = []\n",        "best_global = None\n",        "eval_counter = 0\n",        "pair_counter = 0\n",        "started_at = time.time()\n",        "\n",        "reports_dir = cfg.reports_dir\n",        "reports_dir.mkdir(parents=True, exist_ok=True)\n",        "checkpoint_path = reports_dir / f\"{RUN_TAG}_checkpoint.csv\"\n",        "done_pairs = set()\n",        "\n",        "if RESUME_FROM_CHECKPOINT and checkpoint_path.exists():\n",        "    df_prev = pd.read_csv(checkpoint_path)\n",        "    if \"pair_key\" in df_prev.columns:\n",        "        results = df_prev.to_dict(orient=\"records\")\n",        "        done_pairs = set(df_prev[\"pair_key\"].astype(str).tolist())\n",        "        if not df_prev.empty:\n",        "            best_global = df_prev.sort_values([\"test_move_weighted_acc\", \"recall_min\", \"mcc\"], ascending=[False, False, False]).iloc[0].to_dict()\n",        "        print(f\"[RESUME] loaded rows={len(df_prev)}, done_pairs={len(done_pairs)} from {checkpoint_path}\")\n",        "\n",        "for f_idx, f_combo in enumerate(feature_combos, start=1):\n",        "    f_key = str(tuple(sorted(f_combo.items())))\n",        "\n",        "    if f_key not in feature_cache:\n",        "        state = astro_by_mode[f_combo[\"coord_mode\"]]\n",        "        df_aspects = build_aspects_for_mode(\n",        "            astro_state=state,\n",        "            settings=settings,\n",        "            coord_mode=f_combo[\"coord_mode\"],\n",        "            orb_mult=float(f_combo[\"orb_multiplier\"]),\n",        "        )\n",        "        df_features = build_full_features(\n",        "            state[\"df_bodies\"],\n",        "            df_aspects,\n",        "            df_phases=state[\"df_phases\"] if bool(f_combo[\"include_phases\"]) else None,\n",        "        )\n",        "        df_features = df_features.copy()\n",        "        df_features[\"date\"] = pd.to_datetime(df_features[\"date\"])\n",        "        feature_cache[f_key] = df_features\n",        "\n",        "    df_features = feature_cache[f_key]\n",        "    print(f\"\\n[FEATURE {f_idx}/{len(feature_combos)}] {f_combo}\")\n",        "\n",        "    for l_idx, l_combo in enumerate(label_combos, start=1):\n",        "        sig = pair_signature(f_combo, l_combo)\n",        "        if sig in done_pairs:\n",        "            continue\n",        "\n",        "        if MAX_TOTAL_MODEL_EVALS is not None and eval_counter >= int(MAX_TOTAL_MODEL_EVALS):\n",        "            break\n",        "\n",        "        l_key = str(tuple(sorted(l_combo.items())))\n",        "        if l_key not in label_cache:\n",        "            label_cache[l_key] = build_label_frame(df_market, l_combo)\n",        "\n",        "        df_labels = label_cache[l_key]\n",        "        df_dataset = df_features.merge(df_labels[[\"date\", \"target\", \"y_move_raw\", \"y_move_label\"]], on=\"date\", how=\"inner\")\n",        "        df_dataset = df_dataset.sort_values(\"date\").drop_duplicates(subset=[\"date\"]).reset_index(drop=True)\n",        "\n",        "        if len(df_dataset) < MIN_DATASET_ROWS:\n",        "            done_pairs.add(sig)\n",        "            continue\n",        "\n",        "        train_df, val_df, test_df = split_dataset_silent(df_dataset)\n",        "        if len(train_df) < 100 or len(val_df) < 30 or len(test_df) < 30:\n",        "            done_pairs.add(sig)\n",        "            continue\n",        "\n",        "        feature_cols = [c for c in df_dataset.columns if c not in [\"date\", \"target\", \"y_move_raw\", \"y_move_label\"]]\n",        "        X_train, y_train = prepare_xy(train_df, feature_cols)\n",        "        X_val, y_val = prepare_xy(val_df, feature_cols)\n",        "        X_test, y_test = prepare_xy(test_df, feature_cols)\n",        "        y_move_val = val_df[\"y_move_raw\"].to_numpy(dtype=np.float64)\n",        "        y_move_test = test_df[\"y_move_raw\"].to_numpy(dtype=np.float64)\n",        "\n",        "        best_local = None\n",        "\n",        "        for m_combo in model_combos:\n",        "            if MAX_TOTAL_MODEL_EVALS is not None and eval_counter >= int(MAX_TOTAL_MODEL_EVALS):\n",        "                break\n",        "\n",        "            eval_counter += 1\n",        "\n",        "            try:\n",        "                model = train_xgb_model(\n",        "                    X_train, y_train,\n",        "                    X_val, y_val,\n",        "                    feature_names=feature_cols,\n",        "                    n_classes=2,\n",        "                    device=device,\n",        "                    verbose=False,\n",        "                    **m_combo,\n",        "                )\n",        "\n",        "                best_t, val_score = tune_threshold_by_move_weighted_score(model, X_val, y_val, y_move_val)\n",        "                y_pred_test = model_predict_binary(model, X_test, threshold=best_t)\n",        "\n",        "                core = calc_metrics(y_test, y_pred_test, [0, 1])\n",        "                row = {\n",        "                    \"pair_key\": sig,\n",        "                    **{f\"label_{k}\": v for k, v in l_combo.items()},\n",        "                    **{f\"feature_{k}\": v for k, v in f_combo.items()},\n",        "                    **{f\"model_{k}\": v for k, v in m_combo.items()},\n",        "                    \"threshold\": float(best_t),\n",        "                    \"val_move_weighted_acc\": float(val_score),\n",        "                    \"test_move_weighted_acc\": move_weighted_acc(y_test, y_pred_test, y_move_test),\n",        "                    \"test_direction_capture\": move_direction_capture(y_pred_test, y_move_test),\n",        "                    \"test_top_move_acc\": top_move_acc(y_test, y_pred_test, y_move_test, q=TOP_MOVE_QUANTILE),\n",        "                    \"acc\": float(core[\"acc\"]),\n",        "                    \"bal_acc\": float(core[\"bal_acc\"]),\n",        "                    \"mcc\": float(core[\"mcc\"]),\n",        "                    \"f1_macro\": float(core[\"f1_macro\"]),\n",        "                    \"recall_min\": float(core[\"recall_min\"]),\n",        "                    \"recall_gap\": float(core[\"recall_gap\"]),\n",        "                    \"n_train\": int(len(train_df)),\n",        "                    \"n_val\": int(len(val_df)),\n",        "                    \"n_test\": int(len(test_df)),\n",        "                    \"eval_id\": int(eval_counter),\n",        "                    \"elapsed_min\": float((time.time() - started_at) / 60.0),\n",        "                }\n",        "\n",        "                if is_better(row, best_local):\n",        "                    best_local = row\n",        "\n",        "            except Exception as exc:\n",        "                print(f\"[WARN] skipped model combo due to error: {exc}\")\n",        "                continue\n",        "\n",        "        done_pairs.add(sig)\n",        "        pair_counter += 1\n",        "\n",        "        if best_local is not None:\n",        "            results.append(best_local)\n",        "            if is_better(best_local, best_global):\n",        "                best_global = best_local\n",        "                print(\n",        "                    f\"[NEW BEST] eval={best_global['eval_id']} \"\n",        "                    f\"test_move_weighted_acc={best_global['test_move_weighted_acc']:.4f} \"\n",        "                    f\"feature={f_combo} label_h={l_combo['horizon']} gw={l_combo['gauss_window']} gs={l_combo['gauss_std']}\"\n",        "                )\n",        "\n",        "        if pair_counter % CHECKPOINT_EVERY == 0 and len(results) > 0:\n",        "            df_ckpt = pd.DataFrame(results).sort_values(\n",        "                [\"test_move_weighted_acc\", \"recall_min\", \"mcc\"],\n",        "                ascending=[False, False, False],\n",        "            )\n",        "            df_ckpt.to_csv(checkpoint_path, index=False)\n",        "            print(f\"[CHECKPOINT] {checkpoint_path} rows={len(df_ckpt)} done_pairs={len(done_pairs)}\")\n",        "\n",        "    if MAX_TOTAL_MODEL_EVALS is not None and eval_counter >= int(MAX_TOTAL_MODEL_EVALS):\n",        "        break\n",        "\n",        "print(f\"\\nFinished. model_evals={eval_counter}, kept_rows={len(results)}, done_pairs={len(done_pairs)}\")\n",        "\n",        "if results:\n",        "    df_results = pd.DataFrame(results).sort_values(\n",        "        [\"test_move_weighted_acc\", \"recall_min\", \"mcc\"],\n",        "        ascending=[False, False, False],\n",        "    ).reset_index(drop=True)\n",        "    df_results.to_csv(checkpoint_path, index=False)\n",        "    print(f\"Saved final results: {checkpoint_path}\")\n",        "else:\n",        "    df_results = pd.DataFrame()\n",        "    print(\"No valid combinations evaluated.\")"      ]    },    {      "cell_type": "code",      "execution_count": null,      "metadata": {},      "outputs": [],      "source": [        "if df_results.empty:\n",        "    print(\"No results to display.\")\n",        "else:\n",        "    print(\"Top 20 by test_move_weighted_acc:\")\n",        "    display_cols = [\n",        "        \"test_move_weighted_acc\", \"val_move_weighted_acc\", \"test_top_move_acc\", \"test_direction_capture\",\n",        "        \"recall_min\", \"mcc\", \"feature_coord_mode\", \"feature_orb_multiplier\",\n",        "        \"label_horizon\", \"label_move_share\", \"label_gauss_window\", \"label_gauss_std\",\n",        "        \"label_price_mode\", \"label_label_mode\",\n",        "        \"model_n_estimators\", \"model_max_depth\", \"model_learning_rate\", \"model_weight_power\",\n",        "        \"threshold\",\n",        "    ]\n",        "    display(df_results[display_cols].head(20))\n",        "\n",        "    plt.figure(figsize=(8, 5))\n",        "    plt.scatter(df_results[\"test_move_weighted_acc\"], df_results[\"recall_min\"], alpha=0.5)\n",        "    plt.xlabel(\"test_move_weighted_acc\")\n",        "    plt.ylabel(\"recall_min\")\n",        "    plt.title(\"Quality Frontier: large-move objective vs balanced recall\")\n",        "    plt.grid(alpha=0.25)\n",        "    plt.show()\n",        "\n",        "    best = df_results.iloc[0].to_dict()\n",        "    print(\"Best objective row:\")\n",        "    for k in [\n",        "        \"test_move_weighted_acc\", \"test_top_move_acc\", \"test_direction_capture\",\n",        "        \"recall_min\", \"mcc\", \"feature_coord_mode\", \"feature_orb_multiplier\",\n",        "        \"label_horizon\", \"label_move_share\", \"label_gauss_window\", \"label_gauss_std\",\n",        "        \"label_price_mode\", \"label_label_mode\",\n",        "        \"model_n_estimators\", \"model_max_depth\", \"model_learning_rate\", \"model_weight_power\",\n",        "        \"threshold\",\n",        "    ]:\n",        "        print(f\"  {k}: {best[k]}\")"      ]    }  ],  "metadata": {    "kernelspec": {      "display_name": "btc",      "language": "python",      "name": "python3"    },    "language_info": {      "name": "python"    }  },  "nbformat": 4,  "nbformat_minor": 5}