# %% [markdown]
# # Astro Trading Pipeline - Modular Research Notebook
# 
# This is the **central orchestrating notebook** that imports and runs all modules.
# 
# ## Pipeline Steps:
# 1. Setup & Config
# 2. Load Market Data (from PostgreSQL)
# 3. Visualize Price
# 4. Create Labels (balanced UP/DOWN)
# 5. Compute Astro Data
# 6. Build Features
# 7. Train Model
# 8. Evaluate & Visualize
# 9. (Optional) Grid Search
# 10. Save Model

# %% [markdown]
# ## 0. Environment Check

# %%
# Check dependencies
import importlib.util as iu

required = ["xgboost", "sklearn", "matplotlib", "seaborn", "tqdm", "pyarrow", "psycopg2", "swisseph"]
missing = [pkg for pkg in required if iu.find_spec(pkg) is None]

if missing:
    print("Missing packages:", ", ".join(missing))
    print("Install with: conda install -c conda-forge " + " ".join(missing))
else:
    print("‚úì All dependencies found")

# %% [markdown]
# ## 1. Setup & Configuration

# %%
# Import RESEARCH modules
import sys
from pathlib import Path

# Find project root and add to path
PROJECT_ROOT = Path.cwd().resolve()
if not (PROJECT_ROOT / "RESEARCH").exists():
    for parent in PROJECT_ROOT.parents:
        if (parent / "RESEARCH").exists():
            PROJECT_ROOT = parent
            break

if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

print(f"PROJECT_ROOT: {PROJECT_ROOT}")

# %%
# Import all modules
from RESEARCH.config import cfg, PROJECT_ROOT
from RESEARCH.data_loader import load_market_data, get_latest_date, get_data_paths
from RESEARCH.labeling import create_balanced_labels, gaussian_smooth_centered
from RESEARCH.astro_engine import (
    init_ephemeris,
    calculate_bodies_for_dates,
    calculate_aspects_for_dates,
    calculate_transits_for_dates,
    get_natal_bodies,
)
from RESEARCH.features import (
    build_full_features,
    merge_features_with_labels,
    get_feature_columns,
    get_feature_inventory,
)
from RESEARCH.model_training import (
    split_dataset,
    prepare_xy,
    train_xgb_model,
    tune_threshold,
    predict_with_threshold,
    evaluate_model,
    get_feature_importance,
    check_cuda_available,
)
from RESEARCH.visualization import (
    plot_price_distribution,
    plot_class_distribution,
    plot_price_with_labels,
    plot_last_n_days,
    plot_confusion_matrix,
    plot_feature_importance,
    plot_predictions,
)

print("‚úì All RESEARCH modules imported")

# %%
# Show configuration
print(f"Active subject: {cfg.active_subject_id}")
print(f"Data root: {cfg.data_root}")
print(f"DB URL configured: {bool(cfg.db_url)}")
print(f"Label config: {cfg.get_label_config()}")

# %% [markdown]
# ## 2. Load Market Data

# %%
# Load market data from database
df_market = load_market_data()

# Optional: filter by start date
DATA_START = "2017-11-01"
df_market = df_market[df_market["date"] >= DATA_START].reset_index(drop=True)

print(f"\nMarket data: {len(df_market)} rows")
print(f"Date range: {df_market['date'].min().date()} ‚Üí {df_market['date'].max().date()}")
df_market.head()

# %% [markdown]
# ## 3. Visualize Price

# %%
# Price and return distribution
plot_price_distribution(df_market, price_mode="log")

# %% [markdown]
# ## 4. Create Labels

# %%
# Configuration for labeling
LABEL_CONFIG = {
    "horizon": 1,           # Prediction horizon (days)
    "move_share": 0.5,      # Total share of samples to keep
    "gauss_window": 201,    # Gaussian window for detrending (odd)
    "gauss_std": 50.0,      # Gaussian std
    "price_mode": "raw",    # 'raw' or 'log'
    "label_mode": "balanced_detrended",
}

# Create balanced labels
df_labels = create_balanced_labels(
    df_market,
    horizon=LABEL_CONFIG["horizon"],
    move_share=LABEL_CONFIG["move_share"],
    gauss_window=LABEL_CONFIG["gauss_window"],
    gauss_std=LABEL_CONFIG["gauss_std"],
    price_mode=LABEL_CONFIG["price_mode"],
    label_mode=LABEL_CONFIG["label_mode"],
)

df_labels.head()

# %%
# Class distribution
plot_class_distribution(df_labels)

# %%
# Price with labels
plot_price_with_labels(df_market, df_labels, price_mode="raw")

# %%
# Last 30 days
plot_last_n_days(df_market, df_labels, n_days=30)

# %% [markdown]
# ## 5. Compute Astro Data

# %%
# Initialize ephemeris
settings = init_ephemeris()
print(f"Bodies: {[b.name for b in settings.bodies]}")
print(f"Aspects: {[a.name for a in settings.aspects]}")

# %%
# Calculate body positions for all dates
# (This is fast - no need to cache)
df_bodies, bodies_by_date = calculate_bodies_for_dates(
    df_market["date"],
    settings,
    progress=True,
)

print(f"\nBodies calculated: {len(df_bodies)} rows")
df_bodies.head()

# %%
# Calculate aspects
ORB_MULTIPLIER = 0.25  # Best from grid search (tight aspects)

df_aspects = calculate_aspects_for_dates(
    bodies_by_date,
    settings,
    orb_mult=ORB_MULTIPLIER,
    progress=True,
)

print(f"\nAspects: {len(df_aspects)} rows")
df_aspects.head()

# %% [markdown]
# ## 6. Build Features

# %%
# Build feature matrix
df_features = build_full_features(
    df_bodies,
    df_aspects,
    df_transits=None,  # Add transit aspects if needed
    include_pair_aspects=True,
    include_transit_aspects=False,
    exclude_bodies=["Uranus", "Pluto"],  # Best from grid search - these add noise
)

print(f"Features shape: {df_features.shape}")
df_features.head()

# %%
# Merge with labels
df_dataset = merge_features_with_labels(df_features, df_labels)
print(f"\nDataset shape: {df_dataset.shape}")

# %%
# Feature inventory
feature_inventory = get_feature_inventory(df_dataset)
print("\nFeature groups:")
print(feature_inventory.groupby("group").size())

# %% [markdown]
# ## 7. Train Model

# %%
# Check CUDA availability
use_cuda, device = check_cuda_available()
print(f"Using device: {device}")

# %%
# Split dataset (time-based)
train_df, val_df, test_df = split_dataset(df_dataset, train_ratio=0.7, val_ratio=0.15)

print(f"Train: {train_df['date'].min().date()} ‚Üí {train_df['date'].max().date()}")
print(f"Val:   {val_df['date'].min().date()} ‚Üí {val_df['date'].max().date()}")
print(f"Test:  {test_df['date'].min().date()} ‚Üí {test_df['date'].max().date()}")

# %%
# Prepare X, y
feature_cols = get_feature_columns(df_dataset)
X_train, y_train = prepare_xy(train_df, feature_cols)
X_val, y_val = prepare_xy(val_df, feature_cols)
X_test, y_test = prepare_xy(test_df, feature_cols)

print(f"X_train: {X_train.shape}, y_train: {y_train.shape}")
print(f"X_val:   {X_val.shape}, y_val:   {y_val.shape}")
print(f"X_test:  {X_test.shape}, y_test:  {y_test.shape}")

# %%
# Train XGBoost model
MODEL_PARAMS = {
    "n_estimators": 500,
    "max_depth": 6,
    "learning_rate": 0.03,
    "subsample": 0.8,
    "colsample_bytree": 0.8,
}

model = train_xgb_model(
    X_train, y_train,
    X_val, y_val,
    feature_cols,
    n_classes=2,
    device=device,
    **MODEL_PARAMS,
)

# %%
# Tune threshold on validation set
# –¢–ï–ü–ï–†–¨ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –æ–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ—Ç recall_min (–∫–∞—á–µ—Å—Ç–≤–æ —Ö—É–¥—à–µ–≥–æ –∫–ª–∞—Å—Å–∞)
best_threshold, best_score = tune_threshold(model, X_val, y_val)  # metric="recall_min" –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é

# %% [markdown]
# ## 8. Evaluate & Visualize

# %%
# Predict on test set
y_pred = predict_with_threshold(model, X_test, threshold=best_threshold)

# Evaluate
results = evaluate_model(y_test, y_pred, label_names=["DOWN", "UP"])

# %%
# Confusion matrix
plot_confusion_matrix(y_test, y_pred)

# %%
# Feature importance
imp_df = get_feature_importance(model, feature_cols, top_n=20)
plot_feature_importance(imp_df)

# %%
# Predictions on test set
# –¢–µ–ø–µ—Ä—å df_dataset —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –¥–Ω–∏ —Å forward-filled –º–µ—Ç–∫–∞–º–∏
# –ù—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–∏—Ç—å close –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
import pandas as pd  # –ù–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ

test_df_plot = test_df.copy()
test_df_plot["date"] = pd.to_datetime(test_df_plot["date"])
test_df_plot = test_df_plot.merge(
    df_market[["date", "close"]].assign(date=lambda x: pd.to_datetime(x["date"])), 
    on="date", 
    how="left"
)

plot_predictions(test_df_plot, y_pred, y_true=y_test, price_mode="log")

# %% [markdown]
# ## 9. (Optional) Grid Search
# 
# –í—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –Ω–∏–∂–µ:
# - **run_grid_search** ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ–∏—Å–∫ (coord + gauss + orb)
# - **run_full_grid_search** ‚Äî –ø–æ–ª–Ω—ã–π –ø–æ–∏—Å–∫ —Å body ablation
# - **run_body_ablation_search** ‚Äî —Ç–æ–ª—å–∫–æ ablation —Ç–µ–ª

# %%
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üî¨ PARAMETER GRID SEARCH ‚Äî –ü–ï–†–ï–ë–û–† –í–°–ï–• –ü–ê–†–ê–ú–ï–¢–†–û–í
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#
# –≠—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç –õ–ï–ì–ö–û –º–µ–Ω—è—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞:
# - –û—Ä–±–∏—Å –º–Ω–æ–∂–∏—Ç–µ–ª–∏ (–Ω–∞—Å–∫–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã)
# - –û–∫–Ω–∞ –ì–∞—É—Å—Å–∞ (–º–∞—Å—à—Ç–∞–± —Ç—Ä–µ–Ω–¥–∞)
# - Std –ì–∞—É—Å—Å–∞ (—Ä–µ–∑–∫–æ—Å—Ç—å –ø–µ—Ä–µ—Ö–æ–¥–∞)
# - –†–µ–∂–∏–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç (geo/helio/both)
# - –ö–∞–∫–∏–µ —Ç–µ–ª–∞ –∏—Å–∫–ª—é—á–∞—Ç—å
#
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

from RESEARCH.grid_search import GridSearchConfig, run_grid_search, evaluate_combo
from RESEARCH.astro_engine import init_ephemeris, calculate_bodies_for_dates_multi, precompute_angles_for_dates
from RESEARCH.model_training import check_cuda_available
from itertools import product

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
settings = init_ephemeris()
_, device = check_cuda_available()
print(f"üñ•Ô∏è –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")

# %%
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üéõÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò –ü–û–ò–°–ö–ê ‚Äî –ú–ï–ù–Ø–ô–¢–ï –ó–î–ï–°–¨!
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# üìä BASELINE –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
BASELINE = {
    "R_MIN": 0.578,
    "GAP": 0.004,
    "MCC": 0.159,
    "config": "geo O=0.25 W=201 S=50.0 -[Uranus,Pluto]"
}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üåç –†–ï–ñ–ò–ú –ö–û–û–†–î–ò–ù–ê–¢ ‚Äî –≤—ã–±–µ—Ä–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# "geo"   = –≥–µ–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–∏–µ (–∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –∞—Å—Ç—Ä–æ–ª–æ–≥–∏—è)
# "helio" = –≥–µ–ª–∏–æ—Ü–µ–Ω—Ç—Ä–∏—á–µ—Å–∫–∏–µ (–Ω–∞—É—á–Ω–∞—è –∞—Å—Ç—Ä–æ–Ω–æ–º–∏—è)  
# "both"  = –æ–±–∞ —Ä–µ–∂–∏–º–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã (–±–æ–ª—å—à–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤)

COORD_MODES = ["geo", "helio", "both"]  # ‚Üê –ü–ï–†–ï–ë–†–ê–¢–¨ –í–°–ï –¢–†–ò

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üîÆ –û–†–ë –ú–ù–û–ñ–ò–¢–ï–õ–ò ‚Äî –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã –ª–æ–≤–∏—Ç—å
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 0.25 = –æ—á–µ–Ω—å —É–∑–∫–∏–µ –æ—Ä–±–∏—Å—ã (—Ç–æ–ª—å–∫–æ —Ç–æ—á–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã)
# 0.5  = —É–∑–∫–∏–µ –æ—Ä–±–∏—Å—ã
# 1.0  = —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ—Ä–±–∏—Å—ã
# 1.5  = —à–∏—Ä–æ–∫–∏–µ –æ—Ä–±–∏—Å—ã (–±–æ–ª—å—à–µ –∞—Å–ø–µ–∫—Ç–æ–≤, –±–æ–ª—å—à–µ —à—É–º–∞)

ORB_MULTIPLIERS = [0.1, 0.15, 0.2, 0.25,0.35]  # ‚Üê –®–ò–†–û–ö–ò–ô –î–ò–ê–ü–ê–ó–û–ù

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üìà –û–ö–ù–ê –ì–ê–£–°–°–ê ‚Äî –º–∞—Å—à—Ç–∞–± —Ç—Ä–µ–Ω–¥–∞ –≤ –¥–Ω—è—Ö
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 51  = ~2.5 –º–µ—Å—è—Ü–∞ (–∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã)
# 101 = ~5 –º–µ—Å—è—Ü–µ–≤
# 151 = ~7.5 –º–µ—Å—è—Ü–µ–≤
# 201 = ~10 –º–µ—Å—è—Ü–µ–≤ (–¥–æ–ª–≥–æ—Å—Ä–æ—á–Ω—ã–µ —Ç—Ä–µ–Ω–¥—ã)
# 301 = ~15 –º–µ—Å—è—Ü–µ–≤ (–æ—á–µ–Ω—å –¥–æ–ª–≥–æ)

GAUSS_WINDOWS = [51, 101, 151, 201, 251,300]  # ‚Üê –†–ê–°–®–ò–†–ï–ù–ù–´–ô –î–ò–ê–ü–ê–ó–û–ù

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üîî –®–ò–†–ò–ù–ê –ì–ê–£–°–°–ê ‚Äî —Ä–µ–∑–∫–æ—Å—Ç—å –ø–µ—Ä–µ—Ö–æ–¥–æ–≤ UP/DOWN
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# 20  = —Ä–µ–∑–∫–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã (—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª–µ–Ω –∫ —à—É–º—É)
# 50  = —Å—Ä–µ–¥–Ω–∏–µ –ø–µ—Ä–µ—Ö–æ–¥—ã
# 80  = –ø–ª–∞–≤–Ω—ã–µ –ø–µ—Ä–µ—Ö–æ–¥—ã
# 100 = –æ—á–µ–Ω—å –ø–ª–∞–≤–Ω—ã–µ

GAUSS_STDS = [20.0, 35.0, 50.0, 70.0, 90.0]  # ‚Üê –†–ê–°–®–ò–†–ï–ù–ù–´–ô –î–ò–ê–ü–ê–ó–û–ù

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# üö´ –ò–°–ö–õ–Æ–ß–ê–ï–ú–´–ï –¢–ï–õ–ê ‚Äî –∫–∞–∫–∏–µ –ø–ª–∞–Ω–µ—Ç—ã —É–±—Ä–∞—Ç—å –∏–∑ –∞–Ω–∞–ª–∏–∑–∞
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
EXCLUDE_BODIES = None  # ‚Üê –ù–µ –∏—Å–∫–ª—é—á–∞–µ–º —Ç–µ–ª–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ 11)

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# ‚öôÔ∏è –ü–ê–†–ê–ú–ï–¢–†–´ –ú–û–î–ï–õ–ò
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
MODEL_PARAMS = {
    "n_estimators": 300,
    "max_depth": 3,
    "learning_rate": 0.03,
}

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –ü–æ–¥—Å—á—ë—Ç –∫–æ–º–±–∏–Ω–∞—Ü–∏–π
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
total_combos = len(COORD_MODES) * len(ORB_MULTIPLIERS) * len(GAUSS_WINDOWS) * len(GAUSS_STDS)

print("=" * 80)
print("üî¨ PARAMETER GRID SEARCH")
print("=" * 80)
print(f"""
üìä BASELINE –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:
   R_MIN = {BASELINE['R_MIN']:.3f}
   GAP   = {BASELINE['GAP']:.3f}
   MCC   = {BASELINE['MCC']:.3f}
   Config: {BASELINE['config']}

üéõÔ∏è –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–µ—Ä–µ–±–æ—Ä–∞:
   ‚Ä¢ Coord modes:    {COORD_MODES}
   ‚Ä¢ Orb multipliers: {ORB_MULTIPLIERS}
   ‚Ä¢ Gauss windows:  {GAUSS_WINDOWS}
   ‚Ä¢ Gauss stds:     {GAUSS_STDS}
   ‚Ä¢ Excluded bodies: {EXCLUDE_BODIES}

üìà –í—Å–µ–≥–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π: {total_combos}
   –ü—Ä–∏ ~51 —Ä–∞—Å—á/–º–∏–Ω —ç—Ç–æ –∑–∞–π–º—ë—Ç ~{total_combos/51:.1f} –º–∏–Ω—É—Ç
""")

# %%
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# üöÄ –ó–ê–ü–£–°–ö GRID SEARCH
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

results = []
best_so_far = {"R_MIN": 0, "combo": None}

# –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á—ë—Ç –ø–æ–∑–∏—Ü–∏–π –¥–ª—è –≤—Å–µ—Ö coord_modes
print("\nüìç –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π —Ä–∞—Å—á—ë—Ç –ø–æ–∑–∏—Ü–∏–π...")
cached_bodies = {}
cached_angles = {}

for coord_mode in COORD_MODES:
    print(f"   Computing {coord_mode}...")
    df_bodies, geo_by_date, helio_by_date = calculate_bodies_for_dates_multi(
        df_market["date"], settings, coord_mode=coord_mode, progress=False
    )
    bodies_by_date = geo_by_date if geo_by_date else helio_by_date
    cached_bodies[coord_mode] = (df_bodies, geo_by_date, helio_by_date)
    
    print(f"   Computing angles for {coord_mode}...")
    cached_angles[coord_mode] = precompute_angles_for_dates(bodies_by_date, progress=False)

print("‚úì –ö—ç—à –≥–æ—Ç–æ–≤!\n")

# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤—Å–µ –∫–æ–º–±–∏–Ω–∞—Ü–∏–∏
combos = list(product(COORD_MODES, ORB_MULTIPLIERS, GAUSS_WINDOWS, GAUSS_STDS))
print(f"üî¢ –í—Å–µ–≥–æ –∫–æ–º–±–∏–Ω–∞—Ü–∏–π: {len(combos)}")
print("=" * 80)

for i, (coord_mode, orb, gw, gs) in enumerate(combos):
    params_str = f"[{i+1}/{len(combos)}] {coord_mode} O={orb} W={gw} S={gs}"
    
    try:
        df_bodies, geo_by_date, helio_by_date = cached_bodies[coord_mode]
        bodies_by_date = geo_by_date if geo_by_date else helio_by_date
        
        res = evaluate_combo(
            df_market, df_bodies, bodies_by_date, settings,
            orb, gw, gs,
            exclude_bodies=EXCLUDE_BODIES,
            angles_cache=cached_angles.get(coord_mode),
            device=device,
            model_params=MODEL_PARAMS,
        )
        res["coord_mode"] = coord_mode
        res["orb_mult"] = orb
        res["gauss_window"] = gw
        res["gauss_std"] = gs
        results.append(res)
        
        if "error" not in res:
            r_min = res['recall_min']
            mcc = res['mcc']
            
            # Update best
            if r_min > best_so_far["R_MIN"]:
                best_so_far["R_MIN"] = r_min
                best_so_far["combo"] = f"{coord_mode} O={orb} W={gw} S={gs}"
                best_so_far["MCC"] = mcc
            
            print(f"{params_str:<45} ‚Üí R_MIN={r_min:.3f} MCC={mcc:.3f}")
            print(f"   üèÜ BEST: R_MIN={best_so_far['R_MIN']:.3f} ({best_so_far['combo']})")
        else:
            print(f"{params_str:<45} ‚Üí ERROR: {res.get('error')}")
            
    except Exception as e:
        print(f"{params_str:<45} ‚Üí CRASH: {e}")
        results.append({
            "coord_mode": coord_mode, "orb_mult": orb, 
            "gauss_window": gw, "gauss_std": gs, "error": str(e)
        })

# %%
# RESULTS ‚Äî —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å BASELINE
print("\n" + "=" * 80)
print("üìä RESULTS: PARAMETER GRID SEARCH vs BASELINE")
print("=" * 80)

print(f"""
üìå BASELINE –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:
   R_MIN = {BASELINE['R_MIN']:.3f}
   GAP   = {BASELINE['GAP']:.3f}  
   MCC   = {BASELINE['MCC']:.3f}
   Config: {BASELINE['config']}
""")

results_df = pd.DataFrame(results)

if "recall_min" in results_df.columns:
    # –î–æ–±–∞–≤–ª—è–µ–º delta –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ baseline
    results_df["delta_R_MIN"] = results_df["recall_min"] - BASELINE["R_MIN"]
    results_df["delta_MCC"] = results_df["mcc"] - BASELINE["MCC"]
    
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ recall_min
    results_df = results_df.sort_values("recall_min", ascending=False).reset_index(drop=True)
    
    # –¢–æ–ø-20 —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüèÜ TOP 20 BEST COMBINATIONS:")
    print("-" * 90)
    print(f"{'#':<3} {'Coord':<6} {'Orb':<6} {'Win':<5} {'Std':<5} {'R_MIN':<7} {'Œî R_MIN':<9} {'MCC':<7} {'Status':<10}")
    print("-" * 90)
    
    for i, row in results_df.head(20).iterrows():
        if "error" in row and pd.notna(row.get("error")):
            continue
            
        delta_r = row.get("delta_R_MIN", 0)
        coord = row.get("coord_mode", "?")
        orb = row.get("orb_mult", 0)
        win = row.get("gauss_window", 0)
        std = row.get("gauss_std", 0)
        
        if delta_r > 0:
            status = "‚úÖ BETTER"
        elif delta_r > -0.02:
            status = "üü° ~SAME"
        else:
            status = "‚ùå WORSE"
        
        print(f"{i+1:<3} {coord:<6} {orb:<6} {win:<5} {std:<5.0f} {row['recall_min']:<7.3f} {delta_r:<+9.3f} {row['mcc']:<7.3f} {status:<10}")
    
    print("-" * 90)
    print(f"{'---':<3} {'BASE':<6} {'0.25':<6} {'201':<5} {'50':<5} {BASELINE['R_MIN']:<7.3f} {'---':<9} {BASELINE['MCC']:<7.3f}")
    
    # –ê–Ω–∞–ª–∏–∑ –ø–æ coord_mode
    print("\nüìä SUMMARY BY COORD_MODE:")
    for cm in COORD_MODES:
        subset = results_df[results_df["coord_mode"] == cm]
        if not subset.empty:
            best_r = subset["recall_min"].max()
            avg_r = subset["recall_min"].mean()
            print(f"   {cm:6}: best R_MIN={best_r:.3f}, avg={avg_r:.3f}")

# Save
out_path = PROJECT_ROOT / "data" / "market" / "reports" / "param_grid_results.csv"
results_df.to_csv(out_path, index=False)
print(f"\nüíæ Results saved: {out_path}")

# Best overall
if not results_df.empty and "recall_min" in results_df.columns:
    best = results_df.iloc[0]
    delta = best['recall_min'] - BASELINE['R_MIN']
    print(f"\nüèÜ BEST COMBINATION:")
    print(f"   Coord:  {best.get('coord_mode', '?')}")
    print(f"   Orb:    {best.get('orb_mult', '?')}")
    print(f"   Window: {best.get('gauss_window', '?')}")
    print(f"   Std:    {best.get('gauss_std', '?')}")
    print(f"   R_MIN = {best['recall_min']:.3f} (Œî {delta:+.3f} vs baseline)")
    print(f"   MCC   = {best['mcc']:.3f}")
    
    if delta > 0:
        print(f"\n   üéØ NEW BEST found! Beats baseline by {delta:+.3f}!")
    else:
        print(f"\n   ‚ö†Ô∏è No combination beats the baseline.")

# %%
# BODY ABLATION ONLY (uncomment to run)
# Use current params, test all body exclusion combinations

# from RESEARCH.grid_search import run_body_ablation_search
# 
# ablation_df = run_body_ablation_search(
#     df_market,
#     orb_mult=ORB_MULTIPLIER,
#     gauss_window=LABEL_CONFIG["gauss_window"],
#     gauss_std=LABEL_CONFIG["gauss_std"],
#     max_exclude=3,  # Try removing up to 3 bodies
# )

# %% [markdown]
# ## 10. Save Model

# %%
# Save model
from joblib import dump

artifact_dir = PROJECT_ROOT / "models_artifacts"
artifact_dir.mkdir(parents=True, exist_ok=True)

artifact = {
    "model": model.model,
    "scaler": model.scaler,
    "feature_names": feature_cols,
    "threshold": best_threshold,
    "config": {
        "label_config": LABEL_CONFIG,
        "orb_multiplier": ORB_MULTIPLIER,
        "model_params": MODEL_PARAMS,
    },
}

out_path = artifact_dir / f"xgb_astro_research.joblib"
dump(artifact, out_path)
print(f"‚úì Model saved: {out_path}")

# %% [markdown]
# ---
# ## Summary
# 
# This modular pipeline makes it easy to:
# - **Debug**: Each module can be tested independently
# - **Extend**: Add new features, models, or visualizations
# - **Experiment**: Quickly try different configurations
# 
# ### TODO:
# - [ ] Add moon phases to features
# - [ ] Grid search for astro body exclusion
# - [ ] Add houses for birth date grid search
# - [ ] Save best grid search results
