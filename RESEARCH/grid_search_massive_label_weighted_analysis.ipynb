{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Turning Massive Grid: Post Analysis\n","\n","This notebook reads saved grid-search artifacts and performs focused post-analysis.\n","It does **not** rerun the massive grid search.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from __future__ import annotations\n","\n","import sys\n","from pathlib import Path\n","from typing import Any, Dict\n","\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix\n","from sklearn.utils.class_weight import compute_sample_weight\n","\n","PROJECT_ROOT = Path.cwd().resolve()\n","if not (PROJECT_ROOT / \"RESEARCH\").exists():\n","    for parent in PROJECT_ROOT.parents:\n","        if (parent / \"RESEARCH\").exists():\n","            PROJECT_ROOT = parent\n","            break\n","\n","if str(PROJECT_ROOT) not in sys.path:\n","    sys.path.insert(0, str(PROJECT_ROOT))\n","\n","from RESEARCH.config import cfg as project_cfg\n","from RESEARCH.data_loader import load_market_data\n","from RESEARCH.model_training import check_cuda_available\n","from src.models.xgb import XGBBaseline\n","\n","from RESEARCH2.Moon_cycles.turning_points import TurningPointLabelConfig, label_turning_points\n","from RESEARCH2.Moon_cycles.turning_targets import build_turning_target_frame, merge_features_with_turning_target\n","from RESEARCH2.Moon_cycles.turning_astro_features import TurningAstroFeatureConfig, build_turning_astro_feature_set\n","from RESEARCH2.Moon_cycles.eval_utils import compute_binary_metrics\n","from RESEARCH2.Moon_cycles.splits import make_classic_split\n","\n","pd.set_option(\"display.max_columns\", None)\n","pd.set_option(\"display.expand_frame_repr\", False)\n","\n","print(\"Python:\", sys.version.split()[0])\n","print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Analysis settings\n","RUN_TAG = \"turning_massive_label_grid\"\n","DATA_START = \"2017-11-01\"\n","SEED = 42\n","TRAIN_RATIO = 0.70\n","VAL_RATIO = 0.15\n","\n","# Honest candidate rules (can be tightened/relaxed).\n","HONEST_RULE_STRICT = {\n","    \"test_recall_min\": 0.55,\n","    \"test_recall_gap\": 0.25,\n","    \"val_recall_min\": 0.50,\n","    \"val_recall_gap\": 0.25,\n","}\n","HONEST_RULE_RELAXED = {\n","    \"test_recall_min\": 0.50,\n","    \"test_recall_gap\": 0.35,\n","    \"val_recall_min\": 0.45,\n","    \"val_recall_gap\": 0.35,\n","}\n","\n","REPORTS_DIR = project_cfg.reports_dir if hasattr(project_cfg, \"reports_dir\") else (PROJECT_ROOT / \"data\" / \"market\" / \"reports\")\n","CHECKPOINT_PATH = Path(REPORTS_DIR) / f\"{RUN_TAG}_checkpoint.csv\"\n","DONE_PAIRS_PATH = Path(REPORTS_DIR) / f\"{RUN_TAG}_done_pairs.txt\"\n","\n","if not CHECKPOINT_PATH.exists():\n","    raise FileNotFoundError(f\"Checkpoint not found: {CHECKPOINT_PATH}\")\n","\n","print(\"CHECKPOINT:\", CHECKPOINT_PATH)\n","print(\"DONE_PAIRS:\", DONE_PAIRS_PATH, \"exists=\", DONE_PAIRS_PATH.exists())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def sort_results_frame(df: pd.DataFrame) -> pd.DataFrame:\n","    if df.empty:\n","        return df\n","\n","    out = df.copy()\n","    defaults = {\n","        \"is_feasible\": 0,\n","        \"total_constraint_violation\": 1e9,\n","        \"test_profit_y_obj\": -1e9,\n","        \"test_profit_y\": -1e9,\n","        \"test_recall_min\": -1.0,\n","        \"test_recall_gap\": 1e9,\n","        \"mcc\": -1e9,\n","    }\n","    for k, v in defaults.items():\n","        if k not in out.columns:\n","            out[k] = v\n","\n","    return out.sort_values(\n","        [\n","            \"is_feasible\",\n","            \"total_constraint_violation\",\n","            \"test_profit_y_obj\",\n","            \"test_profit_y\",\n","            \"test_recall_min\",\n","            \"test_recall_gap\",\n","            \"mcc\",\n","        ],\n","        ascending=[False, True, False, False, False, True, False],\n","    )\n","\n","\n","def _extract_label_cfg(row: pd.Series) -> Dict[str, Any]:\n","    return {\n","        \"up_move_pct\": float(row[\"label_up_move_pct\"]),\n","        \"down_move_pct\": float(row[\"label_down_move_pct\"]),\n","        \"cluster_gap_days\": int(row[\"label_cluster_gap_days\"]),\n","        \"min_turn_gap_days\": int(row[\"label_min_turn_gap_days\"]),\n","        \"past_horizon_days\": int(row[\"label_past_horizon_days\"]),\n","        \"past_up_move_pct\": float(row[\"label_past_up_move_pct\"]),\n","        \"past_down_move_pct\": float(row[\"label_past_down_move_pct\"]),\n","    }\n","\n","\n","def _extract_target_cfg(row: pd.Series) -> Dict[str, Any]:\n","    mode = str(row[\"target_mode\"])\n","    cfg = {\n","        \"mode\": mode,\n","        \"min_weight\": float(row[\"target_min_weight\"]),\n","        \"use_amplitude_weight\": bool(row[\"target_use_amplitude_weight\"]),\n","    }\n","    if mode == \"window_kernel\":\n","        cfg.update({\n","            \"window_radius_days\": int(row[\"target_window_radius_days\"]),\n","            \"window_distance_power\": float(row[\"target_window_distance_power\"]),\n","        })\n","    elif mode == \"segment_midpoint\":\n","        cfg.update({\n","            \"segment_center_power\": float(row[\"target_segment_center_power\"]),\n","            \"segment_direction_anchor\": str(row[\"target_segment_direction_anchor\"]),\n","            \"include_last_open_segment\": bool(row[\"target_include_last_open_segment\"]),\n","            \"segment_open_tail_direction_mode\": str(row[\"target_segment_open_tail_direction_mode\"]),\n","            \"segment_open_tail_min_move_pct\": float(row[\"target_segment_open_tail_min_move_pct\"]),\n","        })\n","    else:\n","        raise ValueError(f\"Unsupported target_mode: {mode}\")\n","    return cfg\n","\n","\n","def _extract_model_cfg(row: pd.Series) -> Dict[str, Any]:\n","    return {\n","        \"n_estimators\": int(row[\"model_n_estimators\"]),\n","        \"max_depth\": int(row[\"model_max_depth\"]),\n","        \"learning_rate\": float(row[\"model_learning_rate\"]),\n","        \"subsample\": float(row[\"model_subsample\"]),\n","        \"colsample_bytree\": float(row[\"model_colsample_bytree\"]),\n","        \"early_stopping_rounds\": int(row[\"model_early_stopping_rounds\"]),\n","    }\n","\n","\n","def _safe_predict_proba_up(model_obj: XGBBaseline, X: np.ndarray) -> np.ndarray:\n","    const_cls = getattr(model_obj, \"constant_class\", None)\n","    if const_cls is not None:\n","        c = int(const_cls)\n","        return np.full(X.shape[0], 1.0 if c == 1 else 0.0, dtype=float)\n","\n","    Xs = model_obj.scaler.transform(X)\n","    booster = None\n","    restore_device = None\n","    try:\n","        booster = model_obj.model.get_booster()\n","        restore_device = str(getattr(model_obj, \"device\", \"cpu\"))\n","        booster.set_param({\"device\": \"cpu\"})\n","    except Exception:\n","        booster = None\n","\n","    try:\n","        proba_up = model_obj.model.predict_proba(Xs)[:, 1]\n","    finally:\n","        if booster is not None and restore_device and restore_device.startswith(\"cuda\"):\n","            try:\n","                booster.set_param({\"device\": restore_device})\n","            except Exception:\n","                pass\n","\n","    return np.asarray(proba_up, dtype=float)\n","\n","\n","def _profit_y(y_pred: np.ndarray, next_ret: np.ndarray) -> float:\n","    p = np.where(np.asarray(y_pred, dtype=np.int32) == 1, 1.0, -1.0)\n","    y = np.asarray(next_ret, dtype=float)\n","    return float(np.mean(p * y)) if len(y) > 0 else 0.0\n","\n","\n","def _weighted_move_vector(next_ret: np.ndarray, sample_weight: np.ndarray, power: float = 1.5, clip_q: float = 0.98) -> np.ndarray:\n","    base = np.abs(np.asarray(next_ret, dtype=float))\n","    if base.size == 0:\n","        return np.array([], dtype=float)\n","    cap = float(np.quantile(base, clip_q))\n","    if not np.isfinite(cap) or cap <= 0.0:\n","        cap = float(np.nanmax(base)) if np.isfinite(np.nanmax(base)) and np.nanmax(base) > 0 else 1.0\n","    move_part = np.clip(base / cap, 0.0, 1.0) ** float(power)\n","    w = move_part * np.asarray(sample_weight, dtype=float)\n","    return np.maximum(w, 1e-8)\n","\n","\n","def _profit_y_obj(y_pred: np.ndarray, next_ret: np.ndarray, sample_weight: np.ndarray) -> float:\n","    p = np.where(np.asarray(y_pred, dtype=np.int32) == 1, 1.0, -1.0)\n","    y = np.asarray(next_ret, dtype=float)\n","    w = _weighted_move_vector(next_ret=y, sample_weight=sample_weight)\n","    return float(np.sum(w * (p * y)) / np.sum(w))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_results_raw = pd.read_csv(CHECKPOINT_PATH)\n","df_results = sort_results_frame(df_results_raw).reset_index(drop=True)\n","\n","print(f\"rows={len(df_results)} cols={len(df_results.columns)}\")\n","if \"is_feasible\" in df_results.columns:\n","    print(f\"feasible={int((df_results['is_feasible']==1).sum())}/{len(df_results)}\")\n","\n","best_row = df_results.iloc[0].copy()\n","feas = df_results[df_results.get(\"is_feasible\", 0) == 1].copy()\n","\n","strict = feas[\n","    (feas[\"test_recall_min\"] >= HONEST_RULE_STRICT[\"test_recall_min\"])\n","    & (feas[\"test_recall_gap\"] <= HONEST_RULE_STRICT[\"test_recall_gap\"])\n","    & (feas[\"val_recall_min\"] >= HONEST_RULE_STRICT[\"val_recall_min\"])\n","    & (feas[\"val_recall_gap\"] <= HONEST_RULE_STRICT[\"val_recall_gap\"])\n","].copy()\n","\n","if strict.empty:\n","    strict = feas[\n","        (feas[\"test_recall_min\"] >= HONEST_RULE_RELAXED[\"test_recall_min\"])\n","        & (feas[\"test_recall_gap\"] <= HONEST_RULE_RELAXED[\"test_recall_gap\"])\n","        & (feas[\"val_recall_min\"] >= HONEST_RULE_RELAXED[\"val_recall_min\"])\n","        & (feas[\"val_recall_gap\"] <= HONEST_RULE_RELAXED[\"val_recall_gap\"])\n","    ].copy()\n","\n","if strict.empty:\n","    strict = feas.copy() if not feas.empty else df_results.copy()\n","\n","honest_row = strict.sort_values(\n","    [\"test_recall_min\", \"test_recall_gap\", \"mcc\", \"bal_acc\", \"test_profit_y_obj\"],\n","    ascending=[False, True, False, False, False],\n",").iloc[0].copy()\n","\n","metric_cols = [\n","    \"test_profit_y_obj\", \"test_profit_y\",\n","    \"val_recall_min\", \"val_recall_gap\",\n","    \"test_recall_min\", \"test_recall_gap\",\n","    \"mcc\", \"bal_acc\",\n","]\n","print(\"\\n[A] grid_best from checkpoint\")\n","display(pd.DataFrame([best_row[metric_cols]]))\n","print(\"[B] honest candidate from checkpoint\")\n","display(pd.DataFrame([honest_row[metric_cols]]))\n","\n","param_cols = [c for c in df_results.columns if c.startswith(\"label_\") or c.startswith(\"target_\") or c.startswith(\"model_\")]\n","print(\"\\nParameters: grid_best\")\n","display(pd.DataFrame([best_row[param_cols]]))\n","print(\"Parameters: honest\")\n","display(pd.DataFrame([honest_row[param_cols]]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Build shared data once (market + close_map + astro features).\n","# Uses cache namespace from grid run, so this should be fast if cache exists.\n","\n","df_market = load_market_data()\n","df_market = df_market[df_market[\"date\"] >= DATA_START].copy()\n","df_market[\"date\"] = pd.to_datetime(df_market[\"date\"])\n","df_market[\"close\"] = pd.to_numeric(df_market[\"close\"], errors=\"coerce\")\n","df_market = df_market.dropna(subset=[\"date\", \"close\"]).sort_values(\"date\").drop_duplicates(\"date\").reset_index(drop=True)\n","\n","close_map = df_market[[\"date\", \"close\"]].copy()\n","close_map[\"date\"] = pd.to_datetime(close_map[\"date\"])\n","close_map = close_map.sort_values(\"date\").reset_index(drop=True)\n","close_map[\"next_close\"] = close_map[\"close\"].shift(-1)\n","close_map[\"next_ret\"] = close_map[\"next_close\"] / close_map[\"close\"] - 1.0\n","\n","birth_dt_utc = str(best_row.get(\"birth_dt_utc\", project_cfg.subject.get(\"birth_dt_utc\", \"2009-10-10T18:15:05Z\")))\n","feature_coord_mode = str(best_row.get(\"feature_coord_mode\", \"both\"))\n","feature_orb_mult = float(best_row.get(\"feature_orb_mult\", 0.10))\n","\n","astro_cfg = TurningAstroFeatureConfig(\n","    coord_mode=feature_coord_mode,\n","    orb_mult=feature_orb_mult,\n","    include_pair_aspects=True,\n","    include_phases=True,\n","    include_transit_aspects=True,\n","    add_trig_for_longitudes=True,\n","    add_trig_for_moon_phase=True,\n","    add_trig_for_elongations=True,\n",")\n","\n","df_features = build_turning_astro_feature_set(\n","    df_market=df_market,\n","    birth_dt_utc=birth_dt_utc,\n","    cfg=astro_cfg,\n","    cache_namespace=\"research2_turning_grid\",\n","    use_cache=True,\n","    verbose=True,\n","    progress=True,\n",")\n","\n","print(\"market rows:\", len(df_market), \"features rows:\", len(df_features))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def evaluate_candidate(row: pd.Series, tag: str) -> Dict[str, Any]:\n","    label_cfg = _extract_label_cfg(row)\n","    target_cfg = _extract_target_cfg(row)\n","    model_cfg = _extract_model_cfg(row)\n","\n","    turn_cfg = TurningPointLabelConfig(\n","        horizon_days=int(row.get(\"horizon_days_fixed\", 10)),\n","        up_move_pct=float(label_cfg[\"up_move_pct\"]),\n","        down_move_pct=float(label_cfg[\"down_move_pct\"]),\n","        cluster_gap_days=int(label_cfg[\"cluster_gap_days\"]),\n","        min_turn_gap_days=int(label_cfg[\"min_turn_gap_days\"]),\n","        past_horizon_days=int(label_cfg[\"past_horizon_days\"]),\n","        past_up_move_pct=float(label_cfg[\"past_up_move_pct\"]),\n","        past_down_move_pct=float(label_cfg[\"past_down_move_pct\"]),\n","        tail_direction_mode=str(row.get(\"tail_direction_mode_fixed\", \"endpoint_sign\")),\n","        tail_min_move_pct=float(row.get(\"tail_min_move_pct_fixed\", 0.0)),\n","    )\n","\n","    _, df_turns, _ = label_turning_points(df_market=df_market, cfg=turn_cfg)\n","\n","    if target_cfg[\"mode\"] == \"window_kernel\":\n","        df_target = build_turning_target_frame(\n","            df_market=df_market,\n","            df_turning_points=df_turns,\n","            mode=\"window_kernel\",\n","            window_radius_days=int(target_cfg[\"window_radius_days\"]),\n","            window_distance_power=float(target_cfg[\"window_distance_power\"]),\n","            min_weight=float(target_cfg[\"min_weight\"]),\n","            use_amplitude_weight=bool(target_cfg[\"use_amplitude_weight\"]),\n","            use_numba=True,\n","        )\n","    else:\n","        df_target = build_turning_target_frame(\n","            df_market=df_market,\n","            df_turning_points=df_turns,\n","            mode=\"segment_midpoint\",\n","            segment_center_power=float(target_cfg[\"segment_center_power\"]),\n","            segment_direction_anchor=str(target_cfg[\"segment_direction_anchor\"]),\n","            include_last_open_segment=bool(target_cfg[\"include_last_open_segment\"]),\n","            segment_open_tail_direction_mode=str(target_cfg[\"segment_open_tail_direction_mode\"]),\n","            segment_open_tail_min_move_pct=float(target_cfg[\"segment_open_tail_min_move_pct\"]),\n","            min_weight=float(target_cfg[\"min_weight\"]),\n","            use_amplitude_weight=bool(target_cfg[\"use_amplitude_weight\"]),\n","            use_numba=True,\n","        )\n","\n","    df_dataset = merge_features_with_turning_target(\n","        df_features=df_features,\n","        df_target=df_target,\n","        df_market_close=df_market[[\"date\", \"close\"]],\n","    )\n","    df_dataset = pd.merge(df_dataset, close_map[[\"date\", \"next_ret\"]], on=\"date\", how=\"left\")\n","    df_dataset = df_dataset.dropna(subset=[\"next_ret\", \"target\", \"sample_weight\", \"close\"]).sort_values(\"date\").reset_index(drop=True)\n","\n","    split = make_classic_split(df_dataset, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO)\n","    train_df = df_dataset.iloc[split.train_idx].copy().reset_index(drop=True)\n","    val_df = df_dataset.iloc[split.val_idx].copy().reset_index(drop=True)\n","    test_df = df_dataset.iloc[split.test_idx].copy().reset_index(drop=True)\n","\n","    feature_cols = [\n","        c for c in df_dataset.columns\n","        if c not in {\n","            \"date\", \"target\", \"close\", \"next_ret\",\n","            \"turning_direction\", \"sample_weight\", \"target_mode\",\n","            \"event_index\", \"segment_index\",\n","        }\n","    ]\n","\n","    X_train = train_df[feature_cols].to_numpy(dtype=np.float32)\n","    y_train = train_df[\"target\"].to_numpy(dtype=np.int32)\n","    X_val = val_df[feature_cols].to_numpy(dtype=np.float32)\n","    y_val = val_df[\"target\"].to_numpy(dtype=np.int32)\n","    X_test = test_df[feature_cols].to_numpy(dtype=np.float32)\n","    y_test = test_df[\"target\"].to_numpy(dtype=np.int32)\n","\n","    sw_train_base = pd.to_numeric(train_df[\"sample_weight\"], errors=\"coerce\").fillna(1.0).to_numpy(dtype=np.float32)\n","    sw_val_base = pd.to_numeric(val_df[\"sample_weight\"], errors=\"coerce\").fillna(1.0).to_numpy(dtype=np.float32)\n","    sw_test_base = pd.to_numeric(test_df[\"sample_weight\"], errors=\"coerce\").fillna(1.0).to_numpy(dtype=np.float32)\n","    sw_train = sw_train_base * compute_sample_weight(class_weight=\"balanced\", y=y_train).astype(np.float32)\n","    sw_val = sw_val_base * compute_sample_weight(class_weight=\"balanced\", y=y_val).astype(np.float32)\n","    sw_test = sw_test_base * compute_sample_weight(class_weight=\"balanced\", y=y_test).astype(np.float32)\n","\n","    _, device = check_cuda_available()\n","\n","    def _make_model(device_name: str) -> XGBBaseline:\n","        return XGBBaseline(\n","            n_classes=2,\n","            device=device_name,\n","            random_state=SEED,\n","            early_stopping_rounds=int(model_cfg[\"early_stopping_rounds\"]),\n","            n_estimators=int(model_cfg[\"n_estimators\"]),\n","            max_depth=int(model_cfg[\"max_depth\"]),\n","            learning_rate=float(model_cfg[\"learning_rate\"]),\n","            subsample=float(model_cfg[\"subsample\"]),\n","            colsample_bytree=float(model_cfg[\"colsample_bytree\"]),\n","            tree_method=\"hist\",\n","            eval_metric=\"logloss\",\n","        )\n","\n","    used_device = str(device)\n","    model = _make_model(used_device)\n","    try:\n","        model.fit(\n","            X_train=X_train, y_train=y_train,\n","            X_val=X_val, y_val=y_val,\n","            feature_names=feature_cols,\n","            sample_weight=sw_train,\n","            sample_weight_val=sw_val,\n","        )\n","    except Exception:\n","        used_device = \"cpu\"\n","        model = _make_model(used_device)\n","        model.fit(\n","            X_train=X_train, y_train=y_train,\n","            X_val=X_val, y_val=y_val,\n","            feature_names=feature_cols,\n","            sample_weight=sw_train,\n","            sample_weight_val=sw_val,\n","        )\n","\n","    p_val = _safe_predict_proba_up(model, X_val)\n","    p_test = _safe_predict_proba_up(model, X_test)\n","\n","    threshold = float(row.get(\"threshold\", 0.5))\n","    pred_val = (p_val >= threshold).astype(np.int32)\n","    pred_test = (p_test >= threshold).astype(np.int32)\n","\n","    val_metrics = compute_binary_metrics(y_val, pred_val)\n","    test_metrics = compute_binary_metrics(y_test, pred_test)\n","\n","    ret_val = pd.to_numeric(val_df[\"next_ret\"], errors=\"coerce\").fillna(0.0).to_numpy(dtype=np.float32)\n","    ret_test = pd.to_numeric(test_df[\"next_ret\"], errors=\"coerce\").fillna(0.0).to_numpy(dtype=np.float32)\n","\n","    out = {\n","        \"tag\": tag,\n","        \"used_device\": used_device,\n","        \"threshold\": threshold,\n","        \"val_profit_y\": _profit_y(pred_val, ret_val),\n","        \"test_profit_y\": _profit_y(pred_test, ret_test),\n","        \"val_profit_y_obj\": _profit_y_obj(pred_val, ret_val, sw_val),\n","        \"test_profit_y_obj\": _profit_y_obj(pred_test, ret_test, sw_test),\n","        \"val_metrics\": val_metrics,\n","        \"test_metrics\": test_metrics,\n","        \"conf\": confusion_matrix(y_test, pred_test, labels=[0, 1]),\n","        \"test_frame\": test_df[[\"date\", \"close\", \"next_ret\", \"target\"]].assign(\n","            pred=pred_test,\n","            proba_up=p_test,\n","            match=(y_test == pred_test).astype(np.int32),\n","        ),\n","    }\n","    return out\n","\n","\n","best_eval = evaluate_candidate(best_row, tag=\"grid_best\")\n","honest_eval = evaluate_candidate(honest_row, tag=\"honest\")\n","\n","def _flat(res: Dict[str, Any]) -> Dict[str, Any]:\n","    vm = res[\"val_metrics\"]\n","    tm = res[\"test_metrics\"]\n","    return {\n","        \"candidate\": res[\"tag\"],\n","        \"device\": res[\"used_device\"],\n","        \"threshold\": res[\"threshold\"],\n","        \"val_profit_y_obj\": res[\"val_profit_y_obj\"],\n","        \"test_profit_y_obj\": res[\"test_profit_y_obj\"],\n","        \"val_profit_y\": res[\"val_profit_y\"],\n","        \"test_profit_y\": res[\"test_profit_y\"],\n","        \"val_recall_min\": vm[\"recall_min\"],\n","        \"val_recall_gap\": vm[\"recall_gap\"],\n","        \"test_recall_min\": tm[\"recall_min\"],\n","        \"test_recall_gap\": tm[\"recall_gap\"],\n","        \"test_mcc\": tm[\"mcc\"],\n","        \"test_bal_acc\": tm[\"balanced_accuracy\"],\n","        \"test_acc\": tm[\"accuracy\"],\n","    }\n","\n","compare_df = pd.DataFrame([_flat(best_eval), _flat(honest_eval)])\n","print(\"Recomputed on test period (true labels vs predicted):\")\n","display(compare_df)\n","\n","print(\"\\nConfusion matrix grid_best [rows=true DOWN/UP, cols=pred DOWN/UP]\")\n","print(best_eval[\"conf\"])\n","print(\"\\nConfusion matrix honest [rows=true DOWN/UP, cols=pred DOWN/UP]\")\n","print(honest_eval[\"conf\"])\n","\n","show_cols = [\"date\", \"close\", \"next_ret\", \"target\", \"pred\", \"proba_up\", \"match\"]\n","print(\"\\nSample test markup: grid_best\")\n","display(best_eval[\"test_frame\"][show_cols].head(40))\n","print(\"Sample test markup: honest\")\n","display(honest_eval[\"test_frame\"][show_cols].head(40))\n","\n","print(\"\\nQuick take:\")\n","print(\"- grid_best: more aggressive profit objective.\")\n","print(\"- honest: typically more balanced recalls and lower class-collapse risk.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","# Keep these as default visual style for comparison charts.\n","DEFAULT_PRICE_COLOR = \"#1f77b4\"\n","DEFAULT_UP_COLOR = \"green\"\n","DEFAULT_DOWN_COLOR = \"red\"\n","DEFAULT_SHADE_ALPHA = 0.20\n","\n","\n","def _add_market_truth(frame: pd.DataFrame) -> pd.DataFrame:\n","    out = frame.copy()\n","    out[\"true_surrogate\"] = pd.to_numeric(out[\"target\"], errors=\"coerce\").astype(\"Int64\")\n","    out[\"true_market\"] = (pd.to_numeric(out[\"next_ret\"], errors=\"coerce\").fillna(0.0) >= 0.0).astype(np.int32)\n","    return out\n","\n","\n","def plot_price_pred_true_stack(\n","    eval_result: Dict[str, Any],\n","    title_prefix: str,\n","    true_col: str = \"true_market\",\n","    price_color: str = DEFAULT_PRICE_COLOR,\n","    up_color: str = DEFAULT_UP_COLOR,\n","    down_color: str = DEFAULT_DOWN_COLOR,\n","    shade_alpha: float = DEFAULT_SHADE_ALPHA,\n",") -> None:\n","    \"\"\"\n","    Top: predicted labels background.\n","    Bottom: true labels background (market truth by default).\n","    \"\"\"\n","    frame = _add_market_truth(eval_result[\"test_frame\"]).reset_index(drop=True)\n","    frame[\"date\"] = pd.to_datetime(frame[\"date\"])\n","\n","    if true_col not in frame.columns:\n","        raise ValueError(f\"Unknown true_col={true_col}\")\n","\n","    dates = frame[\"date\"]\n","    prices = pd.to_numeric(frame[\"close\"], errors=\"coerce\").to_numpy(dtype=float)\n","    y_true = pd.to_numeric(frame[true_col], errors=\"coerce\").fillna(0).to_numpy(dtype=np.int32)\n","    y_pred = pd.to_numeric(frame[\"pred\"], errors=\"coerce\").fillna(0).to_numpy(dtype=np.int32)\n","\n","    if len(frame) == 0:\n","        print(f\"[{title_prefix}] empty test frame, nothing to plot\")\n","        return\n","\n","    p_min = float(np.nanmin(prices))\n","    p_max = float(np.nanmax(prices))\n","    margin = (p_max - p_min) * 0.05 if p_max > p_min else 1.0\n","    fill_min = p_min - margin\n","    fill_max = p_max + margin\n","\n","    fig, axes = plt.subplots(2, 1, figsize=(16, 9), sharex=True)\n","\n","    # Top: predicted background.\n","    axes[0].set_title(\n","        f\"{title_prefix} | PREDICTED (R_MIN={eval_result['test_metrics']['recall_min']:.3f}, \"\n","        f\"GAP={eval_result['test_metrics']['recall_gap']:.3f}, MCC={eval_result['test_metrics']['mcc']:.3f})\"\n","    )\n","    axes[0].plot(dates, prices, color=price_color, linewidth=1.5, label=\"Price\")\n","    axes[0].fill_between(dates, fill_min, fill_max, where=(y_pred == 1), color=up_color, alpha=shade_alpha, step=\"mid\", label=\"UP\")\n","    axes[0].fill_between(dates, fill_min, fill_max, where=(y_pred == 0), color=down_color, alpha=shade_alpha, step=\"mid\", label=\"DOWN\")\n","    axes[0].set_ylabel(\"Price\")\n","    axes[0].set_ylim(fill_min, fill_max)\n","    axes[0].grid(True, alpha=0.3, linestyle=\":\")\n","    axes[0].legend(loc=\"upper left\")\n","\n","    # Bottom: true background.\n","    true_name = \"TRUE_MARKET(next_ret>=0)\" if true_col == \"true_market\" else \"TRUE_SURROGATE(target)\"\n","    true_down = float(np.mean(y_true == 0))\n","    true_up = float(np.mean(y_true == 1))\n","    axes[1].set_title(f\"{title_prefix} | {true_name} (DOWN={true_down:.3f}, UP={true_up:.3f})\")\n","    axes[1].plot(dates, prices, color=price_color, linewidth=1.5, label=\"Price\")\n","    axes[1].fill_between(dates, fill_min, fill_max, where=(y_true == 1), color=up_color, alpha=shade_alpha, step=\"mid\", label=\"UP\")\n","    axes[1].fill_between(dates, fill_min, fill_max, where=(y_true == 0), color=down_color, alpha=shade_alpha, step=\"mid\", label=\"DOWN\")\n","    axes[1].set_ylabel(\"Price\")\n","    axes[1].set_xlabel(\"Date\")\n","    axes[1].set_ylim(fill_min, fill_max)\n","    axes[1].grid(True, alpha=0.3, linestyle=\":\")\n","    axes[1].legend(loc=\"upper left\")\n","\n","    fig.suptitle(\n","        f\"{title_prefix} | test_profit_y_obj={eval_result['test_profit_y_obj']:+.6f} \"\n","        f\"| test_profit_y={eval_result['test_profit_y']:+.6f}\",\n","        fontsize=13,\n","        y=0.98,\n","    )\n","    plt.tight_layout(rect=[0, 0, 1, 0.96])\n","    plt.show()\n","\n","\n","def print_truth_disagreement(eval_result: Dict[str, Any], tag: str) -> None:\n","    frame = _add_market_truth(eval_result[\"test_frame\"]).reset_index(drop=True)\n","    disagree = (frame[\"true_surrogate\"].astype(int) != frame[\"true_market\"].astype(int)).mean()\n","    print(f\"[{tag}] surrogate-vs-market disagreement on test: {disagree:.3f}\")\n","\n","\n","print_truth_disagreement(best_eval, \"grid_best\")\n","print_truth_disagreement(honest_eval, \"honest\")\n","\n","# Main chart requested: predicted (top) vs REAL market truth (bottom)\n","plot_price_pred_true_stack(best_eval, title_prefix=\"grid_best\", true_col=\"true_market\")\n","plot_price_pred_true_stack(honest_eval, title_prefix=\"honest\", true_col=\"true_market\")\n","\n","# Optional debug: old surrogate truth (to see why it looked wrong)\n","plot_price_pred_true_stack(best_eval, title_prefix=\"grid_best (debug surrogate)\", true_col=\"true_surrogate\")\n","plot_price_pred_true_stack(honest_eval, title_prefix=\"honest (debug surrogate)\", true_col=\"true_surrogate\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## Retrain On Market Truth\n","\n","This section retrains models directly on market truth labels (future return sign),\n","so we can compare against the surrogate turning-target training.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Market-truth retrain settings (fast, no massive grid rerun)\n","TRUTH_HORIZON_DAYS = int(best_row.get(\"horizon_days_fixed\", 10))\n","TRUTH_DEADZONE_PCT = 0.0\n","TRUTH_WEIGHT_POWER = 1.5\n","TRUTH_WEIGHT_CLIP_Q = 0.98\n","\n","# Threshold constraints: prioritize non-collapsed class behavior.\n","TRUTH_VAL_RECALL_MIN_FLOOR = 0.50\n","TRUTH_VAL_RECALL_GAP_CEIL = 0.35\n","TRUTH_TEST_RECALL_MIN_FLOOR = 0.50\n","TRUTH_TEST_RECALL_GAP_CEIL = 0.35\n","TRUTH_CONSTRAINT_PENALTY = 2.0\n","\n","# Build market-truth dataset from existing astro features.\n","cm = df_market[[\"date\", \"close\"]].copy().sort_values(\"date\").reset_index(drop=True)\n","cm[\"future_close\"] = cm[\"close\"].shift(-TRUTH_HORIZON_DAYS)\n","cm[\"next_ret\"] = cm[\"future_close\"] / cm[\"close\"] - 1.0\n","\n","df_truth = pd.merge(df_features, cm[[\"date\", \"close\", \"next_ret\"]], on=\"date\", how=\"inner\")\n","df_truth = df_truth.dropna(subset=[\"next_ret\", \"close\"]).sort_values(\"date\").reset_index(drop=True)\n","if TRUTH_DEADZONE_PCT > 0.0:\n","    df_truth = df_truth[df_truth[\"next_ret\"].abs() >= TRUTH_DEADZONE_PCT].copy().reset_index(drop=True)\n","\n","df_truth[\"target\"] = (df_truth[\"next_ret\"] >= 0.0).astype(np.int32)\n","\n","cap = float(df_truth[\"next_ret\"].abs().quantile(TRUTH_WEIGHT_CLIP_Q))\n","if not np.isfinite(cap) or cap <= 0:\n","    cap = max(float(df_truth[\"next_ret\"].abs().max()), 1e-6)\n","df_truth[\"sample_weight\"] = np.clip(df_truth[\"next_ret\"].abs() / cap, 0.0, 1.0) ** TRUTH_WEIGHT_POWER\n","\n","df_truth[\"sample_weight\"] = np.maximum(df_truth[\"sample_weight\"].astype(float), 1e-8)\n","\n","print(f\"truth dataset rows={len(df_truth)} horizon={TRUTH_HORIZON_DAYS}d\")\n","print(\"target share up:\", float((df_truth[\"target\"] == 1).mean()))\n","print(\"period:\", df_truth[\"date\"].min(), \"->\", df_truth[\"date\"].max())\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def tune_threshold_market(y_val: np.ndarray, p_val: np.ndarray, ret_val: np.ndarray, sw_val: np.ndarray) -> tuple[float, float, float, dict, float, float, int]:\n","    best_t = 0.5\n","    best_score = -1e18\n","    best_profit_obj = -1e18\n","    best_profit_raw = -1e18\n","    best_metrics = {}\n","    best_violation = 1e18\n","    best_feasible = 0\n","\n","    for t in np.linspace(0.05, 0.95, 91):\n","        pred = (p_val >= t).astype(np.int32)\n","        m = compute_binary_metrics(y_val, pred)\n","        profit_obj = _profit_y_obj(pred, ret_val, sw_val)\n","        profit_raw = _profit_y(pred, ret_val)\n","\n","        violation = (\n","            max(0.0, TRUTH_VAL_RECALL_MIN_FLOOR - float(m[\"recall_min\"]))\n","            + max(0.0, float(m[\"recall_gap\"]) - TRUTH_VAL_RECALL_GAP_CEIL)\n","        )\n","        feasible = int(violation <= 1e-12)\n","        score = float(profit_obj) - TRUTH_CONSTRAINT_PENALTY * float(violation)\n","\n","        if score > best_score:\n","            best_score = float(score)\n","            best_t = float(t)\n","            best_profit_obj = float(profit_obj)\n","            best_profit_raw = float(profit_raw)\n","            best_metrics = m\n","            best_violation = float(violation)\n","            best_feasible = int(feasible)\n","        elif np.isclose(score, best_score):\n","            if feasible > best_feasible:\n","                best_t = float(t)\n","                best_profit_obj = float(profit_obj)\n","                best_profit_raw = float(profit_raw)\n","                best_metrics = m\n","                best_violation = float(violation)\n","                best_feasible = int(feasible)\n","            elif feasible == best_feasible and float(violation) < float(best_violation):\n","                best_t = float(t)\n","                best_profit_obj = float(profit_obj)\n","                best_profit_raw = float(profit_raw)\n","                best_metrics = m\n","                best_violation = float(violation)\n","                best_feasible = int(feasible)\n","\n","    return best_t, best_score, best_profit_obj, best_metrics, best_profit_raw, best_violation, best_feasible\n","\n","\n","def is_better_market(candidate: dict, current: dict | None) -> bool:\n","    if current is None:\n","        return True\n","    if int(candidate.get(\"is_feasible\", 0)) != int(current.get(\"is_feasible\", 0)):\n","        return int(candidate.get(\"is_feasible\", 0)) > int(current.get(\"is_feasible\", 0))\n","\n","    c_v = float(candidate.get(\"total_constraint_violation\", np.inf))\n","    p_v = float(current.get(\"total_constraint_violation\", np.inf))\n","    if not np.isclose(c_v, p_v):\n","        return c_v < p_v\n","\n","    c_obj = float(candidate.get(\"test_profit_y_obj\", -1e9))\n","    p_obj = float(current.get(\"test_profit_y_obj\", -1e9))\n","    if not np.isclose(c_obj, p_obj):\n","        return c_obj > p_obj\n","\n","    c_r = float(candidate.get(\"test_recall_min\", -1.0))\n","    p_r = float(current.get(\"test_recall_min\", -1.0))\n","    if not np.isclose(c_r, p_r):\n","        return c_r > p_r\n","\n","    c_g = float(candidate.get(\"test_recall_gap\", 1e9))\n","    p_g = float(current.get(\"test_recall_gap\", 1e9))\n","    if not np.isclose(c_g, p_g):\n","        return c_g < p_g\n","\n","    return float(candidate.get(\"mcc\", -1e9)) > float(current.get(\"mcc\", -1e9))\n","\n","\n","def train_eval_market_truth(model_cfg: dict, tag: str) -> dict:\n","    split = make_classic_split(df_truth, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO)\n","    train_df = df_truth.iloc[split.train_idx].copy().reset_index(drop=True)\n","    val_df = df_truth.iloc[split.val_idx].copy().reset_index(drop=True)\n","    test_df = df_truth.iloc[split.test_idx].copy().reset_index(drop=True)\n","\n","    feature_cols = [\n","        c for c in df_truth.columns\n","        if c not in {\"date\", \"target\", \"close\", \"next_ret\", \"sample_weight\"}\n","    ]\n","\n","    X_train = train_df[feature_cols].to_numpy(dtype=np.float32)\n","    y_train = train_df[\"target\"].to_numpy(dtype=np.int32)\n","    X_val = val_df[feature_cols].to_numpy(dtype=np.float32)\n","    y_val = val_df[\"target\"].to_numpy(dtype=np.int32)\n","    X_test = test_df[feature_cols].to_numpy(dtype=np.float32)\n","    y_test = test_df[\"target\"].to_numpy(dtype=np.int32)\n","\n","    sw_train_base = train_df[\"sample_weight\"].to_numpy(dtype=np.float32)\n","    sw_val_base = val_df[\"sample_weight\"].to_numpy(dtype=np.float32)\n","    sw_test_base = test_df[\"sample_weight\"].to_numpy(dtype=np.float32)\n","\n","    sw_train = sw_train_base * compute_sample_weight(class_weight=\"balanced\", y=y_train).astype(np.float32)\n","    sw_val = sw_val_base * compute_sample_weight(class_weight=\"balanced\", y=y_val).astype(np.float32)\n","    sw_test = sw_test_base * compute_sample_weight(class_weight=\"balanced\", y=y_test).astype(np.float32)\n","\n","    _, device = check_cuda_available()\n","\n","    def _make_model(device_name: str) -> XGBBaseline:\n","        return XGBBaseline(\n","            n_classes=2,\n","            device=device_name,\n","            random_state=SEED,\n","            early_stopping_rounds=int(model_cfg[\"early_stopping_rounds\"]),\n","            n_estimators=int(model_cfg[\"n_estimators\"]),\n","            max_depth=int(model_cfg[\"max_depth\"]),\n","            learning_rate=float(model_cfg[\"learning_rate\"]),\n","            subsample=float(model_cfg[\"subsample\"]),\n","            colsample_bytree=float(model_cfg[\"colsample_bytree\"]),\n","            tree_method=\"hist\",\n","            eval_metric=\"logloss\",\n","        )\n","\n","    used_device = str(device)\n","    model = _make_model(used_device)\n","    try:\n","        model.fit(\n","            X_train=X_train, y_train=y_train,\n","            X_val=X_val, y_val=y_val,\n","            feature_names=feature_cols,\n","            sample_weight=sw_train,\n","            sample_weight_val=sw_val,\n","        )\n","    except Exception:\n","        used_device = \"cpu\"\n","        model = _make_model(used_device)\n","        model.fit(\n","            X_train=X_train, y_train=y_train,\n","            X_val=X_val, y_val=y_val,\n","            feature_names=feature_cols,\n","            sample_weight=sw_train,\n","            sample_weight_val=sw_val,\n","        )\n","\n","    p_val = _safe_predict_proba_up(model, X_val)\n","    p_test = _safe_predict_proba_up(model, X_test)\n","\n","    ret_val = val_df[\"next_ret\"].to_numpy(dtype=np.float32)\n","    ret_test = test_df[\"next_ret\"].to_numpy(dtype=np.float32)\n","\n","    thr, _, val_profit_obj, val_m, val_profit_raw, val_violation_thr, val_feasible_thr = tune_threshold_market(\n","        y_val=y_val,\n","        p_val=p_val,\n","        ret_val=ret_val,\n","        sw_val=sw_val,\n","    )\n","\n","    pred_val = (p_val >= thr).astype(np.int32)\n","    pred_test = (p_test >= thr).astype(np.int32)\n","\n","    val_metrics = compute_binary_metrics(y_val, pred_val)\n","    test_metrics = compute_binary_metrics(y_test, pred_test)\n","\n","    val_violation = (\n","        max(0.0, TRUTH_VAL_RECALL_MIN_FLOOR - float(val_metrics[\"recall_min\"]))\n","        + max(0.0, float(val_metrics[\"recall_gap\"]) - TRUTH_VAL_RECALL_GAP_CEIL)\n","    )\n","    test_violation = (\n","        max(0.0, TRUTH_TEST_RECALL_MIN_FLOOR - float(test_metrics[\"recall_min\"]))\n","        + max(0.0, float(test_metrics[\"recall_gap\"]) - TRUTH_TEST_RECALL_GAP_CEIL)\n","    )\n","    total_violation = float(val_violation + test_violation)\n","\n","    out = {\n","        \"tag\": tag,\n","        \"device\": used_device,\n","        \"threshold\": float(thr),\n","        \"is_feasible\": int(total_violation <= 1e-12),\n","        \"total_constraint_violation\": float(total_violation),\n","        \"val_constraint_violation\": float(val_violation),\n","        \"test_constraint_violation\": float(test_violation),\n","        \"test_profit_y_obj\": float(_profit_y_obj(pred_test, ret_test, sw_test)),\n","        \"test_profit_y\": float(_profit_y(pred_test, ret_test)),\n","        \"val_profit_y_obj\": float(val_profit_obj),\n","        \"val_profit_y\": float(val_profit_raw),\n","        \"test_recall_up\": float(test_metrics[\"recall_up\"]),\n","        \"test_recall_down\": float(test_metrics[\"recall_down\"]),\n","        \"test_recall_min\": float(test_metrics[\"recall_min\"]),\n","        \"test_recall_gap\": float(test_metrics[\"recall_gap\"]),\n","        \"val_recall_min\": float(val_metrics[\"recall_min\"]),\n","        \"val_recall_gap\": float(val_metrics[\"recall_gap\"]),\n","        \"mcc\": float(test_metrics[\"mcc\"]),\n","        \"bal_acc\": float(test_metrics[\"balanced_accuracy\"]),\n","        \"test_metrics\": test_metrics,\n","        \"test_frame\": test_df[[\"date\", \"close\", \"next_ret\", \"target\"]].assign(\n","            pred=pred_test,\n","            proba_up=p_test,\n","            match=(pred_test == y_test).astype(np.int32),\n","        ),\n","    }\n","    return out\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Candidate configs for quick retrain\n","model_candidates = {\n","    \"from_grid_best\": _extract_model_cfg(best_row),\n","    \"from_honest\": _extract_model_cfg(honest_row),\n","    \"honest_light\": {\n","        \"n_estimators\": 300,\n","        \"max_depth\": 4,\n","        \"learning_rate\": 0.03,\n","        \"subsample\": 0.8,\n","        \"colsample_bytree\": 0.8,\n","        \"early_stopping_rounds\": 50,\n","    },\n","}\n","\n","market_runs = []\n","best_market = None\n","\n","for tag, cfg in model_candidates.items():\n","    r = train_eval_market_truth(cfg, tag=tag)\n","    r[\"model_cfg\"] = cfg\n","    market_runs.append(r)\n","    if is_better_market(r, best_market):\n","        best_market = r\n","\n","market_table = pd.DataFrame([\n","    {\n","        \"tag\": r[\"tag\"],\n","        \"is_feasible\": r[\"is_feasible\"],\n","        \"violation\": r[\"total_constraint_violation\"],\n","        \"test_profit_y_obj\": r[\"test_profit_y_obj\"],\n","        \"test_profit_y\": r[\"test_profit_y\"],\n","        \"test_recall_min\": r[\"test_recall_min\"],\n","        \"test_recall_gap\": r[\"test_recall_gap\"],\n","        \"mcc\": r[\"mcc\"],\n","        \"bal_acc\": r[\"bal_acc\"],\n","        \"threshold\": r[\"threshold\"],\n","        \"device\": r[\"device\"],\n","    }\n","    for r in market_runs\n","]).sort_values(\n","    [\"is_feasible\", \"violation\", \"test_profit_y_obj\", \"test_recall_min\", \"test_recall_gap\", \"mcc\"],\n","    ascending=[False, True, False, False, True, False],\n",").reset_index(drop=True)\n","\n","print(\"Market-truth retrain results:\")\n","display(market_table)\n","\n","print(\"Best market-truth run:\")\n","print(best_market[\"tag\"], best_market[\"model_cfg\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot winner against real market truth (no surrogate target here)\n","winner = best_market\n","\n","# Reuse plotting function from previous section if available.\n","if \"plot_price_pred_true_stack\" in globals():\n","    plot_price_pred_true_stack(\n","        {\n","            \"test_frame\": winner[\"test_frame\"],\n","            \"test_metrics\": winner[\"test_metrics\"],\n","            \"test_profit_y_obj\": winner[\"test_profit_y_obj\"],\n","            \"test_profit_y\": winner[\"test_profit_y\"],\n","        },\n","        title_prefix=f\"market_truth_retrain::{winner['tag']}\",\n","        true_col=\"true_market\",\n","    )\n","else:\n","    # Fallback compact plot\n","    f = winner[\"test_frame\"].copy().reset_index(drop=True)\n","    f[\"date\"] = pd.to_datetime(f[\"date\"])\n","    y_true = (f[\"next_ret\"].to_numpy(dtype=float) >= 0.0).astype(np.int32)\n","    y_pred = f[\"pred\"].to_numpy(dtype=np.int32)\n","    prices = f[\"close\"].to_numpy(dtype=float)\n","\n","    p_min, p_max = float(np.nanmin(prices)), float(np.nanmax(prices))\n","    margin = (p_max - p_min) * 0.05 if p_max > p_min else 1.0\n","\n","    fig, axes = plt.subplots(2, 1, figsize=(16, 9), sharex=True)\n","    for ax, lab, ttl in [\n","        (axes[0], y_pred, \"PREDICTED\"),\n","        (axes[1], y_true, \"TRUE_MARKET\"),\n","    ]:\n","        ax.plot(f[\"date\"], prices, color=\"#1f77b4\", linewidth=1.5)\n","        ax.fill_between(f[\"date\"], p_min - margin, p_max + margin, where=(lab == 1), color=\"green\", alpha=0.2, step=\"mid\")\n","        ax.fill_between(f[\"date\"], p_min - margin, p_max + margin, where=(lab == 0), color=\"red\", alpha=0.2, step=\"mid\")\n","        ax.set_title(ttl)\n","        ax.grid(True, alpha=0.3, linestyle=\":\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","print(\"winner metrics:\")\n","print({\n","    \"test_profit_y_obj\": winner[\"test_profit_y_obj\"],\n","    \"test_profit_y\": winner[\"test_profit_y\"],\n","    \"test_recall_min\": winner[\"test_recall_min\"],\n","    \"test_recall_gap\": winner[\"test_recall_gap\"],\n","    \"mcc\": winner[\"mcc\"],\n","    \"bal_acc\": winner[\"bal_acc\"],\n","})\n"]}],"metadata":{"kernelspec":{"display_name":"btc","language":"python","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}