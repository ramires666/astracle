{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Split Notebook: Transit-Natal Core + Optional Progression/Direction Blocks\n",
    "\n",
    "This notebook is focused on a classic, time-ordered protocol only.\n",
    "\n",
    "Core feature block (enabled by default):\n",
    "- transit aspects to natal,\n",
    "- moon phases and elongations.\n",
    "\n",
    "Optional prebuilt blocks (disabled by default):\n",
    "- progressed-to-natal aspects,\n",
    "- directed-to-natal aspects.\n",
    "\n",
    "Houses are intentionally excluded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5874960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path('/home/rut/ostrofun')\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from RESEARCH.cache_utils import load_cache, save_cache\n",
    "from RESEARCH.config import cfg as project_cfg\n",
    "from RESEARCH.astro_engine import (\n",
    "    init_ephemeris,\n",
    "    parse_birth_dt_utc,\n",
    "    calculate_bodies_for_dates,\n",
    "    calculate_phases_for_dates,\n",
    "    calculate_transits_for_dates,\n",
    "    calculate_aspects_for_dates,\n",
    "    get_natal_bodies,\n",
    ")\n",
    "from RESEARCH.astro.aspects import scale_aspects\n",
    "from src.astro.engine.aspects import calculate_transit_aspects\n",
    "from src.astro.engine.calculator import calculate_bodies\n",
    "from src.astro.engine.models import BodyPosition\n",
    "from src.features.builder import build_transit_aspect_features, build_aspect_pair_features\n",
    "\n",
    "from RESEARCH.model_training import train_xgb_model, check_cuda_available\n",
    "from RESEARCH.features import merge_features_with_labels\n",
    "\n",
    "from RESEARCH2.Moon_cycles.moon_data import (\n",
    "    MoonLabelConfig,\n",
    "    load_market_slice,\n",
    "    build_balanced_labels_for_gauss,\n",
    ")\n",
    "from RESEARCH2.Moon_cycles.splits import make_classic_split\n",
    "from RESEARCH2.Moon_cycles.threshold_utils import tune_threshold_with_balance, predict_proba_up_safe, evaluate_threshold_grid\n",
    "from RESEARCH2.Moon_cycles.eval_utils import compute_binary_metrics, compute_statistical_significance\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 180)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6170dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split mode: classic\n",
      "Ratios train/val/test: 0.5 0.2 0.3\n",
      "Birth datetime: 2009-01-03T18:15:05Z\n",
      "Birthdate sweep enabled: False num_dates= 1\n",
      "Feature blocks: {'classic_transit_phase': True, 'progressed_to_natal': True, 'directed_to_natal': True}\n",
      "Use transit pair aspects: True\n",
      "XGB device: cuda (CUDA available: True )\n",
      "Sweep enabled: True\n",
      "Threshold sensitivity: False\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Configuration\n",
    "# ------------------------------\n",
    "\n",
    "# Data range.\n",
    "START_DATE = '2017-11-01'\n",
    "END_DATE = None\n",
    "\n",
    "# Split protocol: classic only.\n",
    "SPLIT_MODE = 'classic'\n",
    "TRAIN_RATIO = 0.50\n",
    "VAL_RATIO = 0.20\n",
    "\n",
    "# Feature/caching settings.\n",
    "ORB_MULT = 0.1\n",
    "CACHE_NAMESPACE = 'research2_transit_blocks'\n",
    "USE_CACHE = True\n",
    "VERBOSE = True\n",
    "XGB_USE_CUDA, XGB_DEVICE = check_cuda_available()\n",
    "PROGRESS = True\n",
    "\n",
    "# Subject birth datetime for natal chart.\n",
    "BIRTH_DT_UTC = str(project_cfg.subject.get('birth_dt_utc', '2009-10-10T18:15:05Z'))\n",
    "\n",
    "# Birthdate sweep list from your phase-1 transits-only ranking.\n",
    "ENABLE_BIRTHDATE_SWEEP =  False\n",
    "BIRTHDATE_CANDIDATES = [\n",
    "     '2009-10-10', '2009-10-12', '2009-10-13', '2009-01-03',\n",
    "    # '2009-03-27', '2009-03-21', '2009-08-22', '2009-11-05', '2009-01-18','2009-12-03',\n",
    "    # '2009-01-01', '2009-01-06', '2009-04-29', '2009-06-14', '2009-12-25',\n",
    "    # '2009-04-22', '2009-04-04', '2009-02-17', '2009-07-11', '2009-05-04',\n",
    "]\n",
    "\n",
    "\n",
    "def _compose_birth_dt_utc(date_yyyy_mm_dd: str, base_birth_dt_utc: str) -> str:\n",
    "    \"\"\"Attach baseline UTC time to a date-only candidate.\"\"\"\n",
    "    if 'T' in date_yyyy_mm_dd:\n",
    "        return date_yyyy_mm_dd\n",
    "    time_part = str(base_birth_dt_utc).split('T', 1)[1]\n",
    "    return f\"{date_yyyy_mm_dd}T{time_part}\"\n",
    "\n",
    "\n",
    "if ENABLE_BIRTHDATE_SWEEP:\n",
    "    BIRTH_DT_SWEEP_LIST = [_compose_birth_dt_utc(d, BIRTH_DT_UTC) for d in BIRTHDATE_CANDIDATES]\n",
    "else:\n",
    "    BIRTH_DT_SWEEP_LIST = [BIRTH_DT_UTC]\n",
    "\n",
    "# Label config defaults (used when sweep is disabled).\n",
    "LABEL_CFG = MoonLabelConfig(\n",
    "    horizon=1,\n",
    "    move_share=0.5,\n",
    "    label_mode='balanced_detrended',\n",
    "    price_mode='raw',\n",
    ")\n",
    "GAUSS_WINDOW = 201\n",
    "GAUSS_STD = 70.0\n",
    "\n",
    "# Threshold tuning objective penalties.\n",
    "THRESHOLD_GAP_PENALTY = 0.25\n",
    "THRESHOLD_PRIOR_PENALTY = 0.05\n",
    "THRESHOLD_CANDIDATE_GRID = np.linspace(0.01, 0.99, 197)\n",
    "THRESHOLD_CURVE_TOP_K = 10\n",
    "\n",
    "# Optional sensitivity sweep for threshold penalties (no model retraining).\n",
    "ENABLE_THRESHOLD_SENSITIVITY = True\n",
    "THRESHOLD_GAP_PENALTY_GRID = [0.00, 0.10, 0.25, 0.40, 0.80]\n",
    "THRESHOLD_PRIOR_PENALTY_GRID = [0.00, 0.05, 0.10, 0.20, 0.40]\n",
    "\n",
    "# Feature blocks.\n",
    "FEATURE_BLOCKS = {\n",
    "    'classic_transit_phase': True,   # transit->natal + phases/elongations\n",
    "    'progressed_to_natal': True,     # optional block\n",
    "    'directed_to_natal': True,       # optional block\n",
    "}\n",
    "\n",
    "# Optional extension for the classic block: transit-to-transit aspects.\n",
    "CLASSIC_INCLUDE_TRANSIT_PAIR_ASPECTS = True\n",
    "\n",
    "# If True, disabled blocks are still built once and cached.\n",
    "PRECOMPUTE_DISABLED_BLOCKS = True\n",
    "\n",
    "# Models used for classification comparison.\n",
    "# MODEL_SET = ('xgb', 'rf')\n",
    "MODEL_SET = ('xgb',)\n",
    "\n",
    "# ---------------------------------------------------------------------\n",
    "# Sweep options: birth dates + Gaussian labels + key model hyperparameters.\n",
    "# Model selection is done by VALIDATION only.\n",
    "# TEST is evaluated only for best validation configs.\n",
    "# ---------------------------------------------------------------------\n",
    "ENABLE_GAUSS_HYPER_SWEEP = True\n",
    "\n",
    "GAUSS_WINDOWS = [151, 201]\n",
    "GAUSS_STDS = [30.0]\n",
    "\n",
    "XGB_PARAM_GRID = {\n",
    "    'n_estimators': [30, 50, 75,100,150],\n",
    "    'max_depth': [3, 4,6],\n",
    "    'learning_rate': [0.01],\n",
    "    'colsample_bytree': [0.7,0.8,0.9],\n",
    "    'subsample': [0.7,0.8,0.9],\n",
    "    'early_stopping_rounds': [75],\n",
    "    'weight_power': [1.0],\n",
    "    'sideways_penalty': [1.0],\n",
    "}\n",
    "\n",
    "RF_PARAM_GRID = {\n",
    "    'n_estimators': [600, 900],\n",
    "    'max_depth': [5, 7],\n",
    "    'min_samples_leaf': [4, 8],\n",
    "}\n",
    "\n",
    "# Optional cap for fast dry runs. None = full grid.\n",
    "MAX_SWEEP_RUNS = None\n",
    "\n",
    "print('Split mode:', SPLIT_MODE)\n",
    "print('Ratios train/val/test:', TRAIN_RATIO, VAL_RATIO, 1.0 - TRAIN_RATIO - VAL_RATIO)\n",
    "print('Birth datetime:', BIRTH_DT_UTC)\n",
    "print('Birthdate sweep enabled:', ENABLE_BIRTHDATE_SWEEP, 'num_dates=', len(BIRTH_DT_SWEEP_LIST))\n",
    "print('Feature blocks:', FEATURE_BLOCKS)\n",
    "print('Use transit pair aspects:', CLASSIC_INCLUDE_TRANSIT_PAIR_ASPECTS)\n",
    "print('XGB device:', XGB_DEVICE, '(CUDA available:', XGB_USE_CUDA, ')')\n",
    "print('Sweep enabled:', ENABLE_GAUSS_HYPER_SWEEP)\n",
    "print('Threshold sensitivity:', ENABLE_THRESHOLD_SENSITIVITY)\n",
    "print('Threshold grid points:', len(THRESHOLD_CANDIDATE_GRID), 'range=', (float(np.min(THRESHOLD_CANDIDATE_GRID)), float(np.max(THRESHOLD_CANDIDATE_GRID))))\n",
    "print('Threshold penalties grid sizes:', len(THRESHOLD_GAP_PENALTY_GRID), 'x', len(THRESHOLD_PRIOR_PENALTY_GRID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39d0580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Feature block builders\n",
    "# ------------------------------\n",
    "\n",
    "def _market_range_key(df_market: pd.DataFrame) -> dict:\n",
    "    return {\n",
    "        'start_date': pd.to_datetime(df_market['date']).min().strftime('%Y-%m-%d'),\n",
    "        'end_date': pd.to_datetime(df_market['date']).max().strftime('%Y-%m-%d'),\n",
    "        'rows': int(len(df_market)),\n",
    "    }\n",
    "\n",
    "\n",
    "def _cache_params(\n",
    "    df_market: pd.DataFrame,\n",
    "    block_name: str,\n",
    "    birth_dt_utc: str,\n",
    "    extra: dict | None = None,\n",
    ") -> dict:\n",
    "    params = {\n",
    "        'kind': block_name,\n",
    "        **_market_range_key(df_market),\n",
    "        'orb_mult': float(ORB_MULT),\n",
    "        'birth_dt_utc': str(birth_dt_utc),\n",
    "        'schema': 'v1_no_houses',\n",
    "    }\n",
    "    if extra:\n",
    "        params.update(extra)\n",
    "    return params\n",
    "\n",
    "\n",
    "def _normalize_phase_cols(df_phases: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df_phases.copy()\n",
    "    out['date'] = pd.to_datetime(out['date'])\n",
    "\n",
    "    if 'moon_phase_angle' in out.columns:\n",
    "        rad = np.deg2rad(pd.to_numeric(out['moon_phase_angle'], errors='coerce').astype(float))\n",
    "        out['moon_phase_angle_trig_sin'] = np.sin(rad)\n",
    "        out['moon_phase_angle_trig_cos'] = np.cos(rad)\n",
    "\n",
    "    elong_cols = [c for c in out.columns if c.endswith('_elongation')]\n",
    "    for col in elong_cols:\n",
    "        rad = np.deg2rad(pd.to_numeric(out[col], errors='coerce').astype(float))\n",
    "        out[f'{col}_trig_sin'] = np.sin(rad)\n",
    "        out[f'{col}_trig_cos'] = np.cos(rad)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _features_from_transit_df(df_market: pd.DataFrame, df_transits: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = df_market[['date']].copy()\n",
    "    base['date'] = pd.to_datetime(base['date'])\n",
    "\n",
    "    if df_transits.empty:\n",
    "        return base\n",
    "\n",
    "    df_work = df_transits.copy()\n",
    "    df_work['date'] = pd.to_datetime(df_work['date'])\n",
    "    feat = build_transit_aspect_features(df_work)\n",
    "    feat['date'] = pd.to_datetime(feat['date'])\n",
    "\n",
    "    out = base.merge(feat, on='date', how='left')\n",
    "    feature_cols = [c for c in out.columns if c != 'date']\n",
    "    out[feature_cols] = out[feature_cols].fillna(0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _features_from_pair_aspects_df(df_market: pd.DataFrame, df_pair_aspects: pd.DataFrame) -> pd.DataFrame:\n",
    "    base = df_market[['date']].copy()\n",
    "    base['date'] = pd.to_datetime(base['date'])\n",
    "\n",
    "    if df_pair_aspects.empty:\n",
    "        return base\n",
    "\n",
    "    df_work = df_pair_aspects.copy()\n",
    "    df_work['date'] = pd.to_datetime(df_work['date'])\n",
    "    feat = build_aspect_pair_features(df_work)\n",
    "    feat['date'] = pd.to_datetime(feat['date'])\n",
    "\n",
    "    rename_map = {c: f'tr_pair_{c}' for c in feat.columns if c != 'date'}\n",
    "    feat = feat.rename(columns=rename_map)\n",
    "\n",
    "    out = base.merge(feat, on='date', how='left')\n",
    "    feature_cols = [c for c in out.columns if c != 'date']\n",
    "    out[feature_cols] = out[feature_cols].fillna(0)\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_classic_transit_phase_block(df_market: pd.DataFrame, birth_dt_utc: str) -> pd.DataFrame:\n",
    "    block_name = 'classic_transit_phase'\n",
    "    params = _cache_params(\n",
    "        df_market,\n",
    "        block_name,\n",
    "        birth_dt_utc=birth_dt_utc,\n",
    "        extra={'include_transit_pair_aspects': bool(CLASSIC_INCLUDE_TRANSIT_PAIR_ASPECTS)},\n",
    "    )\n",
    "\n",
    "    if USE_CACHE:\n",
    "        cached = load_cache(CACHE_NAMESPACE, block_name, params, verbose=VERBOSE)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "\n",
    "    settings = init_ephemeris()\n",
    "    _, geo_by_date = calculate_bodies_for_dates(\n",
    "        dates=df_market['date'],\n",
    "        settings=settings,\n",
    "        center='geo',\n",
    "        progress=PROGRESS,\n",
    "    )\n",
    "    natal_bodies = get_natal_bodies(str(birth_dt_utc), settings, center='geo')\n",
    "\n",
    "    df_transits = calculate_transits_for_dates(\n",
    "        bodies_by_date=geo_by_date,\n",
    "        natal_bodies=natal_bodies,\n",
    "        settings=settings,\n",
    "        orb_mult=float(ORB_MULT),\n",
    "        progress=PROGRESS,\n",
    "    )\n",
    "\n",
    "    if not df_transits.empty:\n",
    "        df_transits = df_transits.copy()\n",
    "        df_transits['transit_body'] = 'tr_' + df_transits['transit_body'].astype(str)\n",
    "\n",
    "    transit_feat = _features_from_transit_df(df_market, df_transits)\n",
    "\n",
    "    out_base = transit_feat\n",
    "    if CLASSIC_INCLUDE_TRANSIT_PAIR_ASPECTS:\n",
    "        df_pair_aspects = calculate_aspects_for_dates(\n",
    "            bodies_by_date=geo_by_date,\n",
    "            settings=settings,\n",
    "            orb_mult=float(ORB_MULT),\n",
    "            progress=PROGRESS,\n",
    "            prefix='tr_',\n",
    "        )\n",
    "        pair_feat = _features_from_pair_aspects_df(df_market, df_pair_aspects)\n",
    "        out_base = out_base.merge(pair_feat, on='date', how='left')\n",
    "\n",
    "    df_phases = calculate_phases_for_dates(geo_by_date, progress=PROGRESS)\n",
    "    df_phases = _normalize_phase_cols(df_phases)\n",
    "\n",
    "    phase_cols = [c for c in df_phases.columns if c != 'date']\n",
    "    out = out_base.merge(df_phases[['date', *phase_cols]], on='date', how='left')\n",
    "\n",
    "    feature_cols = [c for c in out.columns if c != 'date']\n",
    "    out[feature_cols] = out[feature_cols].fillna(0)\n",
    "\n",
    "    if USE_CACHE:\n",
    "        save_cache(out, CACHE_NAMESPACE, block_name, params, verbose=VERBOSE)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _secondary_progressed_dt(birth_dt: datetime, market_dt: pd.Timestamp) -> datetime:\n",
    "    age_days = (market_dt.date() - birth_dt.date()).days\n",
    "    age_years = float(age_days) / 365.2425\n",
    "    progressed_dt = birth_dt + pd.to_timedelta(age_years, unit='D')\n",
    "    if isinstance(progressed_dt, pd.Timestamp):\n",
    "        return progressed_dt.to_pydatetime()\n",
    "    return progressed_dt\n",
    "\n",
    "\n",
    "def build_progressed_to_natal_block(df_market: pd.DataFrame, birth_dt_utc: str) -> pd.DataFrame:\n",
    "    block_name = 'progressed_to_natal'\n",
    "    params = _cache_params(df_market, block_name, birth_dt_utc=birth_dt_utc)\n",
    "\n",
    "    if USE_CACHE:\n",
    "        cached = load_cache(CACHE_NAMESPACE, block_name, params, verbose=VERBOSE)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "\n",
    "    settings = init_ephemeris()\n",
    "    birth_dt = parse_birth_dt_utc(str(birth_dt_utc))\n",
    "    natal_bodies = get_natal_bodies(str(birth_dt_utc), settings, center='geo')\n",
    "    aspects_cfg = scale_aspects(settings.aspects, float(ORB_MULT))\n",
    "\n",
    "    rows = []\n",
    "    date_list = pd.to_datetime(df_market['date']).reset_index(drop=True)\n",
    "\n",
    "    for i, market_dt in enumerate(date_list, start=1):\n",
    "        progressed_dt = _secondary_progressed_dt(birth_dt, market_dt)\n",
    "        progressed_bodies = calculate_bodies(progressed_dt, settings.bodies, center='geo')\n",
    "\n",
    "        hits = calculate_transit_aspects(progressed_bodies, natal_bodies, aspects_cfg)\n",
    "        for h in hits:\n",
    "            rows.append({\n",
    "                'date': market_dt.date(),\n",
    "                'transit_body': f'prog_{h.transit_body}',\n",
    "                'natal_body': h.natal_body,\n",
    "                'aspect': h.aspect,\n",
    "                'orb': h.orb,\n",
    "                'is_exact': h.is_exact,\n",
    "                'is_applying': h.is_applying,\n",
    "            })\n",
    "\n",
    "        if PROGRESS and (i == 1 or i % 500 == 0 or i == len(date_list)):\n",
    "            print(f'[progressed_to_natal] birth={str(birth_dt_utc)[:10]} {i}/{len(date_list)} days processed')\n",
    "\n",
    "    df_transits = pd.DataFrame(rows)\n",
    "    out = _features_from_transit_df(df_market, df_transits)\n",
    "\n",
    "    if USE_CACHE:\n",
    "        save_cache(out, CACHE_NAMESPACE, block_name, params, verbose=VERBOSE)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def _solar_arc_directed_bodies(\n",
    "    natal_bodies: list[BodyPosition],\n",
    "    solar_arc_deg: float,\n",
    "    market_date: pd.Timestamp,\n",
    ") -> list[BodyPosition]:\n",
    "    directed = []\n",
    "    for nb in natal_bodies:\n",
    "        directed.append(\n",
    "            BodyPosition(\n",
    "                date=market_date.date(),\n",
    "                body=f'dir_{nb.body}',\n",
    "                lon=(float(nb.lon) + float(solar_arc_deg)) % 360.0,\n",
    "                lat=float(nb.lat),\n",
    "                speed=0.0,\n",
    "                is_retro=False,\n",
    "                sign=nb.sign,\n",
    "                declination=float(nb.declination),\n",
    "            )\n",
    "        )\n",
    "    return directed\n",
    "\n",
    "\n",
    "def build_directed_to_natal_block(df_market: pd.DataFrame, birth_dt_utc: str) -> pd.DataFrame:\n",
    "    block_name = 'directed_to_natal'\n",
    "    params = _cache_params(df_market, block_name, birth_dt_utc=birth_dt_utc)\n",
    "\n",
    "    if USE_CACHE:\n",
    "        cached = load_cache(CACHE_NAMESPACE, block_name, params, verbose=VERBOSE)\n",
    "        if cached is not None:\n",
    "            return cached\n",
    "\n",
    "    settings = init_ephemeris()\n",
    "    birth_dt = parse_birth_dt_utc(str(birth_dt_utc))\n",
    "    natal_bodies = get_natal_bodies(str(birth_dt_utc), settings, center='geo')\n",
    "    natal_map = {b.body: b for b in natal_bodies}\n",
    "    if 'Sun' not in natal_map:\n",
    "        raise ValueError('Sun is missing in natal bodies; solar-arc direction cannot be built.')\n",
    "\n",
    "    aspects_cfg = scale_aspects(settings.aspects, float(ORB_MULT))\n",
    "\n",
    "    rows = []\n",
    "    date_list = pd.to_datetime(df_market['date']).reset_index(drop=True)\n",
    "\n",
    "    for i, market_dt in enumerate(date_list, start=1):\n",
    "        progressed_dt = _secondary_progressed_dt(birth_dt, market_dt)\n",
    "        progressed_bodies = calculate_bodies(progressed_dt, settings.bodies, center='geo')\n",
    "        progressed_map = {b.body: b for b in progressed_bodies}\n",
    "\n",
    "        if 'Sun' not in progressed_map:\n",
    "            continue\n",
    "\n",
    "        solar_arc = (float(progressed_map['Sun'].lon) - float(natal_map['Sun'].lon)) % 360.0\n",
    "        directed_bodies = _solar_arc_directed_bodies(natal_bodies, solar_arc, market_dt)\n",
    "\n",
    "        hits = calculate_transit_aspects(directed_bodies, natal_bodies, aspects_cfg)\n",
    "        for h in hits:\n",
    "            rows.append({\n",
    "                'date': market_dt.date(),\n",
    "                'transit_body': h.transit_body,\n",
    "                'natal_body': h.natal_body,\n",
    "                'aspect': h.aspect,\n",
    "                'orb': h.orb,\n",
    "                'is_exact': h.is_exact,\n",
    "                'is_applying': h.is_applying,\n",
    "            })\n",
    "\n",
    "        if PROGRESS and (i == 1 or i % 500 == 0 or i == len(date_list)):\n",
    "            print(f'[directed_to_natal] birth={str(birth_dt_utc)[:10]} {i}/{len(date_list)} days processed')\n",
    "\n",
    "    df_transits = pd.DataFrame(rows)\n",
    "    out = _features_from_transit_df(df_market, df_transits)\n",
    "\n",
    "    if USE_CACHE:\n",
    "        save_cache(out, CACHE_NAMESPACE, block_name, params, verbose=VERBOSE)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_feature_matrix(df_market: pd.DataFrame, birth_dt_utc: str) -> tuple[pd.DataFrame, list[str]]:\n",
    "    builders = {\n",
    "        'classic_transit_phase': build_classic_transit_phase_block,\n",
    "        'progressed_to_natal': build_progressed_to_natal_block,\n",
    "        'directed_to_natal': build_directed_to_natal_block,\n",
    "    }\n",
    "\n",
    "    base = df_market[['date']].copy()\n",
    "    base['date'] = pd.to_datetime(base['date'])\n",
    "\n",
    "    used_blocks = []\n",
    "\n",
    "    for block_name, builder in builders.items():\n",
    "        enabled = bool(FEATURE_BLOCKS.get(block_name, False))\n",
    "\n",
    "        if not enabled and not PRECOMPUTE_DISABLED_BLOCKS:\n",
    "            continue\n",
    "\n",
    "        print('-' * 100)\n",
    "        if enabled:\n",
    "            print(f'Building and USING block: {block_name} | birth={str(birth_dt_utc)[:10]}')\n",
    "        else:\n",
    "            print(f'Precomputing (cache only) block: {block_name} | birth={str(birth_dt_utc)[:10]}')\n",
    "\n",
    "        df_block = builder(df_market, birth_dt_utc=birth_dt_utc)\n",
    "\n",
    "        if enabled:\n",
    "            feature_cols = [c for c in df_block.columns if c != 'date']\n",
    "            rename_map = {c: f'{block_name}__{c}' for c in feature_cols}\n",
    "            base = base.merge(df_block.rename(columns=rename_map), on='date', how='left')\n",
    "            used_blocks.append(block_name)\n",
    "\n",
    "    all_feature_cols = [c for c in base.columns if c != 'date']\n",
    "    base[all_feature_cols] = base[all_feature_cols].fillna(0)\n",
    "    return base, used_blocks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "498a9344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading from cache: research2_moon__market__2017-11-01__8953c00f.parquet\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Building and USING block: classic_transit_phase | birth=2009-01-03\n",
      "ðŸ“‚ Loading from cache: research2_transit_blocks__classic_transit_phase__2017-11-01_orb0.15__ad6493d7.parquet\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Building and USING block: progressed_to_natal | birth=2009-01-03\n",
      "ðŸ“‚ Loading from cache: research2_transit_blocks__progressed_to_natal__2017-11-01_orb0.15__03edcc86.parquet\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Building and USING block: directed_to_natal | birth=2009-01-03\n",
      "ðŸ“‚ Loading from cache: research2_transit_blocks__directed_to_natal__2017-11-01_orb0.15__206dc751.parquet\n",
      "[features] birth=2009-01-03 blocks=['classic_transit_phase', 'progressed_to_natal', 'directed_to_natal'] rows=3017 cols=2056\n",
      "ðŸ“‚ Loading from cache: research2_moon__labels__2017-11-01_h1_gw201__f43f84de.parquet\n",
      "Merged dataset: 3013 samples (ALL days, forward-filled)\n",
      "Features: 2056\n",
      "Default birth: {'birth_dt_utc': '2009-01-03T18:15:05Z'}\n",
      "Default gauss: {'window': 201, 'std': 70.0}\n",
      "Dataset rows: 3013 Num features: 2056\n",
      "Rows: {'train': 1506, 'val': 603, 'test': 904}\n",
      "UP share: {'train': 0.4913678618857902, 'val': 0.5439469320066335, 'test': 0.4745575221238938}\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Dataset build (features + labels)\n",
    "# ------------------------------\n",
    "\n",
    "if SPLIT_MODE != 'classic':\n",
    "    raise ValueError('This notebook supports only classic split mode for now.')\n",
    "\n",
    "# 1) Market data.\n",
    "df_market = load_market_slice(\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    use_cache=USE_CACHE,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "\n",
    "# 2) Feature matrix cache by birth datetime.\n",
    "FEATURE_MATRIX_CACHE: dict[str, dict] = {}\n",
    "\n",
    "\n",
    "def get_feature_matrix_for_birth_dt(birth_dt_utc: str, verbose: bool = False) -> dict:\n",
    "    if birth_dt_utc in FEATURE_MATRIX_CACHE:\n",
    "        return FEATURE_MATRIX_CACHE[birth_dt_utc]\n",
    "\n",
    "    df_features_local, used_blocks_local = build_feature_matrix(df_market, birth_dt_utc=birth_dt_utc)\n",
    "\n",
    "    out = {\n",
    "        'birth_dt_utc': str(birth_dt_utc),\n",
    "        'birth_date': str(birth_dt_utc)[:10],\n",
    "        'df_features': df_features_local,\n",
    "        'used_blocks': used_blocks_local,\n",
    "    }\n",
    "    FEATURE_MATRIX_CACHE[birth_dt_utc] = out\n",
    "\n",
    "    if verbose:\n",
    "        print(\n",
    "            '[features]',\n",
    "            f\"birth={out['birth_date']}\",\n",
    "            f\"blocks={out['used_blocks']}\",\n",
    "            f\"rows={len(df_features_local)}\",\n",
    "            f\"cols={len([c for c in df_features_local.columns if c != 'date'])}\",\n",
    "        )\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_dataset_parts_for_gauss(\n",
    "    gauss_window: int,\n",
    "    gauss_std: float,\n",
    "    birth_dt_utc: str,\n",
    "    verbose: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"Build one dataset + classic split for fixed Gaussian labels and birth datetime.\"\"\"\n",
    "    feature_pack = get_feature_matrix_for_birth_dt(birth_dt_utc, verbose=verbose)\n",
    "    df_features_local = feature_pack['df_features']\n",
    "\n",
    "    df_labels = build_balanced_labels_for_gauss(\n",
    "        df_market=df_market,\n",
    "        gauss_window=int(gauss_window),\n",
    "        gauss_std=float(gauss_std),\n",
    "        label_cfg=LABEL_CFG,\n",
    "        use_cache=USE_CACHE,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    df_dataset = merge_features_with_labels(\n",
    "        df_features=df_features_local,\n",
    "        df_labels=df_labels,\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "    # Keep close for diagnostics only.\n",
    "    df_close = df_market[['date', 'close']].copy()\n",
    "    df_close['date'] = pd.to_datetime(df_close['date'])\n",
    "    df_dataset = pd.merge(df_dataset, df_close, on='date', how='left')\n",
    "\n",
    "    feature_cols_local = [c for c in df_dataset.columns if c not in {'date', 'target', 'close'}]\n",
    "\n",
    "    split = make_classic_split(df_dataset, train_ratio=TRAIN_RATIO, val_ratio=VAL_RATIO)\n",
    "\n",
    "    train_df_local = df_dataset.iloc[split.train_idx].copy().reset_index(drop=True)\n",
    "    val_df_local = df_dataset.iloc[split.val_idx].copy().reset_index(drop=True)\n",
    "    test_df_local = df_dataset.iloc[split.test_idx].copy().reset_index(drop=True)\n",
    "\n",
    "    return {\n",
    "        'birth_dt_utc': str(birth_dt_utc),\n",
    "        'birth_date': str(birth_dt_utc)[:10],\n",
    "        'used_blocks': list(feature_pack['used_blocks']),\n",
    "        'gauss_window': int(gauss_window),\n",
    "        'gauss_std': float(gauss_std),\n",
    "        'df_dataset': df_dataset,\n",
    "        'feature_cols': feature_cols_local,\n",
    "        'train_df': train_df_local,\n",
    "        'val_df': val_df_local,\n",
    "        'test_df': test_df_local,\n",
    "    }\n",
    "\n",
    "\n",
    "# Build default dataset once (used when sweep is disabled).\n",
    "default_parts = build_dataset_parts_for_gauss(\n",
    "    GAUSS_WINDOW,\n",
    "    GAUSS_STD,\n",
    "    birth_dt_utc=BIRTH_DT_UTC,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "df_dataset = default_parts['df_dataset']\n",
    "feature_cols = default_parts['feature_cols']\n",
    "train_df = default_parts['train_df']\n",
    "val_df = default_parts['val_df']\n",
    "test_df = default_parts['test_df']\n",
    "\n",
    "print('Default birth:', {'birth_dt_utc': BIRTH_DT_UTC})\n",
    "print('Default gauss:', {'window': GAUSS_WINDOW, 'std': GAUSS_STD})\n",
    "print('Dataset rows:', len(df_dataset), 'Num features:', len(feature_cols))\n",
    "print('Rows:', {'train': len(train_df), 'val': len(val_df), 'test': len(test_df)})\n",
    "print('UP share:', {\n",
    "    'train': float((train_df['target'] == 1).mean()),\n",
    "    'val': float((val_df['target'] == 1).mean()),\n",
    "    'test': float((test_df['target'] == 1).mean()),\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6197ecc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Model helpers (classification only)\n",
    "# ------------------------------\n",
    "\n",
    "VAL_SORT_COLS = ['val_recall_min', 'val_recall_gap', 'val_mcc', 'val_accuracy']\n",
    "VAL_SORT_ASC = [False, True, False, False]\n",
    "\n",
    "\n",
    "def _expand_param_grid(grid: dict[str, list]) -> list[dict]:\n",
    "    \"\"\"Expand a simple dict-of-lists grid into a list of dicts.\"\"\"\n",
    "    if not grid:\n",
    "        return [{}]\n",
    "    keys = list(grid.keys())\n",
    "    combos = product(*(grid[k] for k in keys))\n",
    "    return [dict(zip(keys, vals)) for vals in combos]\n",
    "\n",
    "\n",
    "def _make_pred_frame(df_part: pd.DataFrame, split_role: str, proba_up: np.ndarray) -> pd.DataFrame:\n",
    "    out = df_part[['date', 'target']].copy().reset_index(drop=True)\n",
    "    out['split_role'] = split_role\n",
    "    out['pred_proba_up'] = np.asarray(proba_up, dtype=float)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _xgb_params_with_defaults(model_params: dict | None = None) -> dict:\n",
    "    params = {\n",
    "        'early_stopping_rounds': 50,\n",
    "        'n_estimators': 500,\n",
    "        'max_depth': 6,\n",
    "        'learning_rate': 0.03,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'subsample': 0.8,\n",
    "        'weight_power': 1.0,\n",
    "        'sideways_penalty': 1.0,\n",
    "    }\n",
    "    if model_params:\n",
    "        params.update(model_params)\n",
    "    return params\n",
    "\n",
    "\n",
    "def _rf_params_with_defaults(model_params: dict | None = None) -> dict:\n",
    "    params = {\n",
    "        'n_estimators': 800,\n",
    "        'max_depth': 6,\n",
    "        'min_samples_leaf': 8,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': 1,\n",
    "    }\n",
    "    if model_params:\n",
    "        params.update(model_params)\n",
    "    return params\n",
    "\n",
    "\n",
    "def train_predict_xgb(\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    feature_cols_local: list[str],\n",
    "    model_params: dict | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    X_train = train_df[feature_cols_local].to_numpy(dtype=float)\n",
    "    y_train = train_df['target'].to_numpy(dtype=int)\n",
    "    X_val = val_df[feature_cols_local].to_numpy(dtype=float)\n",
    "    y_val = val_df['target'].to_numpy(dtype=int)\n",
    "    X_test = test_df[feature_cols_local].to_numpy(dtype=float)\n",
    "\n",
    "    xgb_params = _xgb_params_with_defaults(model_params)\n",
    "\n",
    "    model = train_xgb_model(\n",
    "        X_train=X_train,\n",
    "        y_train=y_train,\n",
    "        X_val=X_val,\n",
    "        y_val=y_val,\n",
    "        feature_names=feature_cols_local,\n",
    "        n_classes=2,\n",
    "        device=XGB_DEVICE,\n",
    "        verbose=False,\n",
    "        early_stopping_rounds=int(xgb_params['early_stopping_rounds']),\n",
    "        n_estimators=int(xgb_params['n_estimators']),\n",
    "        max_depth=int(xgb_params['max_depth']),\n",
    "        learning_rate=float(xgb_params['learning_rate']),\n",
    "        colsample_bytree=float(xgb_params['colsample_bytree']),\n",
    "        subsample=float(xgb_params['subsample']),\n",
    "        weight_power=float(xgb_params['weight_power']),\n",
    "        sideways_penalty=float(xgb_params['sideways_penalty']),\n",
    "    )\n",
    "\n",
    "    p_train = predict_proba_up_safe(model=model, X=X_train)\n",
    "    p_val = predict_proba_up_safe(model=model, X=X_val)\n",
    "    p_test = predict_proba_up_safe(model=model, X=X_test)\n",
    "\n",
    "    return pd.concat(\n",
    "        [\n",
    "            _make_pred_frame(train_df, 'train', p_train),\n",
    "            _make_pred_frame(val_df, 'val', p_val),\n",
    "            _make_pred_frame(test_df, 'test', p_test),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def train_predict_rf(\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    feature_cols_local: list[str],\n",
    "    model_params: dict | None = None,\n",
    ") -> pd.DataFrame:\n",
    "    X_train = train_df[feature_cols_local].to_numpy(dtype=float)\n",
    "    y_train = train_df['target'].to_numpy(dtype=int)\n",
    "    X_val = val_df[feature_cols_local].to_numpy(dtype=float)\n",
    "    X_test = test_df[feature_cols_local].to_numpy(dtype=float)\n",
    "\n",
    "    rf_params = _rf_params_with_defaults(model_params)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=int(rf_params['n_estimators']),\n",
    "        max_depth=int(rf_params['max_depth']),\n",
    "        min_samples_leaf=int(rf_params['min_samples_leaf']),\n",
    "        random_state=int(rf_params['random_state']),\n",
    "        n_jobs=int(rf_params['n_jobs']),\n",
    "    )\n",
    "\n",
    "    w_train = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "    model.fit(X_train, y_train, sample_weight=w_train)\n",
    "\n",
    "    p_train = model.predict_proba(X_train)[:, 1]\n",
    "    p_val = model.predict_proba(X_val)[:, 1]\n",
    "    p_test = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    return pd.concat(\n",
    "        [\n",
    "            _make_pred_frame(train_df, 'train', p_train),\n",
    "            _make_pred_frame(val_df, 'val', p_val),\n",
    "            _make_pred_frame(test_df, 'test', p_test),\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def predict_for_model(parts: dict, model_name: str, model_params: dict | None) -> pd.DataFrame:\n",
    "    train_df_local = parts['train_df']\n",
    "    val_df_local = parts['val_df']\n",
    "    test_df_local = parts['test_df']\n",
    "    feature_cols_local = parts['feature_cols']\n",
    "\n",
    "    if model_name == 'xgb':\n",
    "        return train_predict_xgb(\n",
    "            train_df_local,\n",
    "            val_df_local,\n",
    "            test_df_local,\n",
    "            feature_cols_local,\n",
    "            model_params=model_params,\n",
    "        )\n",
    "    if model_name == 'rf':\n",
    "        return train_predict_rf(\n",
    "            train_df_local,\n",
    "            val_df_local,\n",
    "            test_df_local,\n",
    "            feature_cols_local,\n",
    "            model_params=model_params,\n",
    "        )\n",
    "    raise ValueError(f'Unsupported model: {model_name}')\n",
    "\n",
    "\n",
    "def eval_row_from_pred(\n",
    "    pred_all: pd.DataFrame,\n",
    "    model_name: str,\n",
    "    gap_penalty: float,\n",
    "    prior_penalty: float,\n",
    "    thresholds: np.ndarray | None = None,\n",
    "    include_test: bool = True,\n",
    ") -> dict:\n",
    "    df_val = pred_all[pred_all['split_role'] == 'val']\n",
    "    y_val = df_val['target'].to_numpy(dtype=int)\n",
    "    p_val = df_val['pred_proba_up'].to_numpy(dtype=float)\n",
    "\n",
    "    t, score = tune_threshold_with_balance(\n",
    "        y_val=y_val,\n",
    "        proba_up=p_val,\n",
    "        gap_penalty=float(gap_penalty),\n",
    "        prior_penalty=float(prior_penalty),\n",
    "        thresholds=thresholds,\n",
    "    )\n",
    "\n",
    "    out = {\n",
    "        'model': model_name,\n",
    "        'val_threshold': float(t),\n",
    "        'val_threshold_score': float(score),\n",
    "        'threshold_gap_penalty': float(gap_penalty),\n",
    "        'threshold_prior_penalty': float(prior_penalty),\n",
    "    }\n",
    "\n",
    "    roles = [('val', df_val)]\n",
    "    if include_test:\n",
    "        df_test = pred_all[pred_all['split_role'] == 'test']\n",
    "        roles.append(('test', df_test))\n",
    "\n",
    "    for role, df_part in roles:\n",
    "        y = df_part['target'].to_numpy(dtype=int)\n",
    "        p = df_part['pred_proba_up'].to_numpy(dtype=float)\n",
    "        pred = (p >= float(t)).astype(int)\n",
    "\n",
    "        m = compute_binary_metrics(y_true=y, y_pred=pred)\n",
    "        s = compute_statistical_significance(y_true=y, y_pred=pred, random_baseline=0.5)\n",
    "\n",
    "        for k, v in m.items():\n",
    "            out[f'{role}_{k}'] = float(v) if isinstance(v, (float, int)) else v\n",
    "        out[f'{role}_p_value_vs_random'] = float(s['p_value_vs_random'])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def eval_classification_with_val_threshold(\n",
    "    pred_all: pd.DataFrame,\n",
    "    model_name: str,\n",
    "    include_test: bool = True,\n",
    ") -> dict:\n",
    "    return eval_row_from_pred(\n",
    "        pred_all=pred_all,\n",
    "        model_name=model_name,\n",
    "        gap_penalty=THRESHOLD_GAP_PENALTY,\n",
    "        prior_penalty=THRESHOLD_PRIOR_PENALTY,\n",
    "        thresholds=THRESHOLD_CANDIDATE_GRID,\n",
    "        include_test=include_test,\n",
    "    )\n",
    "\n",
    "\n",
    "def _attach_eval_metadata(row: dict, parts: dict, model_params: dict | None) -> dict:\n",
    "    out = dict(row)\n",
    "    out['birth_dt_utc'] = str(parts['birth_dt_utc'])\n",
    "    out['birth_date'] = str(parts['birth_date'])\n",
    "    out['gauss_window'] = int(parts['gauss_window'])\n",
    "    out['gauss_std'] = float(parts['gauss_std'])\n",
    "\n",
    "    safe_params = dict(model_params or {})\n",
    "    out['model_params_json'] = json.dumps(safe_params, sort_keys=True)\n",
    "    for k, v in safe_params.items():\n",
    "        out[f'hp_{k}'] = v\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def run_one_eval_with_pred(\n",
    "    parts: dict,\n",
    "    model_name: str,\n",
    "    model_params: dict | None,\n",
    "    include_test: bool,\n",
    ") -> tuple[dict, pd.DataFrame]:\n",
    "    pred_all = predict_for_model(parts=parts, model_name=model_name, model_params=model_params)\n",
    "    row = eval_classification_with_val_threshold(\n",
    "        pred_all=pred_all,\n",
    "        model_name=model_name,\n",
    "        include_test=include_test,\n",
    "    )\n",
    "    row = _attach_eval_metadata(row=row, parts=parts, model_params=model_params)\n",
    "    return row, pred_all\n",
    "\n",
    "\n",
    "def run_one_eval(\n",
    "    parts: dict,\n",
    "    model_name: str,\n",
    "    model_params: dict | None,\n",
    "    include_test: bool,\n",
    ") -> dict:\n",
    "    row, _ = run_one_eval_with_pred(\n",
    "        parts=parts,\n",
    "        model_name=model_name,\n",
    "        model_params=model_params,\n",
    "        include_test=include_test,\n",
    "    )\n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a73b6b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep total runs (validation stage): 270\n",
      "[sweep-run] 1/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[sweep-run] 2/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4894 val_f1=0.3452 val_mcc=-0.0513 val_prec_d=0.4688 val_prec_u=0.4074 val_rec_d=0.9441 val_rec_u=0.0347 val_rec_min=0.0347 val_gap=0.9094 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[sweep-run] 3/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[sweep-run] 4/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[sweep-run] 5/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4894 val_f1=0.3452 val_mcc=-0.0513 val_prec_d=0.4688 val_prec_u=0.4074 val_rec_d=0.9441 val_rec_u=0.0347 val_rec_min=0.0347 val_gap=0.9094 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[sweep-run] 6/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[sweep-run] 7/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 8/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4494 val_bal_acc=0.4685 val_f1=0.3742 val_mcc=-0.0943 val_prec_d=0.4563 val_prec_u=0.4026 val_rec_d=0.8392 val_rec_u=0.0978 val_rec_min=0.0978 val_gap=0.7414 val_p=0.994243\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 9/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 10/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 11/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 12/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 13/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 14/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 15/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 16/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 17/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5040 val_f1=0.4940 val_mcc=0.0084 val_prec_d=0.4802 val_prec_u=0.5287 val_rec_d=0.3392 val_rec_u=0.6688 val_rec_min=0.3392 val_gap=0.3296 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 18/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.4912 val_f1=0.4532 val_mcc=-0.0215 val_prec_d=0.4538 val_prec_u=0.5201 val_rec_d=0.2063 val_rec_u=0.7760 val_rec_min=0.2063 val_gap=0.5697 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 19/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 20/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[sweep-run] 21/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[sweep-run] 22/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[sweep-run] 23/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4845 val_f1=0.4143 val_mcc=-0.0411 val_prec_d=0.4649 val_prec_u=0.4808 val_rec_d=0.8112 val_rec_u=0.1577 val_rec_min=0.1577 val_gap=0.6535 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[sweep-run] 24/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[sweep-run] 25/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[sweep-run] 26/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.5216 val_f1=0.4637 val_mcc=0.0545 val_prec_d=0.4877 val_prec_u=0.5812 val_rec_d=0.8287 val_rec_u=0.2145 val_rec_min=0.2145 val_gap=0.6142 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[sweep-run] 27/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5390 val_bal_acc=0.5460 val_f1=0.5336 val_mcc=0.0952 val_prec_d=0.5105 val_prec_u=0.5882 val_rec_d=0.6818 val_rec_u=0.4101 val_rec_min=0.4101 val_gap=0.2717 val_p=0.030471\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[sweep-run] 28/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4876 val_bal_acc=0.4923 val_f1=0.4853 val_mcc=-0.0157 val_prec_d=0.4678 val_prec_u=0.5163 val_rec_d=0.5839 val_rec_u=0.4006 val_rec_min=0.4006 val_gap=0.1833 val_p=0.742644\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[sweep-run] 29/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5373 val_bal_acc=0.5384 val_f1=0.5373 val_mcc=0.0767 val_prec_d=0.5112 val_prec_u=0.5655 val_rec_d=0.5594 val_rec_u=0.5174 val_rec_min=0.5174 val_gap=0.0421 val_p=0.036537\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5373 val_bal_acc=0.5384 val_f1=0.5373 val_mcc=0.0767 val_prec_d=0.5112 val_prec_u=0.5655 val_rec_d=0.5594 val_rec_u=0.5174 val_rec_min=0.5174 val_gap=0.0421 val_p=0.036537\n",
      "[sweep-run] 30/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5373 val_bal_acc=0.5384 val_f1=0.5373 val_mcc=0.0767 val_prec_d=0.5112 val_prec_u=0.5655 val_rec_d=0.5594 val_rec_u=0.5174 val_rec_min=0.5174 val_gap=0.0421 val_p=0.036537\n",
      "[sweep-run] 31/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5373 val_bal_acc=0.5384 val_f1=0.5373 val_mcc=0.0767 val_prec_d=0.5112 val_prec_u=0.5655 val_rec_d=0.5594 val_rec_u=0.5174 val_rec_min=0.5174 val_gap=0.0421 val_p=0.036537\n",
      "[sweep-run] 32/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 33/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 34/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 35/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4494 val_bal_acc=0.4685 val_f1=0.3742 val_mcc=-0.0943 val_prec_d=0.4563 val_prec_u=0.4026 val_rec_d=0.8392 val_rec_u=0.0978 val_rec_min=0.0978 val_gap=0.7414 val_p=0.994243\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 36/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 37/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 38/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 39/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 40/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 41/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 42/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 43/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 44/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5040 val_f1=0.4940 val_mcc=0.0084 val_prec_d=0.4802 val_prec_u=0.5287 val_rec_d=0.3392 val_rec_u=0.6688 val_rec_min=0.3392 val_gap=0.3296 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 45/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.4912 val_f1=0.4532 val_mcc=-0.0215 val_prec_d=0.4538 val_prec_u=0.5201 val_rec_d=0.2063 val_rec_u=0.7760 val_rec_min=0.2063 val_gap=0.5697 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 46/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 47/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 48/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 49/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 50/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4845 val_f1=0.4143 val_mcc=-0.0411 val_prec_d=0.4649 val_prec_u=0.4808 val_rec_d=0.8112 val_rec_u=0.1577 val_rec_min=0.1577 val_gap=0.6535 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 51/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 52/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 53/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.5216 val_f1=0.4637 val_mcc=0.0545 val_prec_d=0.4877 val_prec_u=0.5812 val_rec_d=0.8287 val_rec_u=0.2145 val_rec_min=0.2145 val_gap=0.6142 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 54/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5390 val_bal_acc=0.5460 val_f1=0.5336 val_mcc=0.0952 val_prec_d=0.5105 val_prec_u=0.5882 val_rec_d=0.6818 val_rec_u=0.4101 val_rec_min=0.4101 val_gap=0.2717 val_p=0.030471\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 55/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5340 val_bal_acc=0.5381 val_f1=0.5327 val_mcc=0.0772 val_prec_d=0.5072 val_prec_u=0.5709 val_rec_d=0.6189 val_rec_u=0.4574 val_rec_min=0.4574 val_gap=0.1615 val_p=0.051625\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 56/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5539 val_bal_acc=0.5521 val_f1=0.5521 val_mcc=0.1044 val_prec_d=0.5305 val_prec_u=0.5741 val_rec_d=0.5175 val_rec_u=0.5868 val_rec_min=0.5175 val_gap=0.0693 val_p=0.004549\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 57/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 58/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5240 val_bal_acc=0.5237 val_f1=0.5235 val_mcc=0.0474 val_prec_d=0.4983 val_prec_u=0.5490 val_rec_d=0.5175 val_rec_u=0.5300 val_rec_min=0.5175 val_gap=0.0125 val_p=0.127082\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 59/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5755 val_bal_acc=0.5778 val_f1=0.5754 val_mcc=0.1558 val_prec_d=0.5460 val_prec_u=0.6101 val_rec_d=0.6224 val_rec_u=0.5331 val_rec_min=0.5331 val_gap=0.0893 val_p=0.000121\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 60/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 61/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5307 val_bal_acc=0.5321 val_f1=0.5307 val_mcc=0.0642 val_prec_d=0.5047 val_prec_u=0.5594 val_rec_d=0.5594 val_rec_u=0.5047 val_rec_min=0.5047 val_gap=0.0547 val_p=0.071288\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5592 val_f1=0.5587 val_mcc=0.1183 val_prec_d=0.5329 val_prec_u=0.5853 val_rec_d=0.5664 val_rec_u=0.5521 val_rec_min=0.5521 val_gap=0.0144 val_p=0.002162\n",
      "[sweep-run] 62/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 63/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 64/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 65/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 66/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 67/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 68/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 69/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 70/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 71/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5040 val_f1=0.4940 val_mcc=0.0084 val_prec_d=0.4802 val_prec_u=0.5287 val_rec_d=0.3392 val_rec_u=0.6688 val_rec_min=0.3392 val_gap=0.3296 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 72/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.4912 val_f1=0.4532 val_mcc=-0.0215 val_prec_d=0.4538 val_prec_u=0.5201 val_rec_d=0.2063 val_rec_u=0.7760 val_rec_min=0.2063 val_gap=0.5697 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 73/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 74/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 75/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 76/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 77/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4845 val_f1=0.4143 val_mcc=-0.0411 val_prec_d=0.4649 val_prec_u=0.4808 val_rec_d=0.8112 val_rec_u=0.1577 val_rec_min=0.1577 val_gap=0.6535 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 78/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 79/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 80/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.5216 val_f1=0.4637 val_mcc=0.0545 val_prec_d=0.4877 val_prec_u=0.5812 val_rec_d=0.8287 val_rec_u=0.2145 val_rec_min=0.2145 val_gap=0.6142 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 81/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5390 val_bal_acc=0.5460 val_f1=0.5336 val_mcc=0.0952 val_prec_d=0.5105 val_prec_u=0.5882 val_rec_d=0.6818 val_rec_u=0.4101 val_rec_min=0.4101 val_gap=0.2717 val_p=0.030471\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 82/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5340 val_bal_acc=0.5381 val_f1=0.5327 val_mcc=0.0772 val_prec_d=0.5072 val_prec_u=0.5709 val_rec_d=0.6189 val_rec_u=0.4574 val_rec_min=0.4574 val_gap=0.1615 val_p=0.051625\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 83/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5373 val_bal_acc=0.5367 val_f1=0.5366 val_mcc=0.0733 val_prec_d=0.5119 val_prec_u=0.5613 val_rec_d=0.5245 val_rec_u=0.5489 val_rec_min=0.5245 val_gap=0.0244 val_p=0.036537\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 84/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 85/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5240 val_bal_acc=0.5239 val_f1=0.5236 val_mcc=0.0477 val_prec_d=0.4983 val_prec_u=0.5493 val_rec_d=0.5210 val_rec_u=0.5268 val_rec_min=0.5210 val_gap=0.0058 val_p=0.127082\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 86/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5423 val_bal_acc=0.5404 val_f1=0.5404 val_mcc=0.0809 val_prec_d=0.5180 val_prec_u=0.5631 val_rec_d=0.5035 val_rec_u=0.5773 val_rec_min=0.5035 val_gap=0.0738 val_p=0.020823\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 87/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 88/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5310 val_f1=0.5290 val_mcc=0.0621 val_prec_d=0.5031 val_prec_u=0.5591 val_rec_d=0.5699 val_rec_u=0.4921 val_rec_min=0.4921 val_gap=0.0778 val_p=0.083063\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 89/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5622 val_bal_acc=0.5626 val_f1=0.5620 val_mcc=0.1250 val_prec_d=0.5362 val_prec_u=0.5886 val_rec_d=0.5699 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0147 val_p=0.001277\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 90/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 91/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 92/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 93/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 94/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 95/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 96/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 97/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 98/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5040 val_f1=0.4940 val_mcc=0.0084 val_prec_d=0.4802 val_prec_u=0.5287 val_rec_d=0.3392 val_rec_u=0.6688 val_rec_min=0.3392 val_gap=0.3296 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 99/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.4912 val_f1=0.4532 val_mcc=-0.0215 val_prec_d=0.4538 val_prec_u=0.5201 val_rec_d=0.2063 val_rec_u=0.7760 val_rec_min=0.2063 val_gap=0.5697 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 100/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 101/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 102/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 103/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 104/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4845 val_f1=0.4143 val_mcc=-0.0411 val_prec_d=0.4649 val_prec_u=0.4808 val_rec_d=0.8112 val_rec_u=0.1577 val_rec_min=0.1577 val_gap=0.6535 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 105/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 106/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 107/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.5216 val_f1=0.4637 val_mcc=0.0545 val_prec_d=0.4877 val_prec_u=0.5812 val_rec_d=0.8287 val_rec_u=0.2145 val_rec_min=0.2145 val_gap=0.6142 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 108/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5390 val_bal_acc=0.5460 val_f1=0.5336 val_mcc=0.0952 val_prec_d=0.5105 val_prec_u=0.5882 val_rec_d=0.6818 val_rec_u=0.4101 val_rec_min=0.4101 val_gap=0.2717 val_p=0.030471\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 109/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5340 val_bal_acc=0.5381 val_f1=0.5327 val_mcc=0.0772 val_prec_d=0.5072 val_prec_u=0.5709 val_rec_d=0.6189 val_rec_u=0.4574 val_rec_min=0.4574 val_gap=0.1615 val_p=0.051625\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 110/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5373 val_bal_acc=0.5367 val_f1=0.5366 val_mcc=0.0733 val_prec_d=0.5119 val_prec_u=0.5613 val_rec_d=0.5245 val_rec_u=0.5489 val_rec_min=0.5245 val_gap=0.0244 val_p=0.036537\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 111/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 112/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5240 val_bal_acc=0.5239 val_f1=0.5236 val_mcc=0.0477 val_prec_d=0.4983 val_prec_u=0.5493 val_rec_d=0.5210 val_rec_u=0.5268 val_rec_min=0.5210 val_gap=0.0058 val_p=0.127082\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 113/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5423 val_bal_acc=0.5404 val_f1=0.5404 val_mcc=0.0809 val_prec_d=0.5180 val_prec_u=0.5631 val_rec_d=0.5035 val_rec_u=0.5773 val_rec_min=0.5035 val_gap=0.0738 val_p=0.020823\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 114/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 115/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5310 val_f1=0.5290 val_mcc=0.0621 val_prec_d=0.5031 val_prec_u=0.5591 val_rec_d=0.5699 val_rec_u=0.4921 val_rec_min=0.4921 val_gap=0.0778 val_p=0.083063\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 116/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5622 val_bal_acc=0.5626 val_f1=0.5620 val_mcc=0.1250 val_prec_d=0.5362 val_prec_u=0.5886 val_rec_d=0.5699 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0147 val_p=0.001277\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 117/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 118/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 119/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 120/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 121/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4714 val_f1=0.4572 val_mcc=-0.0613 val_prec_d=0.4293 val_prec_u=0.5049 val_rec_d=0.2867 val_rec_u=0.6562 val_rec_min=0.2867 val_gap=0.3694 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 122/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 123/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 124/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 125/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5040 val_f1=0.4940 val_mcc=0.0084 val_prec_d=0.4802 val_prec_u=0.5287 val_rec_d=0.3392 val_rec_u=0.6688 val_rec_min=0.3392 val_gap=0.3296 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 126/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.4912 val_f1=0.4532 val_mcc=-0.0215 val_prec_d=0.4538 val_prec_u=0.5201 val_rec_d=0.2063 val_rec_u=0.7760 val_rec_min=0.2063 val_gap=0.5697 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 127/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 128/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 129/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 130/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4892 val_bal_acc=0.4944 val_f1=0.4864 val_mcc=-0.0115 val_prec_d=0.4696 val_prec_u=0.5187 val_rec_d=0.5944 val_rec_u=0.3943 val_rec_min=0.3943 val_gap=0.2001 val_p=0.715685\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 131/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4845 val_f1=0.4143 val_mcc=-0.0411 val_prec_d=0.4649 val_prec_u=0.4808 val_rec_d=0.8112 val_rec_u=0.1577 val_rec_min=0.1577 val_gap=0.6535 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 132/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 133/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 134/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5058 val_bal_acc=0.5216 val_f1=0.4637 val_mcc=0.0545 val_prec_d=0.4877 val_prec_u=0.5812 val_rec_d=0.8287 val_rec_u=0.2145 val_rec_min=0.2145 val_gap=0.6142 val_p=0.403497\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 135/270 model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5390 val_bal_acc=0.5460 val_f1=0.5336 val_mcc=0.0952 val_prec_d=0.5105 val_prec_u=0.5882 val_rec_d=0.6818 val_rec_u=0.4101 val_rec_min=0.4101 val_gap=0.2717 val_p=0.030471\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 136/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 137/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4894 val_f1=0.3452 val_mcc=-0.0513 val_prec_d=0.4688 val_prec_u=0.4074 val_rec_d=0.9441 val_rec_u=0.0347 val_rec_min=0.0347 val_gap=0.9094 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 138/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 139/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 140/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4894 val_f1=0.3452 val_mcc=-0.0513 val_prec_d=0.4688 val_prec_u=0.4074 val_rec_d=0.9441 val_rec_u=0.0347 val_rec_min=0.0347 val_gap=0.9094 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 141/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 142/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 143/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4494 val_bal_acc=0.4685 val_f1=0.3742 val_mcc=-0.0943 val_prec_d=0.4563 val_prec_u=0.4026 val_rec_d=0.8392 val_rec_u=0.0978 val_rec_min=0.0978 val_gap=0.7414 val_p=0.994243\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 144/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 145/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 146/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 147/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 148/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 149/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 150/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 151/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 152/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5048 val_f1=0.4972 val_mcc=0.0101 val_prec_d=0.4811 val_prec_u=0.5294 val_rec_d=0.3566 val_rec_u=0.6530 val_rec_min=0.3566 val_gap=0.2964 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 153/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5091 val_bal_acc=0.4945 val_f1=0.4569 val_mcc=-0.0134 val_prec_d=0.4615 val_prec_u=0.5222 val_rec_d=0.2098 val_rec_u=0.7792 val_rec_min=0.2098 val_gap=0.5694 val_p=0.341936\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 154/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4959 val_bal_acc=0.5048 val_f1=0.4846 val_mcc=0.0102 val_prec_d=0.4778 val_prec_u=0.5330 val_rec_d=0.6783 val_rec_u=0.3312 val_rec_min=0.3312 val_gap=0.3471 val_p=0.596503\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 155/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 156/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 157/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4925 val_bal_acc=0.4977 val_f1=0.4897 val_mcc=-0.0047 val_prec_d=0.4724 val_prec_u=0.5228 val_rec_d=0.5979 val_rec_u=0.3975 val_rec_min=0.3975 val_gap=0.2004 val_p=0.658064\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 158/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5340 val_bal_acc=0.5311 val_f1=0.5308 val_mcc=0.0626 val_prec_d=0.5094 val_prec_u=0.5536 val_rec_d=0.4755 val_rec_u=0.5868 val_rec_min=0.4755 val_gap=0.1112 val_p=0.051625\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 159/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 160/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 161/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5158 val_bal_acc=0.5051 val_f1=0.4877 val_mcc=0.0111 val_prec_d=0.4830 val_prec_u=0.5293 val_rec_d=0.2972 val_rec_u=0.7129 val_rec_min=0.2972 val_gap=0.4157 val_p=0.231789\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 162/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 30, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5333 val_f1=0.5187 val_mcc=0.0697 val_prec_d=0.5000 val_prec_u=0.5728 val_rec_d=0.6818 val_rec_u=0.3849 val_rec_min=0.3849 val_gap=0.2970 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 163/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4861 val_f1=0.4779 val_mcc=-0.0283 val_prec_d=0.4628 val_prec_u=0.5083 val_rec_d=0.5874 val_rec_u=0.3849 val_rec_min=0.3849 val_gap=0.2026 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 164/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5423 val_bal_acc=0.5433 val_f1=0.5423 val_mcc=0.0865 val_prec_d=0.5160 val_prec_u=0.5704 val_rec_d=0.5629 val_rec_u=0.5237 val_rec_min=0.5237 val_gap=0.0393 val_p=0.020823\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 165/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 166/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4843 val_f1=0.4156 val_mcc=-0.0412 val_prec_d=0.4648 val_prec_u=0.4811 val_rec_d=0.8077 val_rec_u=0.1609 val_rec_min=0.1609 val_gap=0.6468 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 167/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5423 val_bal_acc=0.5412 val_f1=0.5412 val_mcc=0.0825 val_prec_d=0.5174 val_prec_u=0.5651 val_rec_d=0.5210 val_rec_u=0.5615 val_rec_min=0.5210 val_gap=0.0405 val_p=0.020823\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 168/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 169/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5240 val_f1=0.5216 val_mcc=0.0489 val_prec_d=0.5041 val_prec_u=0.5457 val_rec_d=0.4266 val_rec_u=0.6215 val_rec_min=0.4266 val_gap=0.1949 val_p=0.083063\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 170/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4494 val_bal_acc=0.4685 val_f1=0.3742 val_mcc=-0.0943 val_prec_d=0.4563 val_prec_u=0.4026 val_rec_d=0.8392 val_rec_u=0.0978 val_rec_min=0.0978 val_gap=0.7414 val_p=0.994243\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 171/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 172/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 173/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 174/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 175/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 176/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 177/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 178/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 179/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5048 val_f1=0.4972 val_mcc=0.0101 val_prec_d=0.4811 val_prec_u=0.5294 val_rec_d=0.3566 val_rec_u=0.6530 val_rec_min=0.3566 val_gap=0.2964 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 180/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5091 val_bal_acc=0.4945 val_f1=0.4569 val_mcc=-0.0134 val_prec_d=0.4615 val_prec_u=0.5222 val_rec_d=0.2098 val_rec_u=0.7792 val_rec_min=0.2098 val_gap=0.5694 val_p=0.341936\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 181/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4959 val_bal_acc=0.5048 val_f1=0.4846 val_mcc=0.0102 val_prec_d=0.4778 val_prec_u=0.5330 val_rec_d=0.6783 val_rec_u=0.3312 val_rec_min=0.3312 val_gap=0.3471 val_p=0.596503\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 182/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 183/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 184/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4925 val_bal_acc=0.4977 val_f1=0.4897 val_mcc=-0.0047 val_prec_d=0.4724 val_prec_u=0.5228 val_rec_d=0.5979 val_rec_u=0.3975 val_rec_min=0.3975 val_gap=0.2004 val_p=0.658064\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 185/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5340 val_bal_acc=0.5311 val_f1=0.5308 val_mcc=0.0626 val_prec_d=0.5094 val_prec_u=0.5536 val_rec_d=0.4755 val_rec_u=0.5868 val_rec_min=0.4755 val_gap=0.1112 val_p=0.051625\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 186/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 187/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 188/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5158 val_bal_acc=0.5051 val_f1=0.4877 val_mcc=0.0111 val_prec_d=0.4830 val_prec_u=0.5293 val_rec_d=0.2972 val_rec_u=0.7129 val_rec_min=0.2972 val_gap=0.4157 val_p=0.231789\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 189/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 50, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5333 val_f1=0.5187 val_mcc=0.0697 val_prec_d=0.5000 val_prec_u=0.5728 val_rec_d=0.6818 val_rec_u=0.3849 val_rec_min=0.3849 val_gap=0.2970 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 190/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5324 val_f1=0.5283 val_mcc=0.0652 val_prec_d=0.5029 val_prec_u=0.5627 val_rec_d=0.5979 val_rec_u=0.4669 val_rec_min=0.4669 val_gap=0.1310 val_p=0.083063\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 191/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5579 val_f1=0.5577 val_mcc=0.1164 val_prec_d=0.5390 val_prec_u=0.5778 val_rec_d=0.5070 val_rec_u=0.6088 val_rec_min=0.5070 val_gap=0.1018 val_p=0.001667\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 192/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 193/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5086 val_f1=0.5074 val_mcc=0.0173 val_prec_d=0.4844 val_prec_u=0.5331 val_rec_d=0.4336 val_rec_u=0.5836 val_rec_min=0.4336 val_gap=0.1500 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 194/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5771 val_bal_acc=0.5800 val_f1=0.5768 val_mcc=0.1607 val_prec_d=0.5465 val_prec_u=0.6148 val_rec_d=0.6364 val_rec_u=0.5237 val_rec_min=0.5237 val_gap=0.1127 val_p=0.000087\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 195/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 196/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5224 val_bal_acc=0.5216 val_f1=0.5216 val_mcc=0.0432 val_prec_d=0.4966 val_prec_u=0.5466 val_rec_d=0.5070 val_rec_u=0.5363 val_rec_min=0.5070 val_gap=0.0293 val_p=0.144841\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 197/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5522 val_bal_acc=0.5514 val_f1=0.5513 val_mcc=0.1027 val_prec_d=0.5276 val_prec_u=0.5751 val_rec_d=0.5350 val_rec_u=0.5678 val_rec_min=0.5350 val_gap=0.0329 val_p=0.005757\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 198/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 199/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 200/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 201/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 202/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 203/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 204/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 205/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 206/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5048 val_f1=0.4972 val_mcc=0.0101 val_prec_d=0.4811 val_prec_u=0.5294 val_rec_d=0.3566 val_rec_u=0.6530 val_rec_min=0.3566 val_gap=0.2964 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 207/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5091 val_bal_acc=0.4945 val_f1=0.4569 val_mcc=-0.0134 val_prec_d=0.4615 val_prec_u=0.5222 val_rec_d=0.2098 val_rec_u=0.7792 val_rec_min=0.2098 val_gap=0.5694 val_p=0.341936\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 208/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4959 val_bal_acc=0.5048 val_f1=0.4846 val_mcc=0.0102 val_prec_d=0.4778 val_prec_u=0.5330 val_rec_d=0.6783 val_rec_u=0.3312 val_rec_min=0.3312 val_gap=0.3471 val_p=0.596503\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 209/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 210/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 211/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4925 val_bal_acc=0.4977 val_f1=0.4897 val_mcc=-0.0047 val_prec_d=0.4724 val_prec_u=0.5228 val_rec_d=0.5979 val_rec_u=0.3975 val_rec_min=0.3975 val_gap=0.2004 val_p=0.658064\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 212/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5340 val_bal_acc=0.5311 val_f1=0.5308 val_mcc=0.0626 val_prec_d=0.5094 val_prec_u=0.5536 val_rec_d=0.4755 val_rec_u=0.5868 val_rec_min=0.4755 val_gap=0.1112 val_p=0.051625\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 213/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 214/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 215/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5158 val_bal_acc=0.5051 val_f1=0.4877 val_mcc=0.0111 val_prec_d=0.4830 val_prec_u=0.5293 val_rec_d=0.2972 val_rec_u=0.7129 val_rec_min=0.2972 val_gap=0.4157 val_p=0.231789\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 216/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5333 val_f1=0.5187 val_mcc=0.0697 val_prec_d=0.5000 val_prec_u=0.5728 val_rec_d=0.6818 val_rec_u=0.3849 val_rec_min=0.3849 val_gap=0.2970 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 217/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5324 val_f1=0.5283 val_mcc=0.0652 val_prec_d=0.5029 val_prec_u=0.5627 val_rec_d=0.5979 val_rec_u=0.4669 val_rec_min=0.4669 val_gap=0.1310 val_p=0.083063\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 218/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5579 val_f1=0.5577 val_mcc=0.1164 val_prec_d=0.5390 val_prec_u=0.5778 val_rec_d=0.5070 val_rec_u=0.6088 val_rec_min=0.5070 val_gap=0.1018 val_p=0.001667\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 219/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 220/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5086 val_f1=0.5074 val_mcc=0.0173 val_prec_d=0.4844 val_prec_u=0.5331 val_rec_d=0.4336 val_rec_u=0.5836 val_rec_min=0.4336 val_gap=0.1500 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 221/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5688 val_bal_acc=0.5713 val_f1=0.5687 val_mcc=0.1429 val_prec_d=0.5396 val_prec_u=0.6036 val_rec_d=0.6189 val_rec_u=0.5237 val_rec_min=0.5237 val_gap=0.0952 val_p=0.000413\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 222/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 223/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5041 val_bal_acc=0.5045 val_f1=0.5039 val_mcc=0.0089 val_prec_d=0.4787 val_prec_u=0.5302 val_rec_d=0.5105 val_rec_u=0.4984 val_rec_min=0.4984 val_gap=0.0121 val_p=0.435310\n",
      "[best-now] model=xgb birth=2009-01-03 gw=151 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 75, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5589 val_bal_acc=0.5591 val_f1=0.5586 val_mcc=0.1180 val_prec_d=0.5331 val_prec_u=0.5847 val_rec_d=0.5629 val_rec_u=0.5552 val_rec_min=0.5552 val_gap=0.0077 val_p=0.002162\n",
      "[sweep-run] 224/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 225/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 226/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 227/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 228/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 229/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 230/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 231/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 232/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 233/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5048 val_f1=0.4972 val_mcc=0.0101 val_prec_d=0.4811 val_prec_u=0.5294 val_rec_d=0.3566 val_rec_u=0.6530 val_rec_min=0.3566 val_gap=0.2964 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 234/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5091 val_bal_acc=0.4945 val_f1=0.4569 val_mcc=-0.0134 val_prec_d=0.4615 val_prec_u=0.5222 val_rec_d=0.2098 val_rec_u=0.7792 val_rec_min=0.2098 val_gap=0.5694 val_p=0.341936\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 235/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4959 val_bal_acc=0.5048 val_f1=0.4846 val_mcc=0.0102 val_prec_d=0.4778 val_prec_u=0.5330 val_rec_d=0.6783 val_rec_u=0.3312 val_rec_min=0.3312 val_gap=0.3471 val_p=0.596503\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 236/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 237/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 238/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4925 val_bal_acc=0.4977 val_f1=0.4897 val_mcc=-0.0047 val_prec_d=0.4724 val_prec_u=0.5228 val_rec_d=0.5979 val_rec_u=0.3975 val_rec_min=0.3975 val_gap=0.2004 val_p=0.658064\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 239/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5340 val_bal_acc=0.5311 val_f1=0.5308 val_mcc=0.0626 val_prec_d=0.5094 val_prec_u=0.5536 val_rec_d=0.4755 val_rec_u=0.5868 val_rec_min=0.4755 val_gap=0.1112 val_p=0.051625\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 240/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 241/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 242/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5158 val_bal_acc=0.5051 val_f1=0.4877 val_mcc=0.0111 val_prec_d=0.4830 val_prec_u=0.5293 val_rec_d=0.2972 val_rec_u=0.7129 val_rec_min=0.2972 val_gap=0.4157 val_p=0.231789\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 243/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5333 val_f1=0.5187 val_mcc=0.0697 val_prec_d=0.5000 val_prec_u=0.5728 val_rec_d=0.6818 val_rec_u=0.3849 val_rec_min=0.3849 val_gap=0.2970 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 244/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5290 val_bal_acc=0.5324 val_f1=0.5283 val_mcc=0.0652 val_prec_d=0.5029 val_prec_u=0.5627 val_rec_d=0.5979 val_rec_u=0.4669 val_rec_min=0.4669 val_gap=0.1310 val_p=0.083063\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 245/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5579 val_f1=0.5577 val_mcc=0.1164 val_prec_d=0.5390 val_prec_u=0.5778 val_rec_d=0.5070 val_rec_u=0.6088 val_rec_min=0.5070 val_gap=0.1018 val_p=0.001667\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 246/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 247/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5086 val_f1=0.5074 val_mcc=0.0173 val_prec_d=0.4844 val_prec_u=0.5331 val_rec_d=0.4336 val_rec_u=0.5836 val_rec_min=0.4336 val_gap=0.1500 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 248/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5688 val_bal_acc=0.5713 val_f1=0.5687 val_mcc=0.1429 val_prec_d=0.5396 val_prec_u=0.6036 val_rec_d=0.6189 val_rec_u=0.5237 val_rec_min=0.5237 val_gap=0.0952 val_p=0.000413\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 249/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 250/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.5041 val_bal_acc=0.5045 val_f1=0.5039 val_mcc=0.0089 val_prec_d=0.4787 val_prec_u=0.5302 val_rec_d=0.5105 val_rec_u=0.4984 val_rec_min=0.4984 val_gap=0.0121 val_p=0.435310\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 251/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 252/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4577 val_bal_acc=0.4791 val_f1=0.3596 val_mcc=-0.0757 val_prec_d=0.4629 val_prec_u=0.4000 val_rec_d=0.8951 val_rec_u=0.0631 val_rec_min=0.0631 val_gap=0.8320 val_p=0.982939\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 253/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 254/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4677 val_bal_acc=0.4769 val_f1=0.4544 val_mcc=-0.0494 val_prec_d=0.4574 val_prec_u=0.4896 val_rec_d=0.6573 val_rec_u=0.2965 val_rec_min=0.2965 val_gap=0.3608 val_p=0.948375\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 255/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5000 val_f1=0.3446 val_mcc=0.0000 val_prec_d=0.0000 val_prec_u=0.5257 val_rec_d=0.0000 val_rec_u=1.0000 val_rec_min=0.0000 val_gap=1.0000 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 256/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4842 val_bal_acc=0.4748 val_f1=0.4607 val_mcc=-0.0542 val_prec_d=0.4346 val_prec_u=0.5073 val_rec_d=0.2902 val_rec_u=0.6593 val_rec_min=0.2902 val_gap=0.3691 val_p=0.792299\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 257/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5158 val_f1=0.4630 val_mcc=0.0389 val_prec_d=0.4843 val_prec_u=0.5635 val_rec_d=0.8077 val_rec_u=0.2240 val_rec_min=0.2240 val_gap=0.5837 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 258/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5274 val_bal_acc=0.5144 val_f1=0.4876 val_mcc=0.0333 val_prec_d=0.5034 val_prec_u=0.5352 val_rec_d=0.2622 val_rec_u=0.7666 val_rec_min=0.2622 val_gap=0.5043 val_p=0.096242\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 259/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4726 val_bal_acc=0.4644 val_f1=0.4541 val_mcc=-0.0750 val_prec_d=0.4223 val_prec_u=0.4987 val_rec_d=0.3042 val_rec_u=0.6246 val_rec_min=0.3042 val_gap=0.3204 val_p=0.916937\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 260/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5124 val_bal_acc=0.5048 val_f1=0.4972 val_mcc=0.0101 val_prec_d=0.4811 val_prec_u=0.5294 val_rec_d=0.3566 val_rec_u=0.6530 val_rec_min=0.3566 val_gap=0.2964 val_p=0.284315\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 261/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 4, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5091 val_bal_acc=0.4945 val_f1=0.4569 val_mcc=-0.0134 val_prec_d=0.4615 val_prec_u=0.5222 val_rec_d=0.2098 val_rec_u=0.7792 val_rec_min=0.2098 val_gap=0.5694 val_p=0.341936\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 262/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4959 val_bal_acc=0.5048 val_f1=0.4846 val_mcc=0.0102 val_prec_d=0.4778 val_prec_u=0.5330 val_rec_d=0.6783 val_rec_u=0.3312 val_rec_min=0.3312 val_gap=0.3471 val_p=0.596503\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 263/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.4660 val_bal_acc=0.4701 val_f1=0.4644 val_mcc=-0.0606 val_prec_d=0.4486 val_prec_u=0.4901 val_rec_d=0.5490 val_rec_u=0.3912 val_rec_min=0.3912 val_gap=0.1578 val_p=0.956444\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 264/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.7, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.4992 val_bal_acc=0.5016 val_f1=0.4989 val_mcc=0.0032 val_prec_d=0.4758 val_prec_u=0.5275 val_rec_d=0.5490 val_rec_u=0.4543 val_rec_min=0.4543 val_gap=0.0947 val_p=0.532452\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 265/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4925 val_bal_acc=0.4977 val_f1=0.4897 val_mcc=-0.0047 val_prec_d=0.4724 val_prec_u=0.5228 val_rec_d=0.5979 val_rec_u=0.3975 val_rec_min=0.3975 val_gap=0.2004 val_p=0.658064\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 266/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5340 val_bal_acc=0.5311 val_f1=0.5308 val_mcc=0.0626 val_prec_d=0.5094 val_prec_u=0.5536 val_rec_d=0.4755 val_rec_u=0.5868 val_rec_min=0.4755 val_gap=0.1112 val_p=0.051625\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 267/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.8, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5008 val_bal_acc=0.5160 val_f1=0.4620 val_mcc=0.0395 val_prec_d=0.4843 val_prec_u=0.5645 val_rec_d=0.8112 val_rec_u=0.2208 val_rec_min=0.2208 val_gap=0.5904 val_p=0.500000\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 268/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.7, \"weight_power\": 1.0}\n",
      "   val_acc=0.4809 val_bal_acc=0.4873 val_f1=0.4757 val_mcc=-0.0261 val_prec_d=0.4642 val_prec_u=0.5088 val_rec_d=0.6119 val_rec_u=0.3628 val_rec_min=0.3628 val_gap=0.2491 val_p=0.835802\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 269/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5158 val_bal_acc=0.5051 val_f1=0.4877 val_mcc=0.0111 val_prec_d=0.4830 val_prec_u=0.5293 val_rec_d=0.2972 val_rec_u=0.7129 val_rec_min=0.2972 val_gap=0.4157 val_p=0.231789\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "[sweep-run] 270/270 model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 6, \"n_estimators\": 150, \"sideways_penalty\": 1.0, \"subsample\": 0.9, \"weight_power\": 1.0}\n",
      "   val_acc=0.5257 val_bal_acc=0.5333 val_f1=0.5187 val_mcc=0.0697 val_prec_d=0.5000 val_prec_u=0.5728 val_rec_d=0.6818 val_rec_u=0.3849 val_rec_min=0.3849 val_gap=0.2970 val_p=0.110896\n",
      "[best-now] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "Top configs by VALIDATION (selection stage, no test used):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>birth_dt_utc</th>\n",
       "      <th>gauss_window</th>\n",
       "      <th>gauss_std</th>\n",
       "      <th>model_params_json</th>\n",
       "      <th>val_threshold</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_balanced_accuracy</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_precision_down</th>\n",
       "      <th>val_precision_up</th>\n",
       "      <th>val_recall_down</th>\n",
       "      <th>val_recall_up</th>\n",
       "      <th>val_recall_min</th>\n",
       "      <th>val_recall_gap</th>\n",
       "      <th>val_p_value_vs_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.560531</td>\n",
       "      <td>0.560477</td>\n",
       "      <td>0.560139</td>\n",
       "      <td>0.120799</td>\n",
       "      <td>0.535117</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.561514</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.560531</td>\n",
       "      <td>0.560477</td>\n",
       "      <td>0.560139</td>\n",
       "      <td>0.120799</td>\n",
       "      <td>0.535117</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.561514</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.558872</td>\n",
       "      <td>0.559071</td>\n",
       "      <td>0.558599</td>\n",
       "      <td>0.117986</td>\n",
       "      <td>0.533113</td>\n",
       "      <td>0.584718</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>0.002162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.562189</td>\n",
       "      <td>0.562568</td>\n",
       "      <td>0.561985</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.536184</td>\n",
       "      <td>0.588629</td>\n",
       "      <td>0.569930</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.562189</td>\n",
       "      <td>0.562568</td>\n",
       "      <td>0.561985</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.536184</td>\n",
       "      <td>0.588629</td>\n",
       "      <td>0.569930</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>0.001277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.558872</td>\n",
       "      <td>0.559242</td>\n",
       "      <td>0.558667</td>\n",
       "      <td>0.118331</td>\n",
       "      <td>0.532895</td>\n",
       "      <td>0.585284</td>\n",
       "      <td>0.566434</td>\n",
       "      <td>0.552050</td>\n",
       "      <td>0.552050</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>0.002162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.551394</td>\n",
       "      <td>0.551339</td>\n",
       "      <td>0.102727</td>\n",
       "      <td>0.527586</td>\n",
       "      <td>0.575080</td>\n",
       "      <td>0.534965</td>\n",
       "      <td>0.567823</td>\n",
       "      <td>0.534965</td>\n",
       "      <td>0.032858</td>\n",
       "      <td>0.005757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.575456</td>\n",
       "      <td>0.577750</td>\n",
       "      <td>0.575361</td>\n",
       "      <td>0.155810</td>\n",
       "      <td>0.546012</td>\n",
       "      <td>0.610108</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>0.533123</td>\n",
       "      <td>0.533123</td>\n",
       "      <td>0.089255</td>\n",
       "      <td>0.000121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.536686</td>\n",
       "      <td>0.536579</td>\n",
       "      <td>0.073304</td>\n",
       "      <td>0.511945</td>\n",
       "      <td>0.561290</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.548896</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.024420</td>\n",
       "      <td>0.036537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.536686</td>\n",
       "      <td>0.536579</td>\n",
       "      <td>0.073304</td>\n",
       "      <td>0.511945</td>\n",
       "      <td>0.561290</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.548896</td>\n",
       "      <td>0.524476</td>\n",
       "      <td>0.024420</td>\n",
       "      <td>0.036537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.543298</td>\n",
       "      <td>0.542257</td>\n",
       "      <td>0.086534</td>\n",
       "      <td>0.516026</td>\n",
       "      <td>0.570447</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>0.020823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.568823</td>\n",
       "      <td>0.571270</td>\n",
       "      <td>0.568679</td>\n",
       "      <td>0.142905</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.603636</td>\n",
       "      <td>0.618881</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.095222</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.568823</td>\n",
       "      <td>0.571270</td>\n",
       "      <td>0.568679</td>\n",
       "      <td>0.142905</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.603636</td>\n",
       "      <td>0.618881</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.095222</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.577114</td>\n",
       "      <td>0.580011</td>\n",
       "      <td>0.576816</td>\n",
       "      <td>0.160691</td>\n",
       "      <td>0.546547</td>\n",
       "      <td>0.614815</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.523659</td>\n",
       "      <td>0.112704</td>\n",
       "      <td>0.000087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.524046</td>\n",
       "      <td>0.523896</td>\n",
       "      <td>0.523622</td>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.498328</td>\n",
       "      <td>0.549342</td>\n",
       "      <td>0.520979</td>\n",
       "      <td>0.526814</td>\n",
       "      <td>0.520979</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.127082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.524046</td>\n",
       "      <td>0.523896</td>\n",
       "      <td>0.523622</td>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.498328</td>\n",
       "      <td>0.549342</td>\n",
       "      <td>0.520979</td>\n",
       "      <td>0.526814</td>\n",
       "      <td>0.520979</td>\n",
       "      <td>0.005835</td>\n",
       "      <td>0.127082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.541247</td>\n",
       "      <td>0.541227</td>\n",
       "      <td>0.082467</td>\n",
       "      <td>0.517361</td>\n",
       "      <td>0.565079</td>\n",
       "      <td>0.520979</td>\n",
       "      <td>0.561514</td>\n",
       "      <td>0.520979</td>\n",
       "      <td>0.040535</td>\n",
       "      <td>0.020823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.524046</td>\n",
       "      <td>0.523725</td>\n",
       "      <td>0.523522</td>\n",
       "      <td>0.047394</td>\n",
       "      <td>0.498316</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>0.517483</td>\n",
       "      <td>0.529968</td>\n",
       "      <td>0.517483</td>\n",
       "      <td>0.012486</td>\n",
       "      <td>0.127082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.553897</td>\n",
       "      <td>0.552117</td>\n",
       "      <td>0.552119</td>\n",
       "      <td>0.104387</td>\n",
       "      <td>0.530466</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.517483</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>0.517483</td>\n",
       "      <td>0.069268</td>\n",
       "      <td>0.004549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.537313</td>\n",
       "      <td>0.538395</td>\n",
       "      <td>0.537293</td>\n",
       "      <td>0.076745</td>\n",
       "      <td>0.511182</td>\n",
       "      <td>0.565517</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.517350</td>\n",
       "      <td>0.517350</td>\n",
       "      <td>0.042090</td>\n",
       "      <td>0.036537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.522388</td>\n",
       "      <td>0.521635</td>\n",
       "      <td>0.521566</td>\n",
       "      <td>0.043235</td>\n",
       "      <td>0.496575</td>\n",
       "      <td>0.546624</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.536278</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.029285</td>\n",
       "      <td>0.144841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.560531</td>\n",
       "      <td>0.557913</td>\n",
       "      <td>0.557728</td>\n",
       "      <td>0.116351</td>\n",
       "      <td>0.539033</td>\n",
       "      <td>0.577844</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.608833</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.101840</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.560531</td>\n",
       "      <td>0.557913</td>\n",
       "      <td>0.557728</td>\n",
       "      <td>0.116351</td>\n",
       "      <td>0.539033</td>\n",
       "      <td>0.577844</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.608833</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.101840</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.560531</td>\n",
       "      <td>0.557913</td>\n",
       "      <td>0.557728</td>\n",
       "      <td>0.116351</td>\n",
       "      <td>0.539033</td>\n",
       "      <td>0.577844</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.608833</td>\n",
       "      <td>0.506993</td>\n",
       "      <td>0.101840</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.530680</td>\n",
       "      <td>0.532086</td>\n",
       "      <td>0.530680</td>\n",
       "      <td>0.064172</td>\n",
       "      <td>0.504732</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.504732</td>\n",
       "      <td>0.504732</td>\n",
       "      <td>0.054709</td>\n",
       "      <td>0.071288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.540392</td>\n",
       "      <td>0.540366</td>\n",
       "      <td>0.080923</td>\n",
       "      <td>0.517986</td>\n",
       "      <td>0.563077</td>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.577287</td>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.073791</td>\n",
       "      <td>0.020823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.542289</td>\n",
       "      <td>0.540392</td>\n",
       "      <td>0.540366</td>\n",
       "      <td>0.080923</td>\n",
       "      <td>0.517986</td>\n",
       "      <td>0.563077</td>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.577287</td>\n",
       "      <td>0.503497</td>\n",
       "      <td>0.073791</td>\n",
       "      <td>0.020823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.504146</td>\n",
       "      <td>0.504456</td>\n",
       "      <td>0.503949</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>0.478689</td>\n",
       "      <td>0.530201</td>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>0.012067</td>\n",
       "      <td>0.435310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.504146</td>\n",
       "      <td>0.504456</td>\n",
       "      <td>0.503949</td>\n",
       "      <td>0.008901</td>\n",
       "      <td>0.478689</td>\n",
       "      <td>0.530201</td>\n",
       "      <td>0.510490</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>0.498423</td>\n",
       "      <td>0.012067</td>\n",
       "      <td>0.435310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.529022</td>\n",
       "      <td>0.531022</td>\n",
       "      <td>0.528958</td>\n",
       "      <td>0.062135</td>\n",
       "      <td>0.503086</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.569930</td>\n",
       "      <td>0.492114</td>\n",
       "      <td>0.492114</td>\n",
       "      <td>0.077817</td>\n",
       "      <td>0.083063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.529022</td>\n",
       "      <td>0.531022</td>\n",
       "      <td>0.528958</td>\n",
       "      <td>0.062135</td>\n",
       "      <td>0.503086</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.569930</td>\n",
       "      <td>0.492114</td>\n",
       "      <td>0.492114</td>\n",
       "      <td>0.077817</td>\n",
       "      <td>0.083063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.531138</td>\n",
       "      <td>0.530770</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>0.509363</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.111226</td>\n",
       "      <td>0.051625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.531138</td>\n",
       "      <td>0.530770</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>0.509363</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.111226</td>\n",
       "      <td>0.051625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.531138</td>\n",
       "      <td>0.530770</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>0.509363</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.111226</td>\n",
       "      <td>0.051625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.531138</td>\n",
       "      <td>0.530770</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>0.509363</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.111226</td>\n",
       "      <td>0.051625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.531138</td>\n",
       "      <td>0.530770</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>0.509363</td>\n",
       "      <td>0.553571</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.586751</td>\n",
       "      <td>0.475524</td>\n",
       "      <td>0.111226</td>\n",
       "      <td>0.051625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.529022</td>\n",
       "      <td>0.532390</td>\n",
       "      <td>0.528335</td>\n",
       "      <td>0.065227</td>\n",
       "      <td>0.502941</td>\n",
       "      <td>0.562738</td>\n",
       "      <td>0.597902</td>\n",
       "      <td>0.466877</td>\n",
       "      <td>0.466877</td>\n",
       "      <td>0.131025</td>\n",
       "      <td>0.083063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.529022</td>\n",
       "      <td>0.532390</td>\n",
       "      <td>0.528335</td>\n",
       "      <td>0.065227</td>\n",
       "      <td>0.502941</td>\n",
       "      <td>0.562738</td>\n",
       "      <td>0.597902</td>\n",
       "      <td>0.466877</td>\n",
       "      <td>0.466877</td>\n",
       "      <td>0.131025</td>\n",
       "      <td>0.083063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.529022</td>\n",
       "      <td>0.532390</td>\n",
       "      <td>0.528335</td>\n",
       "      <td>0.065227</td>\n",
       "      <td>0.502941</td>\n",
       "      <td>0.562738</td>\n",
       "      <td>0.597902</td>\n",
       "      <td>0.466877</td>\n",
       "      <td>0.466877</td>\n",
       "      <td>0.131025</td>\n",
       "      <td>0.083063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.538147</td>\n",
       "      <td>0.532681</td>\n",
       "      <td>0.077157</td>\n",
       "      <td>0.507163</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>0.618881</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.161468</td>\n",
       "      <td>0.051625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.538147</td>\n",
       "      <td>0.532681</td>\n",
       "      <td>0.077157</td>\n",
       "      <td>0.507163</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>0.618881</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.161468</td>\n",
       "      <td>0.051625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.533997</td>\n",
       "      <td>0.538147</td>\n",
       "      <td>0.532681</td>\n",
       "      <td>0.077157</td>\n",
       "      <td>0.507163</td>\n",
       "      <td>0.570866</td>\n",
       "      <td>0.618881</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.457413</td>\n",
       "      <td>0.161468</td>\n",
       "      <td>0.051625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.499171</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.498938</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.532452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.499171</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.498938</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.532452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.499171</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.498938</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.532452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.499171</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.498938</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.532452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.499171</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.498938</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.532452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.499171</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.498938</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.532452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.499171</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.498938</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.532452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.499171</td>\n",
       "      <td>0.501605</td>\n",
       "      <td>0.498938</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.475758</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.548951</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.454259</td>\n",
       "      <td>0.094692</td>\n",
       "      <td>0.532452</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model  birth_date          birth_dt_utc  gauss_window  gauss_std                                  model_params_json  val_threshold  val_accuracy  val_balanced_accuracy  \\\n",
       "0    xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.47      0.560531               0.560477   \n",
       "1    xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.47      0.560531               0.560477   \n",
       "2    xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.47      0.558872               0.559071   \n",
       "3    xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.47      0.562189               0.562568   \n",
       "4    xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.47      0.562189               0.562568   \n",
       "5    xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.48      0.558872               0.559242   \n",
       "6    xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.47      0.552239               0.551394   \n",
       "7    xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.48      0.575456               0.577750   \n",
       "8    xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.47      0.537313               0.536686   \n",
       "9    xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.47      0.537313               0.536686   \n",
       "10   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.48      0.542289               0.543298   \n",
       "11   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.48      0.568823               0.571270   \n",
       "12   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.48      0.568823               0.571270   \n",
       "13   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.48      0.577114               0.580011   \n",
       "14   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.48      0.524046               0.523896   \n",
       "15   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.48      0.524046               0.523896   \n",
       "16   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.48      0.542289               0.541247   \n",
       "17   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.48      0.524046               0.523725   \n",
       "18   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.47      0.553897               0.552117   \n",
       "19   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.48      0.537313               0.538395   \n",
       "20   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.48      0.522388               0.521635   \n",
       "21   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.47      0.560531               0.557913   \n",
       "22   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.47      0.560531               0.557913   \n",
       "23   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.47      0.560531               0.557913   \n",
       "24   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.48      0.530680               0.532086   \n",
       "25   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.47      0.542289               0.540392   \n",
       "26   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.47      0.542289               0.540392   \n",
       "27   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.48      0.504146               0.504456   \n",
       "28   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.48      0.504146               0.504456   \n",
       "29   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.48      0.529022               0.531022   \n",
       "30   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.48      0.529022               0.531022   \n",
       "31   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.49      0.533997               0.531138   \n",
       "32   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.49      0.533997               0.531138   \n",
       "33   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.49      0.533997               0.531138   \n",
       "34   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.49      0.533997               0.531138   \n",
       "35   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...           0.49      0.533997               0.531138   \n",
       "36   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.49      0.529022               0.532390   \n",
       "37   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.49      0.529022               0.532390   \n",
       "38   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.49      0.529022               0.532390   \n",
       "39   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.49      0.533997               0.538147   \n",
       "40   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.49      0.533997               0.538147   \n",
       "41   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.49      0.533997               0.538147   \n",
       "42   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.50      0.499171               0.501605   \n",
       "43   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.50      0.499171               0.501605   \n",
       "44   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.50      0.499171               0.501605   \n",
       "45   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.50      0.499171               0.501605   \n",
       "46   xgb  2009-01-03  2009-01-03T18:15:05Z           151       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.50      0.499171               0.501605   \n",
       "47   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.50      0.499171               0.501605   \n",
       "48   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.50      0.499171               0.501605   \n",
       "49   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...           0.50      0.499171               0.501605   \n",
       "\n",
       "    val_f1_macro   val_mcc  val_precision_down  val_precision_up  val_recall_down  val_recall_up  val_recall_min  val_recall_gap  val_p_value_vs_random  \n",
       "0       0.560139  0.120799            0.535117          0.585526         0.559441       0.561514        0.559441        0.002074               0.001667  \n",
       "1       0.560139  0.120799            0.535117          0.585526         0.559441       0.561514        0.559441        0.002074               0.001667  \n",
       "2       0.558599  0.117986            0.533113          0.584718         0.562937       0.555205        0.555205        0.007732               0.002162  \n",
       "3       0.561985  0.124974            0.536184          0.588629         0.569930       0.555205        0.555205        0.014725               0.001277  \n",
       "4       0.561985  0.124974            0.536184          0.588629         0.569930       0.555205        0.555205        0.014725               0.001277  \n",
       "5       0.558667  0.118331            0.532895          0.585284         0.566434       0.552050        0.552050        0.014383               0.002162  \n",
       "6       0.551339  0.102727            0.527586          0.575080         0.534965       0.567823        0.534965        0.032858               0.005757  \n",
       "7       0.575361  0.155810            0.546012          0.610108         0.622378       0.533123        0.533123        0.089255               0.000121  \n",
       "8       0.536579  0.073304            0.511945          0.561290         0.524476       0.548896        0.524476        0.024420               0.036537  \n",
       "9       0.536579  0.073304            0.511945          0.561290         0.524476       0.548896        0.524476        0.024420               0.036537  \n",
       "10      0.542257  0.086534            0.516026          0.570447         0.562937       0.523659        0.523659        0.039278               0.020823  \n",
       "11      0.568679  0.142905            0.539634          0.603636         0.618881       0.523659        0.523659        0.095222               0.000413  \n",
       "12      0.568679  0.142905            0.539634          0.603636         0.618881       0.523659        0.523659        0.095222               0.000413  \n",
       "13      0.576816  0.160691            0.546547          0.614815         0.636364       0.523659        0.523659        0.112704               0.000087  \n",
       "14      0.523622  0.047731            0.498328          0.549342         0.520979       0.526814        0.520979        0.005835               0.127082  \n",
       "15      0.523622  0.047731            0.498328          0.549342         0.520979       0.526814        0.520979        0.005835               0.127082  \n",
       "16      0.541227  0.082467            0.517361          0.565079         0.520979       0.561514        0.520979        0.040535               0.020823  \n",
       "17      0.523522  0.047394            0.498316          0.549020         0.517483       0.529968        0.517483        0.012486               0.127082  \n",
       "18      0.552119  0.104387            0.530466          0.574074         0.517483       0.586751        0.517483        0.069268               0.004549  \n",
       "19      0.537293  0.076745            0.511182          0.565517         0.559441       0.517350        0.517350        0.042090               0.036537  \n",
       "20      0.521566  0.043235            0.496575          0.546624         0.506993       0.536278        0.506993        0.029285               0.144841  \n",
       "21      0.557728  0.116351            0.539033          0.577844         0.506993       0.608833        0.506993        0.101840               0.001667  \n",
       "22      0.557728  0.116351            0.539033          0.577844         0.506993       0.608833        0.506993        0.101840               0.001667  \n",
       "23      0.557728  0.116351            0.539033          0.577844         0.506993       0.608833        0.506993        0.101840               0.001667  \n",
       "24      0.530680  0.064172            0.504732          0.559441         0.559441       0.504732        0.504732        0.054709               0.071288  \n",
       "25      0.540366  0.080923            0.517986          0.563077         0.503497       0.577287        0.503497        0.073791               0.020823  \n",
       "26      0.540366  0.080923            0.517986          0.563077         0.503497       0.577287        0.503497        0.073791               0.020823  \n",
       "27      0.503949  0.008901            0.478689          0.530201         0.510490       0.498423        0.498423        0.012067               0.435310  \n",
       "28      0.503949  0.008901            0.478689          0.530201         0.510490       0.498423        0.498423        0.012067               0.435310  \n",
       "29      0.528958  0.062135            0.503086          0.559140         0.569930       0.492114        0.492114        0.077817               0.083063  \n",
       "30      0.528958  0.062135            0.503086          0.559140         0.569930       0.492114        0.492114        0.077817               0.083063  \n",
       "31      0.530770  0.062604            0.509363          0.553571         0.475524       0.586751        0.475524        0.111226               0.051625  \n",
       "32      0.530770  0.062604            0.509363          0.553571         0.475524       0.586751        0.475524        0.111226               0.051625  \n",
       "33      0.530770  0.062604            0.509363          0.553571         0.475524       0.586751        0.475524        0.111226               0.051625  \n",
       "34      0.530770  0.062604            0.509363          0.553571         0.475524       0.586751        0.475524        0.111226               0.051625  \n",
       "35      0.530770  0.062604            0.509363          0.553571         0.475524       0.586751        0.475524        0.111226               0.051625  \n",
       "36      0.528335  0.065227            0.502941          0.562738         0.597902       0.466877        0.466877        0.131025               0.083063  \n",
       "37      0.528335  0.065227            0.502941          0.562738         0.597902       0.466877        0.466877        0.131025               0.083063  \n",
       "38      0.528335  0.065227            0.502941          0.562738         0.597902       0.466877        0.466877        0.131025               0.083063  \n",
       "39      0.532681  0.077157            0.507163          0.570866         0.618881       0.457413        0.457413        0.161468               0.051625  \n",
       "40      0.532681  0.077157            0.507163          0.570866         0.618881       0.457413        0.457413        0.161468               0.051625  \n",
       "41      0.532681  0.077157            0.507163          0.570866         0.618881       0.457413        0.457413        0.161468               0.051625  \n",
       "42      0.498938  0.003220            0.475758          0.527473         0.548951       0.454259        0.454259        0.094692               0.532452  \n",
       "43      0.498938  0.003220            0.475758          0.527473         0.548951       0.454259        0.454259        0.094692               0.532452  \n",
       "44      0.498938  0.003220            0.475758          0.527473         0.548951       0.454259        0.454259        0.094692               0.532452  \n",
       "45      0.498938  0.003220            0.475758          0.527473         0.548951       0.454259        0.454259        0.094692               0.532452  \n",
       "46      0.498938  0.003220            0.475758          0.527473         0.548951       0.454259        0.454259        0.094692               0.532452  \n",
       "47      0.498938  0.003220            0.475758          0.527473         0.548951       0.454259        0.454259        0.094692               0.532452  \n",
       "48      0.498938  0.003220            0.475758          0.527473         0.548951       0.454259        0.454259        0.094692               0.532452  \n",
       "49      0.498938  0.003220            0.475758          0.527473         0.548951       0.454259        0.454259        0.094692               0.532452  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected best config per model (based on validation only):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>birth_dt_utc</th>\n",
       "      <th>gauss_window</th>\n",
       "      <th>gauss_std</th>\n",
       "      <th>model_params_json</th>\n",
       "      <th>val_threshold</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_balanced_accuracy</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_precision_down</th>\n",
       "      <th>val_precision_up</th>\n",
       "      <th>val_recall_down</th>\n",
       "      <th>val_recall_up</th>\n",
       "      <th>val_recall_min</th>\n",
       "      <th>val_recall_gap</th>\n",
       "      <th>val_p_value_vs_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.560531</td>\n",
       "      <td>0.560477</td>\n",
       "      <td>0.560139</td>\n",
       "      <td>0.120799</td>\n",
       "      <td>0.535117</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.561514</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.001667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  birth_date          birth_dt_utc  gauss_window  gauss_std                                  model_params_json  val_threshold  val_accuracy  val_balanced_accuracy  \\\n",
       "0   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.47      0.560531               0.560477   \n",
       "\n",
       "   val_f1_macro   val_mcc  val_precision_down  val_precision_up  val_recall_down  val_recall_up  val_recall_min  val_recall_gap  val_p_value_vs_random  \n",
       "0      0.560139  0.120799            0.535117          0.585526         0.559441       0.561514        0.559441        0.002074               0.001667  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[final-test] model=xgb birth=2009-01-03 gw=201 std=30.0 params={\"colsample_bytree\": 0.9, \"early_stopping_rounds\": 75, \"learning_rate\": 0.01, \"max_depth\": 3, \"n_estimators\": 100, \"sideways_penalty\": 1.0, \"subsample\": 0.8, \"weight_power\": 1.0}\n",
      "   val_acc=0.5605 val_bal_acc=0.5605 val_f1=0.5601 val_mcc=0.1208 val_prec_d=0.5351 val_prec_u=0.5855 val_rec_d=0.5594 val_rec_u=0.5615 val_rec_min=0.5594 val_gap=0.0021 val_p=0.001667\n",
      "   test_acc=0.5232 test_bal_acc=0.5288 test_f1=0.5154 test_mcc=0.0601 test_prec_d=0.5594 test_prec_u=0.5034 test_rec_d=0.3817 test_rec_u=0.6759 test_rec_min=0.3817 test_gap=0.2942 test_p=0.086323\n",
      "Final model comparison (selection on val, evaluation on test):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>birth_dt_utc</th>\n",
       "      <th>gauss_window</th>\n",
       "      <th>gauss_std</th>\n",
       "      <th>model_params_json</th>\n",
       "      <th>val_threshold</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_balanced_accuracy</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_precision_down</th>\n",
       "      <th>val_precision_up</th>\n",
       "      <th>val_recall_down</th>\n",
       "      <th>val_recall_up</th>\n",
       "      <th>val_recall_min</th>\n",
       "      <th>val_recall_gap</th>\n",
       "      <th>val_p_value_vs_random</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_balanced_accuracy</th>\n",
       "      <th>test_f1_macro</th>\n",
       "      <th>test_mcc</th>\n",
       "      <th>test_precision_down</th>\n",
       "      <th>test_precision_up</th>\n",
       "      <th>test_recall_down</th>\n",
       "      <th>test_recall_up</th>\n",
       "      <th>test_recall_min</th>\n",
       "      <th>test_recall_gap</th>\n",
       "      <th>test_p_value_vs_random</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.560531</td>\n",
       "      <td>0.560477</td>\n",
       "      <td>0.560139</td>\n",
       "      <td>0.120799</td>\n",
       "      <td>0.535117</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.561514</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.52323</td>\n",
       "      <td>0.528763</td>\n",
       "      <td>0.515388</td>\n",
       "      <td>0.060105</td>\n",
       "      <td>0.559375</td>\n",
       "      <td>0.503425</td>\n",
       "      <td>0.381663</td>\n",
       "      <td>0.675862</td>\n",
       "      <td>0.381663</td>\n",
       "      <td>0.294199</td>\n",
       "      <td>0.086323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model  birth_date          birth_dt_utc  gauss_window  gauss_std                                  model_params_json  val_threshold  val_accuracy  val_balanced_accuracy  \\\n",
       "0   xgb  2009-01-03  2009-01-03T18:15:05Z           201       30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...           0.47      0.560531               0.560477   \n",
       "\n",
       "   val_f1_macro   val_mcc  val_precision_down  val_precision_up  val_recall_down  val_recall_up  val_recall_min  val_recall_gap  val_p_value_vs_random  test_accuracy  \\\n",
       "0      0.560139  0.120799            0.535117          0.585526         0.559441       0.561514        0.559441        0.002074               0.001667        0.52323   \n",
       "\n",
       "   test_balanced_accuracy  test_f1_macro  test_mcc  test_precision_down  test_precision_up  test_recall_down  test_recall_up  test_recall_min  test_recall_gap  \\\n",
       "0                0.528763       0.515388  0.060105             0.559375           0.503425          0.381663        0.675862         0.381663         0.294199   \n",
       "\n",
       "   test_p_value_vs_random  \n",
       "0                0.086323  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ------------------------------\n",
    "# Run classification benchmark / sweep\n",
    "# ------------------------------\n",
    "\n",
    "def _val_rank_key(row: dict) -> tuple:\n",
    "    \"\"\"Sorting key for validation-based model selection (lower is better).\"\"\"\n",
    "    return (\n",
    "        -float(row['val_recall_min']),\n",
    "        float(row['val_recall_gap']),\n",
    "        -float(row['val_mcc']),\n",
    "        -float(row['val_accuracy']),\n",
    "    )\n",
    "\n",
    "\n",
    "def _fmt_metrics(prefix: str, row: dict) -> str:\n",
    "    \"\"\"Compact but detailed metrics formatter.\"\"\"\n",
    "    return (\n",
    "        f\"{prefix}_acc={float(row[f'{prefix}_accuracy']):.4f} \"\n",
    "        f\"{prefix}_bal_acc={float(row[f'{prefix}_balanced_accuracy']):.4f} \"\n",
    "        f\"{prefix}_f1={float(row[f'{prefix}_f1_macro']):.4f} \"\n",
    "        f\"{prefix}_mcc={float(row[f'{prefix}_mcc']):.4f} \"\n",
    "        f\"{prefix}_prec_d={float(row[f'{prefix}_precision_down']):.4f} \"\n",
    "        f\"{prefix}_prec_u={float(row[f'{prefix}_precision_up']):.4f} \"\n",
    "        f\"{prefix}_rec_d={float(row[f'{prefix}_recall_down']):.4f} \"\n",
    "        f\"{prefix}_rec_u={float(row[f'{prefix}_recall_up']):.4f} \"\n",
    "        f\"{prefix}_rec_min={float(row[f'{prefix}_recall_min']):.4f} \"\n",
    "        f\"{prefix}_gap={float(row[f'{prefix}_recall_gap']):.4f} \"\n",
    "        f\"{prefix}_p={float(row[f'{prefix}_p_value_vs_random']):.6f}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _cfg_str(row: dict) -> str:\n",
    "    return (\n",
    "        f\"model={row['model']} birth={row.get('birth_date', 'na')} \"\n",
    "        f\"gw={int(row['gauss_window'])} std={float(row['gauss_std']):.1f} \"\n",
    "        f\"params={row['model_params_json']}\"\n",
    "    )\n",
    "\n",
    "\n",
    "if not ENABLE_GAUSS_HYPER_SWEEP:\n",
    "    preds = {}\n",
    "\n",
    "    if 'xgb' in MODEL_SET:\n",
    "        print('Training XGB...')\n",
    "        preds['xgb'] = train_predict_xgb(train_df, val_df, test_df, feature_cols, model_params=None)\n",
    "\n",
    "    if 'rf' in MODEL_SET:\n",
    "        print('Training RF...')\n",
    "        preds['rf'] = train_predict_rf(train_df, val_df, test_df, feature_cols, model_params=None)\n",
    "\n",
    "    rows = []\n",
    "    for name, df_pred in preds.items():\n",
    "        rows.append(eval_classification_with_val_threshold(df_pred, model_name=name, include_test=True))\n",
    "\n",
    "    df_cls = pd.DataFrame(rows).sort_values(VAL_SORT_COLS, ascending=VAL_SORT_ASC).reset_index(drop=True)\n",
    "    print('Classification comparison (threshold tuned on validation):')\n",
    "    display(df_cls[[\n",
    "        'model', 'val_threshold',\n",
    "        'val_accuracy', 'val_balanced_accuracy', 'val_f1_macro', 'val_mcc',\n",
    "        'val_precision_down', 'val_precision_up',\n",
    "        'val_recall_down', 'val_recall_up', 'val_recall_min', 'val_recall_gap', 'val_p_value_vs_random',\n",
    "        'test_accuracy', 'test_balanced_accuracy', 'test_f1_macro', 'test_mcc',\n",
    "        'test_precision_down', 'test_precision_up',\n",
    "        'test_recall_down', 'test_recall_up', 'test_recall_min', 'test_recall_gap', 'test_p_value_vs_random',\n",
    "    ]])\n",
    "\n",
    "    for row in df_cls.to_dict(orient='records'):\n",
    "        print('[single-run]', _cfg_str({\n",
    "            'model': row['model'],\n",
    "            'birth_date': str(BIRTH_DT_UTC)[:10],\n",
    "            'gauss_window': GAUSS_WINDOW,\n",
    "            'gauss_std': GAUSS_STD,\n",
    "            'model_params_json': '{}',\n",
    "        }))\n",
    "        print('  ', _fmt_metrics('val', row))\n",
    "        print('  ', _fmt_metrics('test', row))\n",
    "\n",
    "else:\n",
    "    model_param_sets = {}\n",
    "    if 'xgb' in MODEL_SET:\n",
    "        model_param_sets['xgb'] = _expand_param_grid(XGB_PARAM_GRID)\n",
    "    if 'rf' in MODEL_SET:\n",
    "        model_param_sets['rf'] = _expand_param_grid(RF_PARAM_GRID)\n",
    "\n",
    "    total_runs = len(BIRTH_DT_SWEEP_LIST) * len(GAUSS_WINDOWS) * len(GAUSS_STDS) * sum(len(v) for v in model_param_sets.values())\n",
    "    print('Sweep total runs (validation stage):', total_runs)\n",
    "\n",
    "    sweep_rows = []\n",
    "    done = 0\n",
    "    stop = False\n",
    "\n",
    "    best_global = None\n",
    "    best_global_key = None\n",
    "\n",
    "    for birth_dt_utc in BIRTH_DT_SWEEP_LIST:\n",
    "        if stop:\n",
    "            break\n",
    "        for gauss_window in GAUSS_WINDOWS:\n",
    "            if stop:\n",
    "                break\n",
    "            for gauss_std in GAUSS_STDS:\n",
    "                if stop:\n",
    "                    break\n",
    "\n",
    "                parts = build_dataset_parts_for_gauss(\n",
    "                    int(gauss_window),\n",
    "                    float(gauss_std),\n",
    "                    birth_dt_utc=birth_dt_utc,\n",
    "                    verbose=False,\n",
    "                )\n",
    "\n",
    "                for model_name, param_list in model_param_sets.items():\n",
    "                    if stop:\n",
    "                        break\n",
    "                    for params in param_list:\n",
    "                        row = run_one_eval(parts, model_name, params, include_test=False)\n",
    "                        sweep_rows.append(row)\n",
    "                        done += 1\n",
    "\n",
    "                        current_key = _val_rank_key(row)\n",
    "                        if best_global_key is None or current_key < best_global_key:\n",
    "                            best_global_key = current_key\n",
    "                            best_global = dict(row)\n",
    "\n",
    "                        print(f'[sweep-run] {done}/{total_runs} {_cfg_str(row)}')\n",
    "                        print('  ', _fmt_metrics('val', row))\n",
    "                        if best_global is not None:\n",
    "                            print(f\"[best-now] {_cfg_str(best_global)}\")\n",
    "                            print('  ', _fmt_metrics('val', best_global))\n",
    "\n",
    "                        if MAX_SWEEP_RUNS is not None and done >= int(MAX_SWEEP_RUNS):\n",
    "                            stop = True\n",
    "                            break\n",
    "\n",
    "    if not sweep_rows:\n",
    "        raise RuntimeError('Sweep produced no rows.')\n",
    "\n",
    "    df_sweep_val = pd.DataFrame(sweep_rows).sort_values(VAL_SORT_COLS, ascending=VAL_SORT_ASC).reset_index(drop=True)\n",
    "\n",
    "    print('Top configs by VALIDATION (selection stage, no test used):')\n",
    "    preview_cols = [\n",
    "        'model', 'birth_date', 'birth_dt_utc', 'gauss_window', 'gauss_std', 'model_params_json',\n",
    "        'val_threshold',\n",
    "        'val_accuracy', 'val_balanced_accuracy', 'val_f1_macro', 'val_mcc',\n",
    "        'val_precision_down', 'val_precision_up',\n",
    "        'val_recall_down', 'val_recall_up', 'val_recall_min', 'val_recall_gap', 'val_p_value_vs_random',\n",
    "    ]\n",
    "    display(df_sweep_val[preview_cols].head(50))\n",
    "\n",
    "    best_val_rows = []\n",
    "    for model_name in sorted(df_sweep_val['model'].unique()):\n",
    "        df_model = df_sweep_val[df_sweep_val['model'] == model_name].copy()\n",
    "        best_row = df_model.sort_values(VAL_SORT_COLS, ascending=VAL_SORT_ASC).iloc[0].to_dict()\n",
    "        best_val_rows.append(best_row)\n",
    "\n",
    "    df_best_val = pd.DataFrame(best_val_rows).sort_values(VAL_SORT_COLS, ascending=VAL_SORT_ASC).reset_index(drop=True)\n",
    "\n",
    "    print('Selected best config per model (based on validation only):')\n",
    "    display(df_best_val[preview_cols])\n",
    "\n",
    "    final_rows = []\n",
    "    final_pred_records = []\n",
    "\n",
    "    for _, best in df_best_val.iterrows():\n",
    "        model_name = str(best['model'])\n",
    "        birth_dt_utc = str(best['birth_dt_utc'])\n",
    "        gauss_window = int(best['gauss_window'])\n",
    "        gauss_std = float(best['gauss_std'])\n",
    "        params = json.loads(str(best['model_params_json']))\n",
    "\n",
    "        parts = build_dataset_parts_for_gauss(\n",
    "            gauss_window,\n",
    "            gauss_std,\n",
    "            birth_dt_utc=birth_dt_utc,\n",
    "            verbose=False,\n",
    "        )\n",
    "        final_row, pred_all = run_one_eval_with_pred(parts, model_name, params, include_test=True)\n",
    "        final_rows.append(final_row)\n",
    "\n",
    "        final_pred_records.append({\n",
    "            'model': model_name,\n",
    "            'birth_date': str(parts['birth_date']),\n",
    "            'birth_dt_utc': str(parts['birth_dt_utc']),\n",
    "            'gauss_window': int(parts['gauss_window']),\n",
    "            'gauss_std': float(parts['gauss_std']),\n",
    "            'model_params_json': final_row['model_params_json'],\n",
    "            'pred_all': pred_all,\n",
    "        })\n",
    "\n",
    "        print(f\"[final-test] {_cfg_str(final_row)}\")\n",
    "        print('  ', _fmt_metrics('val', final_row))\n",
    "        print('  ', _fmt_metrics('test', final_row))\n",
    "\n",
    "    df_cls = pd.DataFrame(final_rows).sort_values(VAL_SORT_COLS, ascending=VAL_SORT_ASC).reset_index(drop=True)\n",
    "\n",
    "    print('Final model comparison (selection on val, evaluation on test):')\n",
    "    display(df_cls[[\n",
    "        'model', 'birth_date', 'birth_dt_utc', 'gauss_window', 'gauss_std', 'model_params_json', 'val_threshold',\n",
    "        'val_accuracy', 'val_balanced_accuracy', 'val_f1_macro', 'val_mcc',\n",
    "        'val_precision_down', 'val_precision_up',\n",
    "        'val_recall_down', 'val_recall_up', 'val_recall_min', 'val_recall_gap', 'val_p_value_vs_random',\n",
    "        'test_accuracy', 'test_balanced_accuracy', 'test_f1_macro', 'test_mcc',\n",
    "        'test_precision_down', 'test_precision_up',\n",
    "        'test_recall_down', 'test_recall_up', 'test_recall_min', 'test_recall_gap', 'test_p_value_vs_random',\n",
    "    ]])\n",
    "\n",
    "    if ENABLE_THRESHOLD_SENSITIVITY:\n",
    "        sensitivity_rows = []\n",
    "        curve_rows = []\n",
    "\n",
    "        for rec in final_pred_records:\n",
    "            df_val_pred = rec['pred_all'][rec['pred_all']['split_role'] == 'val']\n",
    "            y_val_curve = df_val_pred['target'].to_numpy(dtype=int)\n",
    "            p_val_curve = df_val_pred['pred_proba_up'].to_numpy(dtype=float)\n",
    "\n",
    "            for gap_penalty in THRESHOLD_GAP_PENALTY_GRID:\n",
    "                for prior_penalty in THRESHOLD_PRIOR_PENALTY_GRID:\n",
    "                    sr = eval_row_from_pred(\n",
    "                        pred_all=rec['pred_all'],\n",
    "                        model_name=rec['model'],\n",
    "                        gap_penalty=float(gap_penalty),\n",
    "                        prior_penalty=float(prior_penalty),\n",
    "                        thresholds=THRESHOLD_CANDIDATE_GRID,\n",
    "                        include_test=True,\n",
    "                    )\n",
    "                    sr['birth_date'] = rec['birth_date']\n",
    "                    sr['birth_dt_utc'] = rec['birth_dt_utc']\n",
    "                    sr['gauss_window'] = rec['gauss_window']\n",
    "                    sr['gauss_std'] = rec['gauss_std']\n",
    "                    sr['model_params_json'] = rec['model_params_json']\n",
    "                    sensitivity_rows.append(sr)\n",
    "\n",
    "                    df_curve = evaluate_threshold_grid(\n",
    "                        y_true=y_val_curve,\n",
    "                        proba_up=p_val_curve,\n",
    "                        gap_penalty=float(gap_penalty),\n",
    "                        prior_penalty=float(prior_penalty),\n",
    "                        thresholds=THRESHOLD_CANDIDATE_GRID,\n",
    "                    )\n",
    "                    if not df_curve.empty:\n",
    "                        df_curve = df_curve.head(int(THRESHOLD_CURVE_TOP_K)).copy()\n",
    "                        df_curve['model'] = rec['model']\n",
    "                        df_curve['birth_date'] = rec['birth_date']\n",
    "                        df_curve['birth_dt_utc'] = rec['birth_dt_utc']\n",
    "                        df_curve['gauss_window'] = rec['gauss_window']\n",
    "                        df_curve['gauss_std'] = rec['gauss_std']\n",
    "                        df_curve['model_params_json'] = rec['model_params_json']\n",
    "                        df_curve['threshold_gap_penalty'] = float(gap_penalty)\n",
    "                        df_curve['threshold_prior_penalty'] = float(prior_penalty)\n",
    "                        curve_rows.append(df_curve)\n",
    "\n",
    "        df_threshold_sensitivity = pd.DataFrame(sensitivity_rows).sort_values(\n",
    "            ['model', 'birth_date', 'gauss_window', 'gauss_std', 'val_recall_min', 'val_recall_gap', 'val_mcc', 'val_accuracy'],\n",
    "            ascending=[True, True, True, True, False, True, False, False],\n",
    "        ).reset_index(drop=True)\n",
    "\n",
    "        print('Threshold penalty sensitivity (no retrain; threshold retuned on val):')\n",
    "        display(df_threshold_sensitivity[[\n",
    "            'model', 'birth_date', 'birth_dt_utc', 'gauss_window', 'gauss_std', 'model_params_json',\n",
    "            'threshold_gap_penalty', 'threshold_prior_penalty', 'val_threshold', 'val_threshold_score',\n",
    "            'val_accuracy', 'val_mcc', 'val_recall_min', 'val_recall_gap',\n",
    "            'test_accuracy', 'test_mcc', 'test_recall_min', 'test_recall_gap', 'test_p_value_vs_random',\n",
    "        ]])\n",
    "\n",
    "        df_threshold_sensitivity_best = (\n",
    "            df_threshold_sensitivity\n",
    "            .sort_values(VAL_SORT_COLS, ascending=VAL_SORT_ASC)\n",
    "            .drop_duplicates(subset=['model', 'birth_dt_utc', 'gauss_window', 'gauss_std', 'model_params_json'])\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        print('Best threshold-penalty combo per selected final model config:')\n",
    "        display(df_threshold_sensitivity_best[[\n",
    "            'model', 'birth_date', 'gauss_window', 'gauss_std',\n",
    "            'threshold_gap_penalty', 'threshold_prior_penalty', 'val_threshold', 'val_threshold_score',\n",
    "            'val_accuracy', 'val_mcc', 'val_recall_min', 'val_recall_gap',\n",
    "            'test_accuracy', 'test_mcc', 'test_recall_min', 'test_recall_gap', 'test_p_value_vs_random',\n",
    "        ]])\n",
    "\n",
    "        if curve_rows:\n",
    "            df_threshold_curve_top = (\n",
    "                pd.concat(curve_rows, ignore_index=True)\n",
    "                .sort_values(\n",
    "                    [\n",
    "                        'model', 'birth_date', 'gauss_window', 'gauss_std',\n",
    "                        'threshold_gap_penalty', 'threshold_prior_penalty',\n",
    "                        'score', 'threshold',\n",
    "                    ],\n",
    "                    ascending=[True, True, True, True, True, True, False, True],\n",
    "                )\n",
    "                .reset_index(drop=True)\n",
    "            )\n",
    "\n",
    "            print('Top threshold candidates by validation objective score:')\n",
    "            display(df_threshold_curve_top[[\n",
    "                'model', 'birth_date', 'birth_dt_utc', 'gauss_window', 'gauss_std', 'model_params_json',\n",
    "                'threshold_gap_penalty', 'threshold_prior_penalty', 'threshold', 'score',\n",
    "                'recall_min', 'recall_gap', 'prior_gap', 'pred_up_share', 'true_up_share',\n",
    "                'accuracy', 'balanced_accuracy', 'mcc', 'f1_macro',\n",
    "            ]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aa0593a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>val_threshold</th>\n",
       "      <th>val_threshold_score</th>\n",
       "      <th>threshold_gap_penalty</th>\n",
       "      <th>threshold_prior_penalty</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_balanced_accuracy</th>\n",
       "      <th>val_mcc</th>\n",
       "      <th>val_f1_macro</th>\n",
       "      <th>val_precision_down</th>\n",
       "      <th>val_precision_up</th>\n",
       "      <th>val_recall_down</th>\n",
       "      <th>val_recall_up</th>\n",
       "      <th>val_recall_min</th>\n",
       "      <th>val_recall_gap</th>\n",
       "      <th>val_support</th>\n",
       "      <th>val_p_value_vs_random</th>\n",
       "      <th>birth_dt_utc</th>\n",
       "      <th>birth_date</th>\n",
       "      <th>gauss_window</th>\n",
       "      <th>gauss_std</th>\n",
       "      <th>model_params_json</th>\n",
       "      <th>hp_n_estimators</th>\n",
       "      <th>hp_max_depth</th>\n",
       "      <th>hp_learning_rate</th>\n",
       "      <th>hp_colsample_bytree</th>\n",
       "      <th>hp_subsample</th>\n",
       "      <th>hp_early_stopping_rounds</th>\n",
       "      <th>hp_weight_power</th>\n",
       "      <th>hp_sideways_penalty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.557844</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.560531</td>\n",
       "      <td>0.560477</td>\n",
       "      <td>0.120799</td>\n",
       "      <td>0.560139</td>\n",
       "      <td>0.535117</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.561514</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.557844</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.560531</td>\n",
       "      <td>0.560477</td>\n",
       "      <td>0.120799</td>\n",
       "      <td>0.560139</td>\n",
       "      <td>0.535117</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.561514</td>\n",
       "      <td>0.559441</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.551945</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.558872</td>\n",
       "      <td>0.559071</td>\n",
       "      <td>0.117986</td>\n",
       "      <td>0.558599</td>\n",
       "      <td>0.533113</td>\n",
       "      <td>0.584718</td>\n",
       "      <td>0.562937</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.007732</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.550031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.562189</td>\n",
       "      <td>0.562568</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.561985</td>\n",
       "      <td>0.536184</td>\n",
       "      <td>0.588629</td>\n",
       "      <td>0.569930</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.550031</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.562189</td>\n",
       "      <td>0.562568</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.561985</td>\n",
       "      <td>0.536184</td>\n",
       "      <td>0.588629</td>\n",
       "      <td>0.569930</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.014725</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>151</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.9, \"early_stopping_roun...</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.273715</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.273715</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.273715</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.273715</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.8, \"early_stopping_roun...</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.273715</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.344565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>603.0</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>2009-01-03T18:15:05Z</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>201</td>\n",
       "      <td>30.0</td>\n",
       "      <td>{\"colsample_bytree\": 0.7, \"early_stopping_roun...</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  val_threshold  val_threshold_score  threshold_gap_penalty  threshold_prior_penalty  val_accuracy  val_balanced_accuracy   val_mcc  val_f1_macro  val_precision_down  \\\n",
       "0     xgb           0.47             0.557844                   0.25                     0.05      0.560531               0.560477  0.120799      0.560139            0.535117   \n",
       "1     xgb           0.47             0.557844                   0.25                     0.05      0.560531               0.560477  0.120799      0.560139            0.535117   \n",
       "2     xgb           0.47             0.551945                   0.25                     0.05      0.558872               0.559071  0.117986      0.558599            0.533113   \n",
       "3     xgb           0.47             0.550031                   0.25                     0.05      0.562189               0.562568  0.124974      0.561985            0.536184   \n",
       "4     xgb           0.47             0.550031                   0.25                     0.05      0.562189               0.562568  0.124974      0.561985            0.536184   \n",
       "..    ...            ...                  ...                    ...                      ...           ...                    ...       ...           ...                 ...   \n",
       "265   xgb           0.05            -0.273715                   0.25                     0.05      0.525705               0.500000  0.000000      0.344565            0.000000   \n",
       "266   xgb           0.05            -0.273715                   0.25                     0.05      0.525705               0.500000  0.000000      0.344565            0.000000   \n",
       "267   xgb           0.05            -0.273715                   0.25                     0.05      0.525705               0.500000  0.000000      0.344565            0.000000   \n",
       "268   xgb           0.05            -0.273715                   0.25                     0.05      0.525705               0.500000  0.000000      0.344565            0.000000   \n",
       "269   xgb           0.05            -0.273715                   0.25                     0.05      0.525705               0.500000  0.000000      0.344565            0.000000   \n",
       "\n",
       "     val_precision_up  val_recall_down  val_recall_up  val_recall_min  val_recall_gap  val_support  val_p_value_vs_random          birth_dt_utc  birth_date  gauss_window  \\\n",
       "0            0.585526         0.559441       0.561514        0.559441        0.002074        603.0               0.001667  2009-01-03T18:15:05Z  2009-01-03           201   \n",
       "1            0.585526         0.559441       0.561514        0.559441        0.002074        603.0               0.001667  2009-01-03T18:15:05Z  2009-01-03           201   \n",
       "2            0.584718         0.562937       0.555205        0.555205        0.007732        603.0               0.002162  2009-01-03T18:15:05Z  2009-01-03           151   \n",
       "3            0.588629         0.569930       0.555205        0.555205        0.014725        603.0               0.001277  2009-01-03T18:15:05Z  2009-01-03           151   \n",
       "4            0.588629         0.569930       0.555205        0.555205        0.014725        603.0               0.001277  2009-01-03T18:15:05Z  2009-01-03           151   \n",
       "..                ...              ...            ...             ...             ...          ...                    ...                   ...         ...           ...   \n",
       "265          0.525705         0.000000       1.000000        0.000000        1.000000        603.0               0.110896  2009-01-03T18:15:05Z  2009-01-03           201   \n",
       "266          0.525705         0.000000       1.000000        0.000000        1.000000        603.0               0.110896  2009-01-03T18:15:05Z  2009-01-03           201   \n",
       "267          0.525705         0.000000       1.000000        0.000000        1.000000        603.0               0.110896  2009-01-03T18:15:05Z  2009-01-03           201   \n",
       "268          0.525705         0.000000       1.000000        0.000000        1.000000        603.0               0.110896  2009-01-03T18:15:05Z  2009-01-03           201   \n",
       "269          0.525705         0.000000       1.000000        0.000000        1.000000        603.0               0.110896  2009-01-03T18:15:05Z  2009-01-03           201   \n",
       "\n",
       "     gauss_std                                  model_params_json  hp_n_estimators  hp_max_depth  hp_learning_rate  hp_colsample_bytree  hp_subsample  hp_early_stopping_rounds  \\\n",
       "0         30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...              100             3              0.01                  0.9           0.8                        75   \n",
       "1         30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...              150             3              0.01                  0.9           0.8                        75   \n",
       "2         30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...               75             3              0.01                  0.9           0.8                        75   \n",
       "3         30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...              100             3              0.01                  0.9           0.8                        75   \n",
       "4         30.0  {\"colsample_bytree\": 0.9, \"early_stopping_roun...              150             3              0.01                  0.9           0.8                        75   \n",
       "..         ...                                                ...              ...           ...               ...                  ...           ...                       ...   \n",
       "265       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...              100             3              0.01                  0.8           0.9                        75   \n",
       "266       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...              100             4              0.01                  0.7           0.9                        75   \n",
       "267       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...              150             3              0.01                  0.7           0.9                        75   \n",
       "268       30.0  {\"colsample_bytree\": 0.8, \"early_stopping_roun...              150             3              0.01                  0.8           0.9                        75   \n",
       "269       30.0  {\"colsample_bytree\": 0.7, \"early_stopping_roun...              150             4              0.01                  0.7           0.9                        75   \n",
       "\n",
       "     hp_weight_power  hp_sideways_penalty  \n",
       "0                1.0                  1.0  \n",
       "1                1.0                  1.0  \n",
       "2                1.0                  1.0  \n",
       "3                1.0                  1.0  \n",
       "4                1.0                  1.0  \n",
       "..               ...                  ...  \n",
       "265              1.0                  1.0  \n",
       "266              1.0                  1.0  \n",
       "267              1.0                  1.0  \n",
       "268              1.0                  1.0  \n",
       "269              1.0                  1.0  \n",
       "\n",
       "[270 rows x 30 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sweep_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad51bdd1",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- This notebook is intentionally classification-first and classic-split only.\n",
    "- Houses are not used.\n",
    "- To test optional blocks, set in config:\n",
    "  - `FEATURE_BLOCKS['progressed_to_natal'] = True`\n",
    "  - `FEATURE_BLOCKS['directed_to_natal'] = True`\n",
    "- If you only want to precompute/cache optional blocks, keep them `False` and set `PRECOMPUTE_DISABLED_BLOCKS = True`.\n",
    "- To include aspects between transit planets, set `CLASSIC_INCLUDE_TRANSIT_PAIR_ASPECTS = True`.\n",
    "- To run birthdate sweep, use `ENABLE_BIRTHDATE_SWEEP` and edit `BIRTHDATE_CANDIDATES`.\n",
    "- To run Gaussian + hyperparameter sweep, set `ENABLE_GAUSS_HYPER_SWEEP = True` and edit:\n",
    "  - `GAUSS_WINDOWS`, `GAUSS_STDS`\n",
    "  - `XGB_PARAM_GRID`, `RF_PARAM_GRID`\n",
    "- Selection is validation-only; test is used only for final selected configs.\n",
    "- Threshold sensitivity is controlled by `ENABLE_THRESHOLD_SENSITIVITY`, `THRESHOLD_GAP_PENALTY_GRID`, `THRESHOLD_PRIOR_PENALTY_GRID`, `THRESHOLD_CANDIDATE_GRID`, `THRESHOLD_CURVE_TOP_K`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}