{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa95c65d",
   "metadata": {},
   "source": [
    "# Moon Cycles Deep Search (Moon-Only Features)\n",
    "\n",
    "This notebook is a **Moon-phase-only** research pipeline for Bitcoin direction prediction.\n",
    "\n",
    "What this notebook does:\n",
    "1. Loads market data from parquet.\n",
    "2. Builds only Moon-phase features (Sun + Moon geometry, no other planets).\n",
    "3. Tunes Gaussian label parameters.\n",
    "4. Evaluates two protocols:\n",
    "   - Classic split: `70 / 15 / 15`\n",
    "   - Walk-forward split: `50% warm-up + 10/10/10/10/10 blocks`, where each block is `5% val + 5% test`\n",
    "5. Runs full visual diagnostics **before training** (baselines) and **after training** (XGBoost).\n",
    "\n",
    "Important:\n",
    "- Everything expensive is cached.\n",
    "- Split boundaries are shown on charts, so train/validation/test are fully transparent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531b50e",
   "metadata": {},
   "source": [
    "## Speed And Caching Strategy\n",
    "\n",
    "Why this notebook runs much faster than a naive implementation:\n",
    "- We compute astro positions only for **Sun and Moon**.\n",
    "- We cache market slices, Moon features, labels, merged datasets, and whole experiment runs.\n",
    "- We reuse the same Moon feature table while sweeping Gaussian parameters.\n",
    "- We keep heavy logic inside reusable Python modules instead of repeating it in notebook cells.\n",
    "\n",
    "This means first run can be heavy, but repeated runs should be much faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377845b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "PROJECT_ROOT = Path('/home/rut/ostrofun')\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from RESEARCH2.Moon_cycles.moon_data import (\n",
    "    MoonLabelConfig,\n",
    "    build_moon_dataset_for_gauss,\n",
    "    build_moon_phase_features,\n",
    "    load_market_slice,\n",
    ")\n",
    "from RESEARCH2.Moon_cycles.search_utils import (\n",
    "    WalkForwardConfig,\n",
    "    XgbConfig,\n",
    "    run_gauss_search,\n",
    ")\n",
    "from RESEARCH2.Moon_cycles.eval_utils import compute_binary_metrics\n",
    "from RESEARCH2.Moon_cycles.eval_visuals import VisualizationConfig, evaluate_with_visuals\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbab1c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Research configuration block\n",
    "# ------------------------------\n",
    "# We keep all knobs in one place so experiments are reproducible.\n",
    "\n",
    "START_DATE = '2017-11-01'\n",
    "END_DATE = None\n",
    "USE_CACHE = True\n",
    "VERBOSE = True\n",
    "\n",
    "# Label parameters that stay fixed while we tune Gaussian window/std.\n",
    "LABEL_CFG = MoonLabelConfig(\n",
    "    horizon=1,\n",
    "    move_share=0.5,\n",
    "    label_mode='balanced_detrended',\n",
    "    price_mode='raw',\n",
    ")\n",
    "\n",
    "# Gaussian grid to tune.\n",
    "GAUSS_WINDOWS = [101, 151, 201, 251, 301]\n",
    "GAUSS_STDS = [30.0, 50.0, 70.0, 90.0]\n",
    "\n",
    "# Model hyperparameters.\n",
    "MODEL_CFG = XgbConfig(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.03,\n",
    "    colsample_bytree=0.8,\n",
    "    subsample=0.8,\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "# Walk-forward split protocol.\n",
    "WF_CFG = WalkForwardConfig(\n",
    "    warmup_ratio=0.50,\n",
    "    block_ratios=(0.10, 0.10, 0.10, 0.10, 0.10),\n",
    "    val_fraction_inside_block=0.50,\n",
    ")\n",
    "\n",
    "# Visual defaults: highly visual by design.\n",
    "VIS_CFG = VisualizationConfig(\n",
    "    rolling_window_days=90,\n",
    "    rolling_min_periods=30,\n",
    ")\n",
    "\n",
    "print('Config loaded.')\n",
    "print('Gaussian grid size =', len(GAUSS_WINDOWS) * len(GAUSS_STDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1d6173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Load market data and build Moon-only features\n",
    "# -------------------------------------------\n",
    "# This is the main expensive astro stage.\n",
    "# On repeated runs it should come from cache.\n",
    "\n",
    "df_market = load_market_slice(\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    use_cache=USE_CACHE,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "\n",
    "df_moon_features = build_moon_phase_features(\n",
    "    df_market=df_market,\n",
    "    use_cache=USE_CACHE,\n",
    "    verbose=VERBOSE,\n",
    "    progress=True,\n",
    ")\n",
    "\n",
    "print('Market rows:', len(df_market))\n",
    "print('Moon feature rows:', len(df_moon_features))\n",
    "print('Market range:', df_market['date'].min().date(), '->', df_market['date'].max().date())\n",
    "\n",
    "display(df_moon_features.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1da0c",
   "metadata": {},
   "source": [
    "## Protocol A: Classic 70/15/15\n",
    "\n",
    "We tune Gaussian parameters and evaluate each candidate using:\n",
    "- Train on first 70%\n",
    "- Tune threshold on next 15%\n",
    "- Report final quality on last 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4144798",
   "metadata": {},
   "outputs": [],
   "source": [
    "classic_search = run_gauss_search(\n",
    "    df_market=df_market,\n",
    "    df_moon_features=df_moon_features,\n",
    "    gauss_windows=GAUSS_WINDOWS,\n",
    "    gauss_stds=GAUSS_STDS,\n",
    "    label_cfg=LABEL_CFG,\n",
    "    model_cfg=MODEL_CFG,\n",
    "    wf_cfg=WF_CFG,\n",
    "    protocol='classic',\n",
    "    use_cache=USE_CACHE,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "\n",
    "classic_table = classic_search['results_table']\n",
    "print('Classic search completed. Top rows:')\n",
    "display(classic_table.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa2d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# Full evaluation for the best classic configuration\n",
    "# -------------------------------------------------------\n",
    "# We evaluate BEFORE training (majority baseline), then AFTER training.\n",
    "\n",
    "classic_best = classic_search['best_result']\n",
    "classic_best_row = classic_search['best_row']\n",
    "print('Best classic config:')\n",
    "display(pd.DataFrame([classic_best_row]))\n",
    "\n",
    "classic_pred = classic_best['predictions'].copy()\n",
    "classic_test = classic_pred[classic_pred['split_role'] == 'test'].copy().reset_index(drop=True)\n",
    "classic_test = classic_test.dropna(subset=['pred_label'])\n",
    "\n",
    "print('Classic test rows:', len(classic_test))\n",
    "\n",
    "# BEFORE training: majority baseline.\n",
    "classic_before = evaluate_with_visuals(\n",
    "    df_plot=classic_test,\n",
    "    y_true=classic_test['target'].to_numpy(dtype=np.int32),\n",
    "    y_pred=classic_test['baseline_majority'].to_numpy(dtype=np.int32),\n",
    "    y_prob_up=None,\n",
    "    title='Classic protocol - BEFORE training (majority baseline)',\n",
    "    vis_cfg=VIS_CFG,\n",
    "    show_visuals=True,\n",
    ")\n",
    "\n",
    "# AFTER training: tuned XGBoost predictions.\n",
    "classic_after = evaluate_with_visuals(\n",
    "    df_plot=classic_test,\n",
    "    y_true=classic_test['target'].to_numpy(dtype=np.int32),\n",
    "    y_pred=classic_test['pred_label'].to_numpy(dtype=np.int32),\n",
    "    y_prob_up=classic_test['pred_proba_up'].to_numpy(dtype=float),\n",
    "    title='Classic protocol - AFTER training (Moon-only model)',\n",
    "    vis_cfg=VIS_CFG,\n",
    "    show_visuals=True,\n",
    ")\n",
    "\n",
    "# Extra number-only baseline check: random baseline with train class prior.\n",
    "classic_random_metrics = compute_binary_metrics(\n",
    "    y_true=classic_test['target'].to_numpy(dtype=np.int32),\n",
    "    y_pred=classic_test['baseline_random'].to_numpy(dtype=np.int32),\n",
    ")\n",
    "print('Classic random baseline metrics:', classic_random_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699aa50c",
   "metadata": {},
   "source": [
    "## Protocol B: Walk-Forward (50% warm-up + 10% blocks)\n",
    "\n",
    "We now use an expanding-window protocol closer to real deployment:\n",
    "- First 50% is initial training history.\n",
    "- Remaining history is split into five 10% sequential blocks.\n",
    "- Each 10% block is split into 5% validation + 5% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0547e865",
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_search = run_gauss_search(\n",
    "    df_market=df_market,\n",
    "    df_moon_features=df_moon_features,\n",
    "    gauss_windows=GAUSS_WINDOWS,\n",
    "    gauss_stds=GAUSS_STDS,\n",
    "    label_cfg=LABEL_CFG,\n",
    "    model_cfg=MODEL_CFG,\n",
    "    wf_cfg=WF_CFG,\n",
    "    protocol='walk_forward',\n",
    "    use_cache=USE_CACHE,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "\n",
    "walk_table = walk_search['results_table']\n",
    "print('Walk-forward search completed. Top rows:')\n",
    "display(walk_table.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------\n",
    "# Full evaluation for the best walk-forward configuration\n",
    "# -----------------------------------------------------------\n",
    "# We evaluate on concatenated test blocks from all folds.\n",
    "\n",
    "walk_best = walk_search['best_result']\n",
    "walk_best_row = walk_search['best_row']\n",
    "print('Best walk-forward config:')\n",
    "display(pd.DataFrame([walk_best_row]))\n",
    "\n",
    "walk_pred = walk_best['predictions'].copy()\n",
    "walk_test = walk_pred[walk_pred['split_role'] == 'test'].copy().reset_index(drop=True)\n",
    "walk_test = walk_test.dropna(subset=['pred_label'])\n",
    "\n",
    "print('Walk-forward concatenated test rows:', len(walk_test))\n",
    "\n",
    "# BEFORE training: majority baseline per fold (already stored in merged test stream).\n",
    "walk_before = evaluate_with_visuals(\n",
    "    df_plot=walk_test,\n",
    "    y_true=walk_test['target'].to_numpy(dtype=np.int32),\n",
    "    y_pred=walk_test['baseline_majority'].to_numpy(dtype=np.int32),\n",
    "    y_prob_up=None,\n",
    "    title='Walk-forward - BEFORE training (majority baseline)',\n",
    "    vis_cfg=VIS_CFG,\n",
    "    show_visuals=True,\n",
    ")\n",
    "\n",
    "# AFTER training: model predictions from each fold test block.\n",
    "walk_after = evaluate_with_visuals(\n",
    "    df_plot=walk_test,\n",
    "    y_true=walk_test['target'].to_numpy(dtype=np.int32),\n",
    "    y_pred=walk_test['pred_label'].to_numpy(dtype=np.int32),\n",
    "    y_prob_up=walk_test['pred_proba_up'].to_numpy(dtype=float),\n",
    "    title='Walk-forward - AFTER training (Moon-only model)',\n",
    "    vis_cfg=VIS_CFG,\n",
    "    show_visuals=True,\n",
    ")\n",
    "\n",
    "walk_random_metrics = compute_binary_metrics(\n",
    "    y_true=walk_test['target'].to_numpy(dtype=np.int32),\n",
    "    y_pred=walk_test['baseline_random'].to_numpy(dtype=np.int32),\n",
    ")\n",
    "print('Walk-forward random baseline metrics:', walk_random_metrics)\n",
    "\n",
    "if 'fold_table' in walk_best:\n",
    "    print('Per-fold quality table:')\n",
    "    display(walk_best['fold_table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc14154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Compare best protocol summaries side by side\n",
    "# -------------------------------------------\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        'protocol': 'classic_70_15_15',\n",
    "        **classic_search['best_row'],\n",
    "    },\n",
    "    {\n",
    "        'protocol': 'walk_forward',\n",
    "        **walk_search['best_row'],\n",
    "    },\n",
    "])\n",
    "\n",
    "cols_order = [\n",
    "    'protocol',\n",
    "    'gauss_window',\n",
    "    'gauss_std',\n",
    "    'test_acc',\n",
    "    'test_bal_acc',\n",
    "    'test_mcc',\n",
    "    'test_recall_min',\n",
    "    'test_recall_down',\n",
    "    'test_recall_up',\n",
    "    'baseline_majority_test_acc',\n",
    "    'baseline_random_test_acc',\n",
    "    'p_value_vs_random',\n",
    "]\n",
    "\n",
    "print('Best candidates comparison:')\n",
    "display(comparison[cols_order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6132ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------\n",
    "# Visual heatmaps: how Gaussian parameters affect quality\n",
    "# ------------------------------------------------------\n",
    "\n",
    "def plot_gauss_heatmap(results_df: pd.DataFrame, metric: str, title: str) -> None:\n",
    "    pivot = results_df.pivot_table(index='gauss_window', columns='gauss_std', values=metric)\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.heatmap(pivot, annot=True, fmt='.3f', cmap='viridis')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('gauss_std')\n",
    "    plt.ylabel('gauss_window')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_gauss_heatmap(classic_table, 'test_recall_min', 'Classic: Recall_MIN by Gaussian params')\n",
    "plot_gauss_heatmap(classic_table, 'test_mcc', 'Classic: MCC by Gaussian params')\n",
    "\n",
    "plot_gauss_heatmap(walk_table, 'test_recall_min', 'Walk-forward: Recall_MIN by Gaussian params')\n",
    "plot_gauss_heatmap(walk_table, 'test_mcc', 'Walk-forward: MCC by Gaussian params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493086e4",
   "metadata": {},
   "source": [
    "## Final Notes\n",
    "\n",
    "- If `p_value_vs_random` is very small, model accuracy is unlikely to be random luck.\n",
    "- Always compare against both baselines (majority and random).\n",
    "- For production, use the best Gaussian config from this notebook and retrain on all available data right before live forecasting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
