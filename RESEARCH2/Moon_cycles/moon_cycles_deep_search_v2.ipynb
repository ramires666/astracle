{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2bf9b4",
   "metadata": {},
   "source": [
    "# Moon Cycles Deep Search (v2) â€” Model Bakeoff\n",
    "\n",
    "Goal of this notebook:\n",
    "- Answer one simple question in the most honest way possible:\n",
    "\n",
    "**Do Moon-phase-only features contain any real predictive edge for BTC direction, or is it basically random?**\n",
    "\n",
    "How we make this answer convincing:\n",
    "1. We test multiple model families (linear, trees, small neural net, XGBoost).\n",
    "2. We use strict time split (no shuffling).\n",
    "3. We choose Gaussian label parameters using **validation only**.\n",
    "4. We touch the test set only for the final report.\n",
    "\n",
    "If all models look random on the test set, the problem is NOT the model.\n",
    "It means the features probably do not carry useful signal (for this target)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f949238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "PROJECT_ROOT = Path('/home/rut/ostrofun')\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from RESEARCH2.Moon_cycles.moon_data import (\n",
    "    MoonLabelConfig,\n",
    "    build_moon_phase_features,\n",
    "    load_market_slice,\n",
    ")\n",
    "from RESEARCH2.Moon_cycles.bakeoff_utils import run_moon_model_bakeoff\n",
    "from RESEARCH2.Moon_cycles.eval_visuals import VisualizationConfig, evaluate_with_visuals\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cc90b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Research configuration block\n",
    "# ------------------------------\n",
    "\n",
    "START_DATE = '2017-11-01'\n",
    "END_DATE = None\n",
    "USE_CACHE = True\n",
    "VERBOSE = True\n",
    "\n",
    "# Label parameters that stay fixed while we tune Gaussian window/std.\n",
    "LABEL_CFG = MoonLabelConfig(\n",
    "    horizon=1,\n",
    "    move_share=0.5,\n",
    "    label_mode='balanced_detrended',\n",
    "    price_mode='raw',\n",
    ")\n",
    "\n",
    "# Gaussian grid to tune (label detrending parameters).\n",
    "GAUSS_WINDOWS = [101, 151, 201, 251, 301]\n",
    "GAUSS_STDS = [30.0, 50.0, 70.0, 90.0]\n",
    "\n",
    "# Threshold tuning penalties (helps avoid one-class prediction collapse).\n",
    "THRESHOLD_GAP_PENALTY = 0.25\n",
    "THRESHOLD_PRIOR_PENALTY = 0.05\n",
    "\n",
    "# XGBoost params (kept as baseline).\n",
    "XGB_PARAMS = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.03,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'early_stopping_rounds': 50,\n",
    "}\n",
    "\n",
    "# Dark-theme visuals.\n",
    "VIS_CFG = VisualizationConfig(\n",
    "    rolling_window_days=90,\n",
    "    rolling_min_periods=30,\n",
    "    probability_bins=64,\n",
    ")\n",
    "\n",
    "print('Config loaded.')\n",
    "print('Gaussian grid size =', len(GAUSS_WINDOWS) * len(GAUSS_STDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedbe0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------\n",
    "# Load market data and build Moon-only features\n",
    "# -------------------------------------------\n",
    "\n",
    "df_market = load_market_slice(\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    use_cache=USE_CACHE,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "\n",
    "df_moon_features = build_moon_phase_features(\n",
    "    df_market=df_market,\n",
    "    use_cache=USE_CACHE,\n",
    "    verbose=VERBOSE,\n",
    "    progress=True,\n",
    ")\n",
    "\n",
    "print('Market rows:', len(df_market))\n",
    "print('Moon feature rows:', len(df_moon_features))\n",
    "print('Market range:', df_market['date'].min().date(), '->', df_market['date'].max().date())\n",
    "\n",
    "display(df_moon_features.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4cda6",
   "metadata": {},
   "source": [
    "## Bakeoff Run\n",
    "\n",
    "This section runs a grid over Gaussian label parameters and evaluates multiple models.\n",
    "\n",
    "Important:\n",
    "- We select the best Gaussian params **per model** using **validation metrics**.\n",
    "- Only after that we look at test metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ae5f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "bakeoff = run_moon_model_bakeoff(\n",
    "    df_market=df_market,\n",
    "    df_moon_features=df_moon_features,\n",
    "    gauss_windows=GAUSS_WINDOWS,\n",
    "    gauss_stds=GAUSS_STDS,\n",
    "    label_cfg=LABEL_CFG,\n",
    "    include_xgb=True,\n",
    "    xgb_params=XGB_PARAMS,\n",
    "    threshold_gap_penalty=THRESHOLD_GAP_PENALTY,\n",
    "    threshold_prior_penalty=THRESHOLD_PRIOR_PENALTY,\n",
    "    use_cache=USE_CACHE,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "\n",
    "results_table = bakeoff['results_table']\n",
    "best_by_val = bakeoff['best_by_val_table']\n",
    "best_runs = bakeoff['best_runs']\n",
    "\n",
    "print('Bakeoff results rows:', len(results_table))\n",
    "print('Best-by-validation table (one row per model):')\n",
    "display(best_by_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf918f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# Show top configs per model by VALIDATION quality\n",
    "# -------------------------------------------------\n",
    "# This makes it easy to see if any model consistently beats random.\n",
    "\n",
    "show_cols = [\n",
    "    'model',\n",
    "    'gauss_window',\n",
    "    'gauss_std',\n",
    "    'val_recall_min',\n",
    "    'val_recall_gap',\n",
    "    'val_mcc',\n",
    "    'val_acc',\n",
    "    'test_recall_min',\n",
    "    'test_recall_gap',\n",
    "    'test_mcc',\n",
    "    'test_acc',\n",
    "    'p_value_vs_random',\n",
    "    'baseline_majority_test_acc',\n",
    "    'baseline_random_test_acc',\n",
    "    'pred_up_share',\n",
    "]\n",
    "\n",
    "for model in sorted(results_table['model'].unique()):\n",
    "    sub = results_table[results_table['model'] == model].copy()\n",
    "    sub = sub.sort_values(\n",
    "        ['val_recall_min', 'val_recall_gap', 'val_mcc', 'val_acc'],\n",
    "        ascending=[False, True, False, False],\n",
    "    )\n",
    "    print()\n",
    "    print('='*90)\n",
    "    print('MODEL:', model)\n",
    "    display(sub[show_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb99f83",
   "metadata": {},
   "source": [
    "## Visual Diagnostics For Winners\n",
    "\n",
    "For each model, we take its best-by-validation configuration and plot:\n",
    "- confusion matrix\n",
    "- predicted vs true label background over price\n",
    "- rolling metrics\n",
    "- probability histogram\n",
    "\n",
    "This is the most \"human readable\" way to see if the model actually does something useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f88f127",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name, run in best_runs.items():\n",
    "    print()\n",
    "    print('#' * 100)\n",
    "    print('WINNER MODEL:', model_name)\n",
    "\n",
    "    pred = run['predictions'].copy()\n",
    "    test_df = pred[pred['split_role'] == 'test'].copy().reset_index(drop=True)\n",
    "    test_df = test_df.dropna(subset=['pred_label'])\n",
    "\n",
    "    # Evaluate baseline (majority) vs model on the SAME test period.\n",
    "    _ = evaluate_with_visuals(\n",
    "        df_plot=test_df,\n",
    "        y_true=test_df['target'].to_numpy(dtype=np.int32),\n",
    "        y_pred=test_df['baseline_majority'].to_numpy(dtype=np.int32),\n",
    "        y_prob_up=None,\n",
    "        title=f\"{model_name.upper()} - BEFORE training (majority baseline)\",\n",
    "        vis_cfg=VIS_CFG,\n",
    "        show_visuals=True,\n",
    "    )\n",
    "\n",
    "    _ = evaluate_with_visuals(\n",
    "        df_plot=test_df,\n",
    "        y_true=test_df['target'].to_numpy(dtype=np.int32),\n",
    "        y_pred=test_df['pred_label'].to_numpy(dtype=np.int32),\n",
    "        y_prob_up=test_df['pred_proba_up'].to_numpy(dtype=float),\n",
    "        title=f\"{model_name.upper()} - AFTER training (Moon-only)\",\n",
    "        vis_cfg=VIS_CFG,\n",
    "        show_visuals=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291c352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------\n",
    "# Quick conclusion helper\n",
    "# -------------------------------------------------\n",
    "# This is a simple text summary you can read like a report.\n",
    "\n",
    "report_cols = [\n",
    "    'model',\n",
    "    'gauss_window',\n",
    "    'gauss_std',\n",
    "    'val_recall_min',\n",
    "    'val_recall_gap',\n",
    "    'val_mcc',\n",
    "    'test_recall_min',\n",
    "    'test_recall_gap',\n",
    "    'test_mcc',\n",
    "    'test_acc',\n",
    "    'accuracy_ci95_low',\n",
    "    'accuracy_ci95_high',\n",
    "    'p_value_vs_random',\n",
    "]\n",
    "\n",
    "display(best_by_val[report_cols])\n",
    "\n",
    "print()\n",
    "print('Interpretation guide (very simple):')\n",
    "print('- If test_acc CI includes 0.50 and p-value is not small (e.g. > 0.05), it looks like random.')\n",
    "print('- If test_recall_min is below 0.50, the weaker class is basically not predictable.')\n",
    "print('- If MCC is near 0, it is basically random.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
